{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from newsapi import NewsApiClient\n",
    "from newspaper import Article\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "from newspaper import Article, ArticleException\n",
    "from requests.exceptions import HTTPError\n",
    "from langchain import OpenAI, ConversationChain, LLMChain, PromptTemplate\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from pymongo import MongoClient\n",
    "from urllib.parse import urlparse\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Codes below is how we made ChatGPT predict news relevancy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relevance_GPT(article_insert):\n",
    "    print('RELEVANCE GPT FUNCTION WORKING')\n",
    "    try:\n",
    "        #Defining Function + ChatGPT\n",
    "        #Langchain implementation\n",
    "        template = \"\"\" You are a bot that will be given an article and to deem if it is relevant to technology. \n",
    "        Please answer with Relevant or Irrelevant \n",
    "\n",
    "        Technology also includes the following:\n",
    "        \n",
    "        AI includes Discriminative AI, Machine Learning, Generative AI\n",
    "\n",
    "        Quantum Computing includes Quantum Internet, Quantum Communications, Quatum Computing\n",
    "\n",
    "        Green Computing includes Green Serverless Computing, Green Edge Applications, Green Data Streaming\n",
    "\n",
    "        Robotics\n",
    "\n",
    "        Trust Technologies includes Privacy Enhancing Technologies, Regulation Technologies, Al Governance Technologies\n",
    "\n",
    "        Anti-disinformation technologies includes Content Provenance Technologies, Anti-misinformation technologies, Detection of Generated Al content\n",
    "\n",
    "        Communications Technologies includes 5G, Networks, Seamless\n",
    "\n",
    "        In terms of the article information, classify them as Relevant or Irrelevant. \n",
    "\n",
    "        Make sure that there are no spacing before the first word.\n",
    "\n",
    "\n",
    "        Human: {article}\n",
    "        Assistant:\"\"\"\n",
    "\n",
    "        prompt = PromptTemplate(\n",
    "            input_variables=[\"article\"], \n",
    "            template=template\n",
    "        )\n",
    "\n",
    "        chatgpt_chain = LLMChain(\n",
    "            llm = OpenAI(openai_api_key=api_key,model=\"gpt-3.5-turbo-instruct\", temperature=0), \n",
    "            prompt=prompt, \n",
    "            verbose=False,  # Set verbose to False to suppress output\n",
    "            memory=ConversationBufferMemory(memory_key=\"history\", input_key=\"article\")\n",
    "        )\n",
    "        #Let ChatGPT to Categorise\n",
    "        output = chatgpt_chain.predict(article=article_insert) \n",
    "\n",
    "        #To make sure that there are no spacing which ChatGPT outputs \" Category_Name\" -> \"Category_Name\"\n",
    "        output = output.strip()\n",
    "\n",
    "        return output\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return \"Irrelevant\"  # Return 'Irrelevant'' category in case of error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RELEVANCE GPT FUNCTION WORKING\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "An error occurred: Error code: 400 - {'error': {'message': \"This model's maximum context length is 4097 tokens, however you requested 5626 tokens (5370 in your prompt; 256 for the completion). Please reduce your prompt; or completion length.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "An error occurred: Error code: 400 - {'error': {'message': \"This model's maximum context length is 4097 tokens, however you requested 5702 tokens (5446 in your prompt; 256 for the completion). Please reduce your prompt; or completion length.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "RELEVANCE GPT FUNCTION WORKING\n",
      "Column exported successfully.\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv('news relevancy - api_data.csv')\n",
    "#Def bart apply to be used for pandas apply function\n",
    "def gpt_rev(x):\n",
    "    result = relevance_GPT(x)\n",
    "    return result\n",
    "\n",
    "\n",
    "df['bart_cat'] = df['Article'].apply(gpt_rev)\n",
    "\n",
    "column_to_export = df['cat']\n",
    "\n",
    "# Export the column to a CSV file\n",
    "column_to_export.to_csv('gpt_column.csv', index=False)\n",
    "\n",
    "print(\"Column exported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chat-GPT Accuracy in Predicting Relevancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_prediction(predicted_csv):\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv('news relevancy - api_data.csv')\n",
    "    print(predicted_csv)\n",
    "    df_2 = pd.read_csv(predicted_csv)\n",
    "    #df_2 = pd.read_csv(predicted_csv)\n",
    "\n",
    "    # List of categories to label as 1\n",
    "    label_1_categories = [\"Business\",\"General\",\"Finance\"]\n",
    "\n",
    "    # Apply a lambda function to assign labels\n",
    "    df['bart_col'] = df_2.iloc[:, 0].apply(lambda x: 0 if x in label_1_categories else 1)\n",
    "\n",
    "\n",
    "    # Replace \"Yes\" and \"No\" with 1s and 0s respectively\n",
    "    df.replace({\"Relevant\": 1, \"Irrelevant\": 0}, inplace=True)\n",
    "\n",
    "    # Separate predictions and ground truth\n",
    "    predictions = df['bart_col']  # Assuming predictions are in the first row\n",
    "    ground_truth = df['groundTruth']  # Assuming ground truth is in the second row\n",
    "\n",
    "\n",
    "    #print(predictions)\n",
    "\n",
    "    # Compare predictions and ground truth\n",
    "    correct_predictions = (predictions == ground_truth).sum()\n",
    "    total_predictions = len(predictions)\n",
    "\n",
    "    # Print results\n",
    "    print(\"Predictions:\", predictions.values)\n",
    "    print(\"Ground Truth:\", ground_truth.values)\n",
    "    print(\"Number of correct predictions:\", correct_predictions)\n",
    "    print(\"Total predictions made:\", total_predictions)\n",
    "    print(\"Accuracy:\", correct_predictions / total_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt_column.csv\n",
      "Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1]\n",
      "Ground Truth: [1 1 1 1 1 0 1 0 1 1 0 0 1 0 0 0 1 1 1 0 1 0 1 0 1 1 0 0 0 1 0 0 1 1 1 1 1\n",
      " 0 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1\n",
      " 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 1 1 0 0 0 1\n",
      " 1 0 1 1 1 1 1 0 1 1 1 0 1 0 0 0 1 0 0 0 1 0 1 1 0 1 1 0 1 1 1 0 1 0 0 0 0\n",
      " 0 0]\n",
      "Number of correct predictions: 95\n",
      "Total predictions made: 150\n",
      "Accuracy: 0.6333333333333333\n"
     ]
    }
   ],
   "source": [
    "#Chat GPT Prediction\n",
    "acc_prediction('gpt_column.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bart_column.csv\n",
      "Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1]\n",
      "Ground Truth: [1 1 1 1 1 0 1 0 1 1 0 0 1 0 0 0 1 1 1 0 1 0 1 0 1 1 0 0 0 1 0 0 1 1 1 1 1\n",
      " 0 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1\n",
      " 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 1 1 0 0 0 1\n",
      " 1 0 1 1 1 1 1 0 1 1 1 0 1 0 0 0 1 0 0 0 1 0 1 1 0 1 1 0 1 1 1 0 1 0 0 0 0\n",
      " 0 0]\n",
      "Number of correct predictions: 95\n",
      "Total predictions made: 150\n",
      "Accuracy: 0.6333333333333333\n"
     ]
    }
   ],
   "source": [
    "#Bart Prediction\n",
    "acc_prediction('bart_column.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deberta_column.csv\n",
      "Predictions: [1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 0 1 1 1 0 1\n",
      " 0 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 0 0 1 1 0 0 1\n",
      " 1 0 1 0 1 0 0 1 1 1 1 0 0 0 1 0 1 0 1 1 1 1 1 0 1 1 0 0 1 0 0 1 1 0 0 0 0\n",
      " 0 1 1 1 1 0 1 0 1 1 1 1 1 0 0 0 0 0 0 1 1 1 0 1 0 1 1 0 1 1 1 0 0 0 0 0 0\n",
      " 0 0]\n",
      "Ground Truth: [1 1 1 1 1 0 1 0 1 1 0 0 1 0 0 0 1 1 1 0 1 0 1 0 1 1 0 0 0 1 0 0 1 1 1 1 1\n",
      " 0 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1\n",
      " 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 1 1 0 0 0 1\n",
      " 1 0 1 1 1 1 1 0 1 1 1 0 1 0 0 0 1 0 0 0 1 0 1 1 0 1 1 0 1 1 1 0 1 0 0 0 0\n",
      " 0 0]\n",
      "Number of correct predictions: 116\n",
      "Total predictions made: 150\n",
      "Accuracy: 0.7733333333333333\n"
     ]
    }
   ],
   "source": [
    "#deberta\n",
    "acc_prediction('deberta_column.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [1 1 1 1 1 0 1 0 1 1 0 0 1 0 0 0 1 1 1 0 1 0 1 0 1 1 0 0 0 1 0 0 1 1 1 1 1\n",
      " 0 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1\n",
      " 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 1 1 0 0 0 1\n",
      " 1 0 1 1 1 1 1 0 1 1 1 0 1 0 0 0 1 0 0 0 1 0 1 1 0 1 1 0 1 1 1 0 1 0 0 0 0\n",
      " 0 0]\n",
      "Ground Truth: [1 1 1 1 1 0 1 0 1 1 0 0 1 0 0 0 1 1 1 0 1 0 1 0 1 1 0 0 0 1 0 0 1 1 1 1 1\n",
      " 0 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1\n",
      " 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 1 1 0 0 0 1\n",
      " 1 0 1 1 1 1 1 0 1 1 1 0 1 0 0 0 1 0 0 0 1 0 1 1 0 1 1 0 1 1 1 0 1 0 0 0 0\n",
      " 0 0]\n",
      "Number of correct predictions: 150\n",
      "Total predictions made: 150\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "#voting\n",
    "df = pd.read_csv('news relevancy - api_data.csv')\n",
    "df_2 = pd.read_csv('voting_column.csv')\n",
    "\n",
    "# Replace \"Yes\" and \"No\" with 1s and 0s respectively\n",
    "df.replace({\"Relevant\": 1, \"Irrelevant\": 0}, inplace=True)\n",
    "\n",
    "# Separate predictions and ground truth\n",
    "predictions = df.iloc[:,5]  \n",
    "ground_truth = df['groundTruth']  \n",
    "\n",
    "# Compare predictions and ground truth\n",
    "correct_predictions = (predictions == ground_truth).sum()\n",
    "total_predictions = len(predictions)\n",
    "\n",
    "# Print results\n",
    "print(\"Predictions:\", predictions.values)\n",
    "print(\"Ground Truth:\", ground_truth.values)\n",
    "print(\"Number of correct predictions:\", correct_predictions)\n",
    "print(\"Total predictions made:\", total_predictions)\n",
    "print(\"Accuracy:\", correct_predictions / total_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
