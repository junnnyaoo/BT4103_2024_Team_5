Title,Link,Article,newsCategory,newsRelevancy,groundTruth,
Apple iOS 17.4: iMessage Gets Post-Quantum Encryption in New Update,https://www.wired.com/story/apple-pq3-post-quantum-encryption/,"Apple is launching its first post-quantum protections, one of the biggest deployments of the future-resistant encryption technology to date.

Billions of medical records, financial transactions, and messages we send to each other are protected by encryption. It’s fundamental to keeping modern life and the global economy running relatively smoothly. However, the decades-long race to create vastly powerful quantum computers, which could easily crack current encryption, creates new risks.

While practical quantum computing technology may still be years or decades away, security officials, tech companies, and governments are ramping up their efforts to start using a new generation of post-quantum cryptography. These new encryption algorithms will, in short, protect our current systems against any potential quantum computing-based attacks.

Today Cupertino is announcing that PQ3—its post-quantum cryptographic protocol—will be included in iMessage. The update will launch in iOS and iPad OS 17.4 and macOS 14.4 after previously being deployed in the beta versions of the software. Apple, which published the news on its security research blog, says the change is the “most significant cryptographic security upgrade in iMessage history.”

“We rebuilt the iMessage cryptographic protocol from the ground up,” its blog post says, adding that the upgrade will fully replace its existing encryption protocols by the end of this year. You don’t need to do anything other than update your operating system for the new protections to be applied.

Quantum computing is serious business. Governments in the US, China, and Russia as well as tech companies such as Google, Amazon, and IBM are plowing billions into the (still) relatively nascent efforts to create quantum computers. If successful, the technologies could help unlock scientific breakthroughs in everything from drug design to creating longer-lasting batteries. Politicians are also vying to become quantum superpowers. The current quantum computing devices are still experimental and not practical for general use.

Unlike the computers we use today, quantum computers use qubits, which can exist in more than one state. (Current bits are either ones or zeroes). It means that quantum devices can store more information than traditional computers and perform more complex calculations, including potentially cracking encryption.

“Quantum computers, if deployed reliably and in a scalable manner, would have the potential to break most of today’s cryptography,” says Lukasz Olejnik, an independent cybersecurity and privacy researcher and consultant. This includes the encryption in the messaging apps that billions of people use every day. Most encrypted messaging apps using public key cryptography have used RSA, Elliptic Curve, or Diffie-Hellman algorithms.

Responding to the potential threat—which has been known about since the 1990s—intelligence and security agencies have become increasingly vocal about developing and deploying quantum-resistant cryptography. The National Institute of Standards and Technology in the US has been a driving force behind the creation of these new encryption types. Olejnik says tech companies are taking the quantum threat “very” seriously. “Much more serious than some older changes like switches between hash functions,” Olejnik says, adding that things are moving relatively fast given that post-quantum cryptography is still “very young” and there’s “no functional quantum computer on the horizon.”",Communications Technologies,Relevant,Relevant,
These Companies Have a Plan to Kill Apps,https://www.wired.com/story/these-companies-have-a-plan-to-kill-apps/,"In another example, Yue asks the phone to find a gift for his grandma who cannot get out of bed. It generated an interface with several products within carousels, and each row had a brief explanation of why the product might be a good fit. He settled on the Kindle.

Yue then did a long-press on the product card to ask another query: ""What is the screen made of?"" The phone generated the answer as a paragraph of text below (notably with no sources), and when he then asked to watch unboxing videos, it added a row of YouTube videos on the topic.

This wizardry is reminiscent of Siri cofounder Dag Kittlaus' onstage demo of Viv way back in 2016, which was designed to be a conversational smart layer that let users interact with various services. His live demo also included asking by voice the digital assistant to book him a hotel room in Palm Springs. Clearly mighty impressed, Samsung snapped up Viv later that same year, and we've not really seen anything of it since.

You can get a pretty good glimpse of how Brain Technologies' tech works with its app, Natural AI, which it released in 2020. Yue says his company pioneered the large action models that can enable a digital AI assistant to execute tasks. Since the company had an early start, its AI can purportedly generate interfaces for more than 4 million functions it has trained since 2016. That should cover almost anything you can do on a computing device. “Instead of going to apps, apps come to you,” he says.

But Yue doesn’t think we’re moving away from apps just yet. That’s why this concept device is still an Android phone. If you don’t want to converse with the AI, you can access apps just like normal. The touchscreen isn’t going away either, and he believes this concept is the right combination of AI and a graphical interface.

Brain Technologies has apparently already received tremendous interest from other manufacturers, and Yue says it's the only AI company the Emerson Collective (Laurene Powell Jobs' venture capital firm) has invested in. It seems almost inevitable that we'll see its generated interfaces in more kinds of devices in the future.

“Everything is app-centric,” Yue says. “We’re trying to build a human-centric future. We’re trying to give people more power in this relationship. At the end of the day, whatever the next best interface is, wins.”

Sierra, a startup developing AI-powered agents to “elevate the customer experience” for big companies including WeightWatchers, Sonos, and SiriusXM, is of a similar view, stating that, in the future, a company’s AI version of itself will be just as, if not more, important as its app or website. “It's going to completely change the way companies exist digitally,” says Bret Taylor, who left his job as co-CEO of Salesforce to start Sierra.

Human After All

The founders of A Phone, A Friend—Tomas Ramanauskas and Tomas Dirvonskas—echoed the same sentiments on making phones more personal with the help of AI. “We think that AI gives an opportunity to humanize this relationship to actually make it more human instead of just this cold, transactional, attention economy kind of thing,” Ramanauskas says.",AI,Relevant,Relevant,
Inside Finland’s state-of-the-art quantum computing hardware ecosystem,https://thenextweb.com/news/finland-quantum-computing-hardware-ecosystem,"In 1965, cryogenics pioneer Olli V. Lounasmaa set up the Low Temperature Laboratory (LTL) at what is now Aalto University to research ultra-low temperature physics. Despite some initial scepticism because “why would anyone want to research cold in Finland,” the LTL has prospered, attracting researchers from all over the world — and laying the foundation for Finland’s leading quantum computing startup ecosystem.



Quantum computing has long been the stuff of dreams. Arthur C. Clarke’s statement from the 1970s that “any sufficiently advanced technology is indistinguishable from magic,” has never felt truer than when trying to wrap one’s head around phenomena such as quantum entanglement. However, individual pieces of the puzzle are beginning to fit together at an ever-increasing pace.

Making it through the NISQ era

Before we venture any further down the quantum rabbit hole however, just a small public service announcement for those who might be wondering what exactly quantum computers, which use quantum bits, or qubits, as the basic unit of data, actually do. The truth is, not a whole lot — yet. However, their potential is nothing short of, well, magical.



If the reality the evangelists are hoping for comes to pass, quantum computers will be able to solve complex issues, including climate change, novel material engineering, new kinds of medicine, ultra-secure forms of encryption, and more. They could also literally “break the internet” on what is known as Q-Day.

“The ultimate goal would be to run some AI and accelerate that with the help of a quantum computer and that kind of system would be able to solve some questions on a, let’s say, superhuman level,” Juha Vartiainen, head of global affairs and co-founder of IQM, Finland’s – strike that — Europe’s leading quantum hardware company in superconducting circuits, tells TNW.

The <3 of EU tech The latest rumblings from the EU tech scene, a story from our wise ol' founder Boris, and some questionable AI art. It's free, every week, in your inbox. Sign up now!

“Maybe some philosophical questions about the fabric of the world, sort of with first-hand access to the quantum realm,” he muses. So basically, the ultimate questions of Life, the Universe, and Everything.

But this is something like quantum utopia. Quantum technologies, and in particular quantum computers, are still in their infancy. Startups looking to carve out a niche in the field need to find means of financially surviving what is called the NISQ-era. This stands for Noisy Intermediate-Scale Quantum, and refers to the current state of high error rates and limited number of qubits.

It is considered a time of exploration and learning, more than one of actual commercial application. In turn, this means that it is difficult for investors to cash in on the promises of the technology within a customary time span.

“We are the camel startups,” says Himadri Majumdar, founder and CEO of SemiQon, a company building silicon-based semiconducting quantum processors. “We take it slow, but at a steady pace.”

SemiQon, a spinout from Finland’s state-owned non-profit ​​research organisation VTT, has been able to leverage both private and public funding, Majumdar explains. “What we are trying to do is to demonstrate in cycles how we can get to the scalability aspect with every iteration of fabrication that we do.”

The geopolitical quantum realm

Due to the difficulty in attracting capital, the edge in quantum computing mostly belongs to countries with governments ready to spend on what they believe will give them a leg up economically — or geopolitically — in the future. In 2022, China poured $15.3bn into the technology, followed by only $1.8bn from the US government, and $1.2bn from the EU.

The quantum computing market, worth $9.3bn in 2022, is expected to grow to $203.1bn by 2032. Companies with significant quantum projects include tech giants like IBM, Google Quantum AI, Amazon, and Microsoft. And yet, a small country in the Nordics has built a world-leading quantum technology ecosystem — including a company without which there would be no quantum computers at all.



“From our point of view, the story has only started,” says Jonas Geust, CEO of Bluefors, the global market leader for what are essentially quantum computer refrigerators. These are the golden “chandeliers” keeping the qubits chilled. They are a requirement for today’s superconducting qubits to function, and entirely synonymous with quantum computers in the mind of the broader public.



Although, as quantum computing systems begin to scale, that might change. Bluefors’ biggest “fridge” to date is KIDE, built to support a 1,000 qubit system (such as IBM’s Quantum Condor chip). KIDE is structurally different in the sense that it’s standing on the floor, rather than hanging from the ceiling.



It is also a hexagon, where you can remove one of the doors, and then put another KIDE next to it, interlinking several quantum computers. “We are looking at how to build the scalability in terms of varying industrial needs,” Geust adds. “We are working on what our customers will need in five years from now and the actual implementations that are still ahead of us.”



Bluefors was founded in 2008 by Rob Blauwgeers and Pieter Vorselman. It now employs 600 people, has a revenue of over €160mn, and considers the US “its second home.” The company is also exploring other applications for its cryogenic technology, such as cooling for sensitive sensors for astrophysics, hydrogen storage, and basic material science.

Near-term quantum computer utility vs. million-qubit era

Other quantum hardware startups are also defining revenue generating applications. IQM, for instance, has begun supplying research institutes with smaller scale qubit systems, on which tomorrow’s quantum engineers can learn to read and handle qubits. The company launched in 2018, and in 2022 it raised €128mn in Series A2 — the largest ever funding round raised by a European quantum computing company.



The company’s first product is the “affordably priced” 5-qubit IQM Spark. “Quantum education has historically been available to only very few physicists,” Vartiainen says. “And this was fine, because not that many quantum physicists were needed. But now things have changed, and very suddenly.”

The idea behind Spark is that “students can use it and play with it and run physics simulations, very fundamental discoveries of quantum physics, and run some simple algorithms and learn how a quantum computer works,” Vartiainen explains.



IQM is also getting ready to ship its larger system Radiance, ranging from 54 to 150 qubits, which it says will “pave the way” to quantum advantage (when a quantum computer can demonstrably solve a problem no classical computer can), helping businesses train on and navigate smaller systems before larger ones become commercially available.



IQM has found a commercial niche as it helps train scientists with the quantum technology available now, using superconductors that require large refrigerating apparatuses. SemiQon on the other hand is building its semiconducting quantum chips that are much less affected by temperatures for “the million qubit era.”



“What we were doing at VTT was based on superconductors. So we were building superconductor-based quantum computers. But we also had this capability of doing semiconductor-based quantum processors or quantum computing devices,” Majumdar says. “And that was more interesting for me personally, because semiconductors are scalable, they are affordable, and the technology has a much bigger prospect of scaling.”

The strength of the Finnish ecosystem and finding talent

Beyond academic traditions, what are the foundations on which Finland has built this leading quantum business container? “One thing is that it’s quite concentrated,” IQM’s Vartiainen says. “Actually, it’s quite a small area — within maybe a radius of two, three kilometres, there are quite a lot of quantum players.”



“There is a lot of know-how in this ecosystem,” Majumdar emphasises. “This means that we can find solutions, or persons who have the solutions, relatively easily and quite quickly compared to other places.”



Access to facilities and government-supported infrastructure, such as those at VTT just outside Helsinki, are also essential for startups working in fields like quantum. “If you need a measurement facility for a specific, very niche measurement, you find it here. And you don’t have to go far,” Majumdar says.

For its part, Bluefors works actively with universities and takes on many summer trainees. Indeed, partnership seems to be the key also for solving workforce-related issues. When looking for micro-engineering skills, for instance, the company turned to its neighbours at the Finnish School of Watchmaking.

When asked about the difficulty in finding talent for such high-skilled work, Geust states that: “It’s a continuous challenge. I think this is what anybody working with new technologies is experiencing.”

Then he utters what seems to summarise the Finnish ethos, and perhaps in part also explains how this ecosystem has managed to punch above its weight in attracting both talent and foreign investment. “On the other hand, I sort of come from the school that it doesn’t help complaining, you know — we just need to do a better job.”

We are still some way away (not even experts can agree on exactly how far) from quantum supremacy. We still need to observe, learn, tinker, and, quite possibly, dream enough for that day to become a reality. But until then, quantum computers will be able to work in conjunction with classical computers, running highly specific simulations.

This is very much being explored in the quantum software engineering realm, a whole other chapter in the quantum saga, which we will feature in another story.",Quantum Computing,Relevant,Relevant,
"New AI and 5G advancements will usher in the era of edge computing on smartphones, autonomous cars, and more",https://www.businessinsider.com/ai-edge-computing-5g-cloud-artificial-intelligence-2024-3,"The AI boom is breathing life into edge computing, which moves data processing away from the cloud.

The edge-computing boom could reduce costs and the environmental impact of powering AI.

This article is part of ""5G and Connectivity Playbook,"" a series exploring some of our time's most important tech innovations.

NEW LOOK Sign up to get the inside scoop on today’s biggest stories in markets, tech, and business — delivered daily. Read preview Thanks for signing up! Access your favorite topics in a personalized feed while you're on the go. download the app Email address Sign up By clicking “Sign Up”, you accept our Terms of Service and Privacy Policy . You can opt-out at any time.

Artificial intelligence is driving us into the era of edge computing — two words you should expect to hear more in the coming months and years.

Tech giants have poured billions of dollars into the cloud and spent years trying to get customers to move data onto remote servers. Now they're expanding to edge computing, which refers to moving more of the computation closer to the user (the ""edge"" of the network).

Whether it's your smartphone, an autonomous car, or a security device in your home, edge computing means more of the heavy lifting happens on or near the device. That change could lead to lower latency, lower energy costs, and improved privacy and security as less sensitive information gets beamed to some far-flung server.

The concept behind edge computing is nothing new, but the AI gold rush and improvements to 5G make it a perfect time for the space to take off. 5G lets devices on the edge communicate with one another and the cloud. While 5G had a slow and messy start, recent advancements could prove a shot in the arm for edge computing, which will require data connections to run seamlessly.

Amazon had eyed edge computing as a billion-dollar business, Business Insider previously reported. The buzz around AI and its potential for edge computing also ignited talk at the Mobile World Congress, held in Barcelona last month.

Jim Poole, the vice president of global business development at Equinix, said at an MWC panel that the move toward edge computing is accelerating in part because of the AI boom, which requires much more data to be processed.

""Data gravity is a real thing,"" Poole said. ""At some point, it becomes financially and physically impossible to transmit that data all the way back to someplace else.""

The latency benefits of edge are crucial with technologies such as driverless cars, which need to make split-second decisions. That's why autonomous vehicles have powerful computers that live on the vehicle itself. The same goes for medical equipment or devices used in dangerous types of manufacturing, where more computing needs to be done on the fly.

The China International Import Expo in Shanghai. Aly Song/Reuters

AI accelerates edge computing

The industry has already seen some benefits of edge in smartphones, with a push to create better chips and software to allow more AI horsepower onto devices. This will also require AI companies to launch smaller language models that can run on less powerful devices.

The Taiwanese chip company MediaTek had one of the most impressive demos at MWC this year: a smartphone-like device running a generative image maker powered by a Stable Diffusion AI model, which created and edited pictures in real time.

Lenovo, which was also at the show, is making a big enterprise play by selling its ""edge AI"" servers to businesses and has plans to make moves in edge for consumers, Tom Butler, the executive director of Lenovo's laptop line, told BI.

""If you think of bringing in generative workloads to device, first of all, I solve for time, security, and privacy, because I'm not pushing up to cloud and back down,"" he said.

Edge computing could save energy

Shifting AI closer to the user could have cost benefits for tech companies like OpenAI, Google, and Amazon, which run AI models on their servers at great expense.

Edge computing could also have environmental benefits. The data centers that power AI in the cloud use an enormous amount of water and energy.

Jillian Kaplan, the head of global 5G at Dell, said during an MWC panel that edge computing will be a ""huge energy saver.""

"" I think the sustainability topic has come and gone throughout the years,"" Kaplan said.

""I don't think it's going to fluctuate again,"" she added. ""I think, where we are, it has to stay top of mind, and these edge and AI capabilities are going to help us keep our equipment extremely energy efficient, which we have to do with the massive amounts of data coming in.""",AI,Relevant,Relevant,
Seeking nominations for the top creative agencies harnessing generative AI,https://www.businessinsider.com/seeking-nominations-for-the-top-ad-agencies-harnessing-generative-ai-2024-2,"Business Insider is seeking nominations for a list showcasing the creative agencies that have mastered generative AI technologies and are using them to produce consumer-facing work.

Advertisement

Please submit your nominations using this form.

Over the last year, ad agencies have taken big steps familiarizing themselves with generative AI tools — and they've become much more adept at harnessing the nascent technology for their clients' creative work. Even still, the tech continues to evolve with eye-popping results, as seen by OpenAI's new Sora video generation tool.

While many agencies have built generative AI into their behind-the-scenes workflows, we're looking for agencies, both big and small, that have used it to develop the copy and art that consumers have seen. These agencies should have already helped create campaigns using generative AI that are in the wild.

We are not looking for agencies who use AI to optimize online ad placements, use it mostly for internal processes, or do not have work to show that incorporates generative AI. In other words: We want loads of examples of existing campaigns using generative AI.

Advertisement

We plan to publish the list in April.",AI,Relevant,Relevant,
The 4 Big Questions the Pentagon's New UFO Report Fails to Answer,https://www.wired.com/story/questions-pentagon-ufo-report/,"But what, then, were those programs? Herein lies the most intriguing—and potentially ground-breaking—question that the Pentagon study leaves us wondering: What exactly are the secret compartmentalized programs that the whistleblowers and government witnesses misidentified as being related to UAP technology? What, exactly, are the Pentagon, intelligence community, or defense contractors working on that, from a concentric circle or two away inside the shadowy world of SAPs, looks and sounds like reverse-engineering out-of-this-world technology or even studying so-called “non-human biologics”?

There are at least four clear possibilities.

Secret Tech From Foreign Nations

First, what exotic technological possibilities have been recovered from unknown terrestrial sources? For example, if the government is working on reverse-engineering technologies, those technologies are likely from advanced adversary nation-states like China, Russia, and Iran, and perhaps even quasi-allies like Israel that may be more limited in their technology-sharing with the US. What have other countries mastered that we haven’t?

A Question of ‘Peculiar Characteristics’

Second, what technologies has the US mastered that the public doesn’t know about? One of the common threads of UFO sightings across decades have been secret military aircraft and spacecraft in development or not yet publicly acknowledged. For example, the CIA estimated that the U-2 spy plane in the 1950s accounted for as much as half of reported UFO sightings. And the AARO report spends a half-dozen pages documenting how confusion over subsequent generations of secret US government aircraft appear to have also contributed to the great intergalactic game of telephone of UFO programs inside the government, including modern Predator, Reaper, and Global Hawk drones. AARO investigated one claim where a witness reported hearing a former US military service member had touched an extraterrestrial spacecraft, but when they tracked down the service member, he said that the conversation was likely a garbled version of the time he touched an F-117 Nighthawk stealth fighter at a secret facility.

There are surely other secret craft still in testing and development now, including the B-21 stealth bomber, which had its first test flight in November and is now in testing at Edwards Air Force Base in California, as well as others we don’t know about. The government can still surprise us with unknown craft—like the until-then-unknown modified stealthy helicopter left behind on the Pakistan raid to kill Osama bin Laden. And some of these still-classified efforts are likely causing UFO confusion too: AARO untangled one witness’s claim of spotting a UAP with “peculiar characteristics” at a specific time and place and were able to determine, “at the time the interviewee said he observed the event, the DOD was conducting tests of a platform protected by a SAP. The seemingly strange characteristics reported by the interviewee match closely with the platform’s characteristics, which was being tested at a military facility in the time frame the interviewee was there.” So what was that craft—and what were its “peculiar characteristics?”

Relatedly, the US military has a classified spaceship, the X-37B, that has regularly orbited around the Earth since its first mission in 2010—it just blasted off on its seventh and most recent mission in December—and its previous, sixth, mission lasted a record-breaking 908 days in orbit. The Pentagon has said remarkably little about what it does up there for years at a time. What secret space-related or aviation-related programs is the government running that outsiders confuse as alien spacecraft?

A Material Matter

The third likely area of tech development that might appear to outsiders to be UFO-related is more speculative basic research and development: What propulsion systems or material-science breakthroughs are defense contractors at work on right now that could transform our collective future? Again, AARO found such confusion taking place: After one witness reported hearing that “aliens” had observed one secret government test, AARO traced the allegation back to find “the conversation likely referenced a test and evaluation unit that had a nickname with ‘alien’ connotations at the specific installation mentioned. The nature of the test described by the interviewee closely matched the description of a specific materials test conveyed to AARO investigators.” So what materials were being tested there?

There are some puzzling materials-science breadcrumbs wrapped throughout the AARO report. It found one instance where “a private sector organization claimed to have in its possession material from an extraterrestrial craft recovered from a crash at an unknown location from the 1940s or 1950s. The organization claimed that the material had the potential to act as a THz frequency waveguide, and therefore, could exhibit ‘anti-gravity’ and ‘mass reduction’ properties under the appropriate conditions.” Ultimately, though, the new report concluded, “AARO and a leading science laboratory concluded that the material is a metallic alloy, terrestrial in nature, and possibly of USAF [US Air Force] origin, based on its materials characterization.”

A Knowledge Limit

Fourth and lastly is the category of the truly weird: Scientists at the forefront of physics point out that we should be humble about how little of the universe we truly understand; as Harvard astronomy chair Avi Loeb explains, effectively all that we’ve learned about relativity and quantum physics has unfolded in the span of a single human lifespan, and astounding new discoveries continue to amaze scientists. Just last summer, scientists announced they’d detected for the first time gravitational waves criss-crossing the universe that rippled through space-time, and astrophysicists continue to suspect that the universe is far weirder than we think. (Italian astrophysicist Carlo Rovelli last year posited the existence of “white holes” that would be related to black holes, which, he pointed out, were still a mystery just 25 years ago when he was starting his career.)

Answers here could be almost unfathomably weird—think parallel dimensions or the ability to travel at a fraction of the speed of light. And one of the most intriguing questions left by the UAP “game of telephone” is whether there are truly astounding advances in physics that government scientists, defense contractors, or research laboratories or centers could be feeling around that could also appear from the outside to be UFO-related.",General,Relevant,Irrelevant,
"This startup taps quantum, AI to fast-track discovery of new materials",https://thenextweb.com/news/this-startup-taps-quantum-ai-to-fast-track-discovery-of-new-materials,"From batteries and semiconductors to energy storage, the transition to green technologies requires the development of new, sustainable materials at an unprecedented pace.

German startup Quantistry believes it can fast-track the discovery of such materials using a mix of quantum tech, physics-based simulations, and machine learning. By automating the process, it looks to sidestep the “high costs, fragmented expertise, and slow innovation” inherent to classical R&D.

Quantistry has developed a cloud-based platform powered by small-scale quantum computers and AI, that allows users to determine material and molecular properties in simulation, rather than in real-life. This removes much of the trial and error in material discovery, enabling companies to focus on developing those materials with the most promise from the outset.

In a vote of confidence for the budding company, it has just bagged €3mn in funding, which includes backing from Chemovator, the business incubator of German chemical giant BASF.



The investment round is led by Ananda Impact Ventures, one of the oldest and most established European impact funds. Quantistry will use the cash to further develop its simulation platform and secure new customers.

The <3 of EU tech The latest rumblings from the EU tech scene, a story from our wise ol' founder Boris, and some questionable AI art. It's free, every week, in your inbox. Sign up now!

Marcel Quennet, CEO of Berlin-based Quantistry, said the company isn’t just looking to speed up industrial R&D, but also make it more accessible to companies who may not have the budget for more traditional, labour-intensive methods.

“It’s clear: simulations not only transform the industrial R&D landscape but also steer it towards a greener future — yet, they remain out of reach for many. Together, we’re democratising this technology, shaping the future of chemical R&D and materials science,” said the co-founder, who holds a PhD in Quantum Chemistry.

Quantistry’s new funding round comes amid a surge in AI investment, as companies tap machines to accelerate the development of everything from medical treatments to fusion energy.

The German startup isn’t the only one using AI to speed up material discoveries either. Google DeepMind recently unveiled a deep learning tool that predicted the structure of over 2.2 million crystalline materials — 45 times more than the number discovered in the entire history of science.

Quantistry was founded in 2019 by Quennet and co-founders Arturo Robertazzi, computational chemist and science communicator, and Stefan Kupferberg, finance expert and serial entrepreneur.",Green Computing,Relevant,Relevant,
The UK is improving productivity through new technologies and industrial digital transformation,https://www.businessinsider.com/sc/how-the-uk-is-helping-the-manufacturing-sector-improve-productivity,"In 2018, the UK government launched the Made Smarter Adoption pilot program to provide manufacturing SMEs in the North-West of England with impartial expert advice , training, and financial support.

Following its success, the program has been extended to an additional four English regions with the aim of helping the UK recapture its industrial spirit.

In FY2025/26, the UK government has committed to spending up to £16 million to extend the scheme to the whole of England.

In 2017, an independent review board led by Jurgen Maier, then CEO of Siemens UK, made a startling proposal: If UK businesses adopted digital technology at a faster rate, the country's industrial productivity could increase by a remarkable 25%. What's more, digital adoption could reduce greenhouse gas emissions by 4.5% over the next decade.

The Made Smarter review took place to address the country's 'productivity puzzle,' and support businesses to create well-paid jobs and reduce their environmental footprint.

Adopting digital technologies — such as artificial intelligence, robotics, data analytics, and additive manufacturing — has helped early adopter businesses to transform their productivity, and the Made Smarter review illustrated what UK's manufacturing sectors could gain from following their lead, such as:

Increasing productivity by at least 25%, output by £455 billion, and manufacturing sector growth by up to 3% per year

Raising exports through international competitiveness

Strengthening UK supply chains and creating new value streams

Addressing regional economic disparities

Creating 175,000 jobs

Upskilling one million industrial workers

Reducing CO2 emissions by 4.5%

Its report called for the UK to recapture its industrial spirit as a nation of 'creators and makers,' focusing on small-to-medium enterprises, the lifeblood of the country's economy. In response, the UK government launched the Made Smarter Adoption pilot program in 2018, providing manufacturing SMEs in the North-West of England with impartial expert advice, match-funded grants, leadership and skills training, and digital interns. By 2022, four additional English regions had been added to the program following the success of the pilot.

Unprecedented demand drives adoption

Using funding from Made Smarter, protein bar manufacturer Nutree Life invested in state-of-the-art automation technologies to respond to the growing popularity of vegan and plant-based products.

Automation enabled Nutree Life's production to be high volume, high speed, and accurate. Crucially, the increased productivity and manufacturing capacity enabled Nutree Life to cope with the upsurge in demand.

The business, which is co-owned by Patrick Mroczak and his son-in-law Adam Hodgkinson, is now on target to almost quadruple its revenue, from £1.2m to £4m, and has doubled its workforce since the start of the year.

""When we approached Made Smarter for help with upgrading our production process, I never imagined that we'd achieve so much so fast,"" Patrick said. ""It has given us the platform and the confidence to take that next step to secure business growth.""

Investment can fund expansion into new markets

As one of only two cycle clothing companies that manufacture their products in the UK, Lusso is replacing manual production processes with an Auto CAD and CAM system.

""The financial support has made a transformational impact on the production side of the business,"" said Jake Wright, Lusso's managing director. ""The CAD software has enabled us to refine our patterns, so they are more accurate and anatomical, resulting in a more efficient sewing stage of production and better fitting finished garments. We are also able to operate on a larger scale, accelerating the cutting process by up to 80% and increasing productivity by 400%.""

Lusso has always proudly manufactured their products in the UK and Wright says this has been at the heart of the business since its inception in 1982.

""We strongly believe that sustainable production practices should be followed as standard, not just for marketing purposes. By manufacturing in-house, we have a very stable supply chain with a low carbon footprint,"" Wright said.

Transformative technology powers innovation

Leading puppeteers Mackinnon & Saunders collaborated with top Hollywood director Guillermo del Toro to manufacture the miniature stars of the Oscar-winning film ""Pinocchio."" Using match-funding from Made Smarter, they developed a world first: a puppet made using 3D-printed stainless steel. This meant transitioning from the traditionally engineered methods to more technically advanced techniques to develop the fragile Pinocchio puppet. Metal printing technologies enabled the company to maintain the strength of the original puppet parts, and the funding paid for 25 stainless steel puppets used for the duration of filming, speeding up the stop-motion process.

The Mackinnon & Saunders puppet for Pinocchio was developed with the help of funding from Made Smarter. Netflix / Mackinnon & Saunders

""Without this backing, we would not have had the resources to conduct research and development, which is key to keeping us at the forefront of this industry,"" said cofounder Peter Saunders. ""The financial support was critical to both the growth and survival of the company.""

The 3D printing enabled by the funding has been a game changer for his company. ""We've adopted this printing technique throughout the business, and we anticipate this technology will be widely adopted within the animation industry,"" Saunders said.

Extending Made Smarter to other areas of the UK

""Over 4,000 manufacturing SMEs have registered on Made Smarter to date, and over 600 industrial digital technologies projects have received grant funding,"" said Michael Clark, Deputy Director of Advanced Manufacturing at the UK's Department for Business and Trade. ""Long term, our objective is to boost UK growth and productivity, through increasing innovation and adoption of industrial digital technologies across the whole of manufacturing.""

Over the financial year 2025-26, the UK government has committed to spending up to £16 million to offer the scheme to all regions in England, before working with the devolved administrations to explore expanding the programme further from 2026-27, as part of the UK's Advanced Manufacturing Plan to seize the opportunities of the twin transitions of net zero and digitalization. ""Our ambition is for the UK to be the best place in the world to start and grow a manufacturing business,"" Clark said.

Learn more about how the UK can support your manufacturing business.

This post was created by Insider Studios with the UK Department for Business and Trade.",General,Relevant,Irrelevant,
Microsoft to pump €3.2B into German AI technologies,https://thenextweb.com/news/microsoft-german-ai-investment,"Microsoft will invest €3.2bn in AI tech in Germany over the next two years, the firm’s vice chair Brad Smith announced today.

The investment will see the doubling of Microsoft’s AI and data centre infrastructure capacity in Germany, said Smith. It marks the largest single investment in Microsoft’s 40-year history in the EU country.

German Chancellor Olaf Scholz welcomed the move, noting that it signifies a vote of confidence for Europe’s largest economy.

While the American software giant refrained from specifying the exact locations of the investments, its CEO for Germany, Marianne Janik, mentioned a focus on the western Rhineland region and the vicinity of the banking hub of Frankfurt.

In these regions, Microsoft would be close to major customers, such as the pharmaceutical company Bayer AG and energy company RWE. This would help to keep data latency between data centres and applications as low as possible.

AI training for over 1 million people

While Germany is one of the world’s leading technology powerhouses, it suffers from a lack of AI skills, said Smith. In response, the investment will include a programme for training up to 1.2 million people in new AI capabilities.

Microsoft’s outlay would “help build out infrastructure to help the German economy continue its use of AI and build out the skill base to fill the jobs required,” according to the company’s vice chair.

The move tops the list of the tech giant’s largest foreign investments. Last year, the firm pumped $3.14bn and $3.25bn into the UK and Australia respectively.

While more details will surely emerge in coming weeks, the big play by Microsoft comes at a time of significant growth for Germany’s AI ecosystem.

In November, Heidelberg-based startup Aleph Alpha raised $500mn in one of Europe’s largest AI rounds ever, while in the same month the German government pledged €1.6bn for the development of the technology.

While the investments made by Germany — and the EU for that matter — pale in comparison with the huge sums being doled out in the US and China, the region’s strength could be in quality over quantity.

This mindset is embodied in the startups themselves. While giants like OpenAI have been heavily criticised for creating AI models based on troves of copywritten data scraped from the web, the likes of Aleph Alpha and France’s Mistral AI focus on creating accountable, fair AI models for businesses and governments.",AI,Relevant,Relevant,
OPPO debuts its 'AI Center' as it prepares to bring Gen AI to the Reno 11,https://www.androidcentral.com/apps-software/oppo-introduces-ai-center,"What you need to know

OPPO announced in a press release that it has created an ""AI Center,"" capable of bringing generative AI features to its devices as it looks to the future.

OPPO plans to bring generative AI features to its Reno 11 series in Q2 2024 once it launches globally.

Such features include the OPPO AI Eraser and more, which may benefit from the brand's LLM, AndesGPT.

OPPO is prepared to take on artificial intelligence on smartphones by introducing its new ""AI Center."" According to a press release, the company states, ""Through dedicated research and development into AI and its applications, the new Center aims to further strengthen OPPO’s AI capabilities."" OPPO is also focused on ""exploring"" features that act on behalf of the user experience.

OPPO's new AI Center is said to create generative AI features that embody a few key characteristics for its AI phones. A device must ""efficiently utilize"" computing resources for Gen AI while being aware of real-world time using its sensors and ""understanding the complex information"" users give it.

The company added an AI phone from its kitchen that must contain self-learning capabilities and ""multimodal"" content generate abilities for ""inspiration and knowledge support.""

OPPO aims to ""revolutionize"" the industry, and this all begins in Q2 2024 as it plans to bring ""advanced"" generative AI features to the Reno 11 series.

The Chinese OEM states that ""an array"" of features will appear in the series when it launches globally. Such features include OPPO AI Eraser and more. OPPO adds the arrival of its generative AI features will vary depending on the market release of its Reno 11 series.

Its upcoming devices may also leverage the brand's custom large language model, AndesGPT. After launching the Find X7 series, OPPO's model is said to handle ""dialogue enhancement, personalization, and cloud-device collaboration.""

(Image credit: OPPO)

Pete Lau, chief product officer of OPPO, said, ""OPPO is dedicated to becoming a contributor and promoter of AI Smartphones. We look forward to working together with our industry partners to jointly drive the innovation of the mobile phone industry and reshape the intelligent experience of mobile phones.""

The company states it plans to expand its range of generative AI features to more product lines and markets around the world. Moreover, OPPO appears confident that its AI Center will ""enhance"" and complement its app ecosystem present on devices.

The post mentions OPPO will open a development platform so those creating new technologies for its devices can have access to all the AI tools they require.",AI,Relevant,Relevant,
White House urges tech companies to adopt secure program languages,https://readwrite.com/memory-safe-white-house-urges-major-tech-companies-to-adopt-secure-programme-languages/,"The White House Office of the National Cyber Director (ONCD) has urged the largest players in emerging technologies to adopt safer programming languages.

The advice was released as part of a new report titled “ Back to the Building Blocks: A Path Toward Secure and Measurable Software .”

The ONCD stated, “method manufacturers can use to reduce memory safety vulnerabilities is to secure one of the building blocks of cyberspace: the programming language. Using memory-safe programming languages can eliminate most memory safety errors.”

What is the Office of the National Cyber Director (ONCD)?

The ONCD advises the President of the United States on matters of cybersecurity policy, and strategy and highlights any concerns in this space. The security entity spans all U.S. government departments, private companies, and international partners to coordinate federal cybersecurity policy.

“The challenge of eliminating entire classes of software vulnerabilities is an urgent and complex problem,” The new report would state.

“It is a path that requires the convergence of government initiative, private sector innovation, and groundbreaking academic research. Working together to proactively eliminate software vulnerabilities alleviates the burden from those least equipped to bear it, and empowers front-line cyber defenders to look forward. Defining high-quality cybersecurity realigns incentives and provides confidence in what cyberspace can be.”

The Biden-Harris Administration has received recognition from industry leaders for this decision to reaffirm the vulnerabilities that must be considered in lockstep with technological advancements.

The ONCD would post on the official X page about the clamor of support from members of academia and the private sector about the White House’s direction:

In support of our report calling for a memory safe future, we have received an incredible response with statements of support from a variety of companies, academic experts, and leaders in civil society. Join us!https://t.co/N725GaEoPa — Office of the National Cyber Director (@ONCD) February 26, 2024

Fidelma Russo, Executive Vice President and General Manager, Hybrid Cloud and Chief Technology Officer at Hewlett Packard Enterprise said, “we commend Director Coker and the Administration for this initiative, which is an important response to the ever-evolving cyber threat landscape. Memory-safe computing prevents vulnerabilities before they can be exploited by threat actors, and will be a new internal standard at HPE for cloud-native development.”

Professor of Computer Science at Stanford University, Dan Boneh commented that the “White House is taking a pragmatic approach, and is proposing to start this conversion with critical space systems, which is a good testing ground for the proposed approach. Preventing memory safety bugs is only the beginning of a long journey towards more secure software.”

“We, as a nation, have the ability – and the responsibility – to reduce the attack surface in cyberspace and prevent entire classes of security bugs from entering the digital ecosystem but that means we need to tackle the hard problem of moving to memory-safe programming languages,” National Cyber Director Harry Coker would say.

Featured image: Pexels",General,Relevant,Irrelevant,
Saudi Arabia to invest $100bn to create advanced robotics industry,https://readwrite.com/saudi-arabia-to-invest-100bn-to-create-advanced-robotics-industry/,"Saudi Arabia is set to see a $100 billion investment over the next six years, with an aim to become a leader in the field of electronics and advanced industrials.

On February 1, 2024, the country’s Public Investment Fund company Alat was launched. Four partnerships and the news of major investment have now been revealed.

In an announcement today via press release (Feb 20) $100 billion will be invested by 2030. This will go towards enhancing the “capabilities of the technological sector, benefitting from the rapid development of this sector in Saudi Arabia.”

Alat will be partnering with Softbank Group, Carrier Corporation, Dahua Technology Ltd, and The Saudi Technology and Security Comprehensive Control Company (Tahakom).

The Global CEO of Alat Amit Midha said: “In conjunction with our international and regional partners, the first four of which we proudly announce today, we will redefine sustainable manufacturing.

“Alat’s mandate is focused on harnessing the Kingdom´s solar, wind and green hydrogen clean energy.

“We are passionately using technology to transform businesses, leveraging cutting-edge AI technology and fourth-industrial revolution technologies for manufacturing. This is not only using clean energy but applying sustainability measures to all our operations, buildings, logistics and supply chain, with sustainability at the core of everything we do.”

According to its website, these plans will contribute $9.3 billion to non-oil GDP by 2030 and create 39,000 direct jobs.

Global partnerships

Alat’s global partnership with the Softbank Group will include a $150 million investment to set up a fully automated manufacturing and engineering hub that will serve local and global demand. The aim is for the manufacturing plant to be open by December 2024.

The agreement with Carrier Corporation includes the development of a manufacturing and R&D center, expected to create more than 5,000 local jobs.

Alat and Dahua Technology Ltd will invest $200 million to establish a secure and compliant global business for vision-centric products, called Alat AlVisio Technology Co. Ltd., and a manufacturing facility in Saudi Arabia.

The fourth partnership, with The Saudi Technology and Security Comprehensive Control Company (Tahakom), will involve collaboration on solution designs, product specifications, and more, as well as building technology roadmaps and client and vendor relationships.

Featured image; Photo by Louis Reed on Unsplash



",General,Relevant,Irrelevant,
"AI Is Coming for the Experts. First, It Needs Their Help",https://www.wired.com/story/remotasks-ai-expert-data-labor/,"Jay fell in love with math at boarding school after a supportive physics teacher introduced him to the joy of complex calculus. He went on to study physics and math in college, hoping to one day similarly pass on what he’d learned to a new generation. That chance came in October 2022, when 25-year-old Jay answered a job listing seeking a math expert to grade equations through an online platform. But he would not be inspiring budding young mathematicians like his past self. He would instead be training an artificial intelligence system that may eventually make his expertise obsolete.

According to Jay, who asked to use a pseudonym to protect his privacy, the system he was schooling had been built by a company soon to be a household name: OpenAI. His job was to act as an expert guide for the company’s large language model—a machine-learning system that can convey information in a conversational format, like a chatbot—as it tried to improve its math. From his home in Portugal, he would tell the model if it was taking the right steps to solve math problems, adding thumbs up or thumbs down emojis to AI-generated answers, and sometimes writing out explanations about why the AI had gone wrong.

Jay says he knew he was training algorithms for the company overseen by Sam Altman because he was invited to join the OpenAI workspace in Slack. A screenshot he shared with WIRED shows he was part of a group, called “math trainers,” that was set up by the OpenAI researcher Yuri Burda. But Jay was not working directly for the famous AI company. Instead he was being paid by one of the world’s biggest data labor platforms, called Remotasks, a subsidiary of US startup Scale AI, which was valued at over $7 billion back in 2021 and counts OpenAI, Meta, Microsoft, and the US Army among its clients.

Scale AI works closely with its clients to provide and curate the training data they need to build up the AI models behind self-driving cars or large language models. Often, that data ultimately derives from people contracted to Remotasks—which has, according to its website, signed up hundreds of thousands of workers since it launched in 2017. Much of that workforce has been concentrated in countries that offer relatively cheap labor, like the Philippines, where Remotasks says its recruits mostly train computer vision for autonomous vehicles, helping self-driving cars recognize the shapes around them. But in the past year, the company claims the geography of Remotasks’ workers has shifted to the United States and Europe, as it searches for white-collar skills and language specialists to train large language models—fueling concern that these people are essentially training themselves out of a job.

Jay is thoughtful about his role in the future of work. “It’s true,” he says. “I am passing on knowledge that I have and that the machine does not have.” He’s aware that AI models still struggle to replicate the ingenuity with which humans solve complex math problems. But he’s hoping the work he did will help create AI that can benefit, not replace, him—envisioning a future where he could practice algebra or calculus with a chatbot who can match his level. “That's kind of what I was picturing, when I started training these.”

Willow Primack, VP of data operations at Scale AI, says that Remotasks and others are turning to subject matter experts for data labor in response to the major shift in the applications of AI systems, as these systems start to produce knowledge and content. As the tech industry has rushed to embrace generative AI over the past year and applied it to more sophisticated tasks, data providers have needed a new intake of contractors capable of what Primack calls “expert fact-checking.”",AI,Relevant,Relevant,
Nikon buys high-end cinema camera company RED,https://www.engadget.com/nikon-buys-high-end-cinema-camera-company-red-100243796.html,"Nikon has announced it is buying RED, the high-end cinema camera company, for an undisclosed sum. In a statement, the camera giant, which has suffered along with most of the imaging industry in recent years, said RED will become a wholly-owned subsidiary, as found by The Verge. RED currently has about 220 employees, and no layoff plans have been made public in response to the sale.

RED was founded in 2005 and has since had its cameras used in popular productions, including Squid Game, Peaky Blinders and Captain Marvel — a market Nikon plans to expand into with this acquisition. Nikon has withdrawn from less profitable areas of the camera market in recent years, including ending development on new DSLRs

The move could benefit both parties, as RED's president Jarred Lang shared on Facebook: ""This strategic partnership brings together Nikon's extensive history and expertise in product development, know-how in image processing, as well as optical technology and user interface with RED's revolutionary digital cinema cameras and award-winning technologies."" RED's 2018 attempt to expand on its own (into smartphones, no less) didn't last long, and the products soon were discontinued.

Interestingly, RED sued its new owner in 2022, claiming that Nikon knowingly used RED's patented data compression technology in its Z9 camera. Nikon, in turn, argued the legitimacy of RED's patents before the two companies agreed to a dismissal.",General,Relevant,Irrelevant,
Google fires engineer who protested at a company-sponsored Israeli tech conference,https://www.engadget.com/google-fires-engineer-who-protested-at-a-company-sponsored-israeli-tech-conference-090430890.html,"Google has fired a Cloud engineer who interrupted Barak Regev, the managing director of its business in Israel, during a speech at an Israeli tech event in New York, according to CNBC. ""I'm a Google software engineer and I refuse to build technology that powers genocide or surveillance!"" the engineer was seen and heard shouting in a video captured by freelance journalist Caroline Haskins that went viral online. While being dragged away by security — and amidst jeers from the audience — he continued talking and referenced Project Nimbus. That's the $1.2 billion contract Google and Amazon had won to supply AI and other advanced technologies to the Israeli military.

Last year, a group of Google employees published an open letter urging the company to cancel Project Nimbus, in addition to calling out the ""hate, abuse and retaliation"" Arab, Muslim and Palestinian workers are getting within the company. ""Project Nimbus puts Palestinian community members in danger! I refuse to build technology that is gonna be used for cloud apartheid,"" the engineer said. After he was removed from the venue, Regev told the audience that ""[p]art of the privilege of working in a company, which represents democratic values is giving the stage for different opinions."" He ended his speech after a second protester interrupted and accused Google of being complicit in genocide.

A Google Cloud engineer just interrupted Google Israel managing director Barak Regev at Israeli tech industry conference MindTheTech this morning in NY.



“I refuse to build technology that powers genocide!” he yelled, referring to Google’s Project Nimbus contract pic.twitter.com/vM9mMFlJRS — Caroline Haskins (@car0linehaskins) March 4, 2024

The incident took place during the MindTheTech conference in New York. Its theme for the year was apparently ""Stand With Israeli Tech,"" because investments in Israel slowed down after the October 7 Hamas attacks. Haskins wrote a detailed account of what she witnessed at the event, but she wasn't able to stay until it wrapped up, because she was also thrown out by security.

The Google engineer who interrupted the event told Haskins that he wanted ""other Google Cloud engineers to know that this is what engineering looks like — is standing in solidarity with the communities affected by your work."" He spoke to the journalist anonymously to avoid professional repercussions, but Google clearly found out who he was. In a statement to Engadget, a Google spokesperson said, ""Earlier this week, an employee disrupted a coworker who was giving a presentation – interfering with an official company-sponsored event. This behavior is not okay, regardless of the issue, and the employee was terminated for violating our policies.""

Update, March 9 2024, 1:58PM ET: This story has been updated to include a statement from Google.

This article contains affiliate links; if you click such a link and make a purchase, we may earn a commission.",General,Relevant,Irrelevant,
Sail-powered cargo ship 'shows potential of wind',https://www.bbc.co.uk/news/technology-68543677,"BAR Technologies, the UK firm which designed the wings, is seeking other ships to fit, and says it will use three wings rather than two in future, increasing the fuel and emissions saved.",General,Relevant,Irrelevant,
"Bezos, Nvidia Join OpenAI in Funding Humanoid Robot Startup",https://hardware.slashdot.org/story/24/02/26/0228255/bezos-nvidia-join-openai-in-funding-humanoid-robot-startup,"OpenAI, Microsoft, Nvidia, and Jeff Bezos are all part of a pack of investors in a business ""developing human-like robots ,"" reports Bloomberg, ""according to people with knowledge of the situation...""At the startup — which is named ""Figure"" — engineers ""are working on a robot that looks and moves like a human. The company has said it hopes its machine, called Figure 01, will be able to perform dangerous jobs that are unsuitable for people and that its technology will help alleviate labor shortages.""Bloomberg calls the investments in Figure ""part of a scramble to find new applications for artificial intelligence.""",AI,Relevant,Relevant,
Google DeepMind taps the power of its AI to accelerate quantum computers,https://thenextweb.com/news/google-deepmind-ai-to-accelerate-quantum-computers,"In new research, Google DeepMind has demonstrated that its AI can help accelerate the development of quantum computers — taking one step further in combining two of the most disruptive technologies.

DeepMind worked together with UK-based Quantinuum to solve a key challenge in fault-tolerant quantum computers: reducing the number of T gates.

T gates are essential in implementing a quantum circuit — a network of gates that manipulates qubits to generate algorithms. However, T gates are also the most expensive and most resource-intensive gates of the network.

To address this, the team developed AlphaTensor-Quantum, an extension of DeepMind’s AlphaTensor, the first AI system that can discover efficient algorithms for tasks such as matrix multiplication.

AlphaTensor-Quantum is an AI model that leverages the relationship between optimising T-count and tensor decomposition, using deep reinforcement learning.

In contrast to existing approaches, the model can incorporate domain-specific knowledge about quantum computation as well as use “gadgetisation” techniques, which implement alternative gates by introducing additional qubits and operations. This way, the AI can significantly reduce the number of T gates.

According to the researchers, AlphaTensor-Quantum outperforms existing systems for T-count optimisation and is as efficient as the “best” human-designed solutions across numerous applications. It can also save “hundreds of hours” of research by optimising the process in a fully automated way, the team says in the paper.

“On a representative standard benchmark set of circuits, AlphaTensor-Quantum improves the cost by 37% on average on the existing state of the art obtained by human-crafted heuristics,” Konstantinos Meichanetzidis, head of product development at Quantinuum, told TNW.

DeepMind and Quantinuum envision applications in quantum chemistry and related fields, and suggest that possible future research could focus on improving the algorithm’s neural network architecture.

“In general, the method can be readily applied to any given circuit independent of application, and the improvements over the baselines correspond directly to space and time cost of the quantum algorithm under consideration,” Meichanetzidis said.

Update (11:30AM CET, February 27, 2024): The article has been updated to include the comments from Quantinuum.

One of the themes of this year’s TNW Conference is Ren-AI-ssance: The AI-Powered Rebirth. If you want to go deeper into all things artificial intelligence, or simply experience the event (and say hi to our editorial team), we’ve got something special for our loyal readers. Use the code TNWXMEDIA at checkout to get 30% off your business pass, investor pass or startup packages (Bootstrap & Scaleup).",AI,Relevant,Relevant,
"Dell chief teases arrival of 1,000-watt Nvidia GPU chip",https://readwrite.com/dell-chief-teases-arrival-of-1000-watt-nvidia-gpu-chip/,"A Dell executive has teased a blockbuster GPU to be launched by Nvidia later this year.

Nvidia, the leading global supplier of chips used in artificial intelligence (AI), is getting ready to unleash the B100 which will blow the H100 out of the water.

That impressive commodity, running at 700W, will be outstripped by its successor with the B100 set to consume 1000 watts – an increase of 42%.

Nvidia is said to enjoy an enviable 80% market share in the high-end AI chip sector, but it plans further expansion including the formation of a dedicated unit for designing custom chips for cloud computing companies and other sectors.

Jeff Clarke, COO at Dell Technologies, has expressed his anticipation for the upcoming AI accelerator, speaking on his company’s recent earnings call.

“We’re excited about what’s happening with the H200 and its performance improvement,” he told investors, with the same sentiment expressed toward the B100 chip and an unknown B200.

When will Nvidia launch the B100 chip?

It was claimed direct cooling liquid won’t be required for GPU’s sapping through 1000 watts, but it could be introduced “next year with the B200”.

This aspect of the dialogue has provoked curiosity and intrigue as there is no current chip with that label on the horizon at Nvidia, at least not on the roadmap shared with its investors in October 2023.

It could be Clarke was referring to the GB200 Superchip which is expected to bring together Nvidia’s Grace CPU with its B100 GPU, like the GH200. Alternatively, a trump card could be up the proverbial sleeve of the Delaware-incorporated tech multinational.

The company declined to comment, following the remarks made by the Dell chief, but further information will be forthcoming at Nvidia’s GTC event from 17-21 March.

The arrival of the B100 isn’t expected until late this year, given the launch of to launch of the H200 GPU in the first half of the year.

Image: Marketing Maverick/X",AI,Relevant,Relevant,
Meta sues “brazenly disloyal” former exec over stolen confidential docs,https://arstechnica.com/tech-policy/2024/03/meta-sues-brazenly-disloyal-former-exec-over-stolen-confidential-docs/,"A recently unsealed court filing has revealed that Meta has sued a former senior employee for ""brazenly disloyal and dishonest conduct"" while leaving Meta for an AI data startup called Omniva that The Information has described as ""mysterious.""

According to Meta, its former vice president of infrastructure, Dipinder Singh Khurana (also known as T.S.), allegedly used his access to ""confidential, non-public, and highly sensitive"" information to steal more than 100 internal documents in a rushed scheme to poach Meta employees and borrow Meta's business plans to speed up Omniva's negotiations with key Meta suppliers.

Meta believes that Omniva—which Data Center Dynamics (DCD) reported recently ""pivoted from crypto to AI cloud""—is ""seeking to provide AI cloud computing services at scale, including by designing and constructing data centers."" But it was held back by a ""lack of data center expertise at the top,"" DCD reported.

The Information reported that Omniva began hiring Meta employees to fill the gaps in this expertise, including wooing Khurana away from Meta.

Last year, Khurana notified Meta that he was leaving on May 15, and that's when Meta first observed Khurana's allegedly ""utter disregard for his contractual and legal obligations to Meta—including his confidentiality obligations to Meta set forth in the Confidential Information and Invention Assignment Agreement that Khurana signed when joining Meta.""

A Meta investigation found that during Khurana's last two weeks at the company, he allegedly uploaded confidential Meta documents—including ""information about Meta’s 'Top Talent,' performance information for hundreds of Meta employees, and detailed employee compensation information""—on Meta's network to a Dropbox folder labeled with his new employer's name.

""Khurana also uploaded several of Meta’s proprietary, highly sensitive, confidential, and non-public contracts with business partners who supply Meta with crucial components for its data centers,"" Meta alleged. ""And other documents followed.""

Advertisement

In addition to pulling documents, Khurana also allegedly sent ""urgent"" requests to subordinates for confidential information on a key supplier, including Meta’s pricing agreement ""for certain computing hardware.""

""Unaware of Khurana’s plans, the employee provided Khurana with, among other things, Meta’s pricing-form agreement with that supplier for the computing hardware and the supplier’s Meta-specific preliminary pricing for a particular chip,"" Meta alleged.

Some of these documents were ""expressly marked confidential,"" Meta alleged. Those include a three-year business plan and PowerPoints regarding ""Meta’s future 'roadmap' with a key supplier"" and ""Meta’s 2022 redesign of its global-supply-chain group"" that Meta alleged ""would directly aid Khurana in building his own efficient and effective supply-chain organization"" and afford a path for Omniva to bypass ""years of investment."" Khurana also allegedly ""uploaded a PowerPoint discussing Meta’s use of GPUs for artificial intelligence.""

Meta was apparently tipped off to this alleged betrayal when Khurana used his Meta email and network access to complete a writing assignment for Omniva as part of his hiring process. For this writing assignment, Khurana ""disclosed non-public information about Meta’s relationship with certain suppliers that it uses for its data centers"" when asked to ""explain how he would help his potential new employer develop the supply chain for a company building data centers using specific technologies.""

In a seeming attempt to cover up the alleged theft of Meta documents, Khurana apparently ""attempted to scrub"" one document ""of its references to Meta,"" as well as removing a label marking it ""CONFIDENTIAL—FOR INTERNAL USE ONLY.” But when replacing ""Meta"" with ""X,"" Khurana allegedly missed the term ""Meta"" in ""at least five locations.""

""Khurana took such action to try and benefit himself or his new employer, including to help ensure that Khurana would continue to work at his new employer, continue to receive significant compensation from his new employer, and/or to enable Khurana to take shortcuts in building his supply-chain team at his new employer and/or helping to build his new employer’s business,"" Meta alleged.

Ars could not immediately reach Khurana for comment. Meta noted that he has repeatedly denied breaching his contract or initiating contact with Meta employees who later joined Omniva. He also allegedly refused to sign a termination agreement that reiterates his confidentiality obligations.",General,Relevant,Irrelevant,
Humane Announces Telco Partnerships in Japan and South Korea,https://humane.com/media/humane-and-softbank,"This partnership, as part of a strategic investment opportunity, will see SoftBank become the exclusive telecom provider for Ai Pin in Japan, leveraging SoftBank’s top-class services and compelling customer touchpoints to bring Ai Pin to a new market. SoftBank and Humane will also explore bringing CosmOS to other mobile devices and be working together on an app-less ecosystem of third-party services and AI-driven user experiences in Japan.

By combining SoftBank’s strong business foundation and broad subscriber base with Humane’s advanced developments in AI, this collaboration will create an entirely new device category and OS offering for the region. It marks a significant advancement in AI technology for Japanese consumers.

Imran Chaudhri and Bethany Bongiorno, co-founders of Humane: “Partnering with SoftBank allows us to bring our vision of more intuitive and seamless AI experiences directly to Japanese consumers. This collaboration is a testament to our shared commitment to innovation and to redefining the boundaries of what AI can do for our everyday lives.”

Yoshiaki Adachi, Vice President, Head of Product Division, SoftBank Corp: “SoftBank Corp. has been dedicated to enhancing customer experiences by utilizing AI

technologies to facilitate the sustainable growth of our telecommunications business. Through our partnership with Humane Inc., we are confident that merging Humane’s AI technology with our expertise in areas like advanced mobile networks, IoT, and Cloud and AI computing holds great potential to enrich people’s daily lives. We will continue our efforts to bring AI technology closer to our customers.”

About Humane:

Founded by Imran Chaudhri and Bethany Bongiorno in 2019, Humane is creating the technologies and platforms for the intelligence age. Their first product, the Humane Ai Pin, enables the consumer to take the power of AI with them everywhere. They have partnered with Microsoft, OpenAI, Qualcomm Technologies, Inc., and T-Mobile in their mission to deliver the next era of personal mobile computing, which will be one driven by AI.

Humane press contact: press@humane.com.

About SoftBank Corp.:

Guided by the SoftBank Group's corporate philosophy, ""Information Revolution – Happiness for everyone,"" SoftBank Corp. (TOKYO: 9434) operates telecommunications and IT businesses in Japan and globally. Building on its strong business foundation and compelling number of customer touchpoints, SoftBank Corp. is expanding into non-telecom fields in line with its ""Beyond Carrier"" growth strategy while further growing its telecom business. Also, by fully harnessing the power of AI, 5G/6G, IoT, Digital Twin, Non-Terrestrial Network (NTN) solutions, including High Altitude Platform Station (HAPS)-based stratospheric telecommunications, and other advanced technologies, SoftBank Corp. aims to be ""a company that provides next-generation social infrastructure essential to the development of a digital society."" To learn more, please visit https://www.softbank.jp/en/.",Communications Technologies,Relevant,Relevant,
Making Wooden Shingles with Hand Tools,https://hackaday.com/2024/02/22/making-wooden-shingles-with-hand-tools/,"While they have mostly been replaced with other roofing technologies, wooden shingles have a certain rustic charm. If you’re curious about how to make them by hand, [Harry Rogers] takes us through his friend [John] making some.

There are two primary means of splitting a log for making shingles (or shakes). The first is radial, like one would cut a pie, and the other is lateral, with all the cuts in the same orientation. Using a froe, the log is split in progressively smaller halves to control the way the grain splits down the length of the log and minimize waste. Larger logs result in less waste and lend themselves to the radial method, while smaller logs must be cut laterally. Laterally cut shingles have a higher propensity for warping and other issues, but will work when larger logs are not available.

Once the pieces are split out of the log, they are trimmed with an axe, including removing the outer sapwood which is the main attractant for bugs and other creatures that might try eating your roof. Once down to approximately the right dimensions, the shingle is then smoothed out on a shave horse with a draw knife. Interestingly, the hand-made shingles have a longer lifespan than those sawn since the process works more with the grain of the wood and introduces fewer opportunities for water to seep into the shingles.

If you’re looking for something more solarpunk and less cottagecore for your house, maybe try a green solar roof, and if you’ve got a glass roof, try cleaning it with the Grawler.",General,Relevant,Irrelevant,
Figure AI: Humanoid robot maker given $2.6bn valuation by Jeff Bezos,https://readwrite.com/figure-ai-humanoid-robot-maker-given-2-6bn-valuation-by-jeff-bezos/,"Figure AI has reportedly been given a valuation of $2.6 billion from investors including Jeff Bezos, Nvidia, and Microsoft.

The startup working to build humanoid robots that can perform dangerous and undesirable jobs was able to raise $675 million, when it was seeking $500 million in a funding round led by Microsoft Corp.

Founded in 2022, the California-based company said that its priority will be in industries such as manufacturing, shipping and logistics, warehousing, and retail, “where labor shortages are the most severe.” Its founder Brett Adcock shared the news on X, stating that, “OpenAI & Figure signed a collaboration agreement to develop next-generation AI models for robots”

Excited to share: Figure raises $675M at $2.6B Valuation + OpenAI & Figure signed a collaboration agreement to develop next generation AI models for robots Below are the details: pic.twitter.com/V57nn9P3oA — Brett Adcock (@adcock_brett) February 29, 2024

“Our vision at Figure is to bring humanoid robots into commercial operations as soon as possible. This investment, combined with our partnership with OpenAI and Microsoft, ensures that we are well-prepared to bring embodied AI into the world to make a transformative impact on humanity,” said Adcock in a statement.

He added, “AI and robotics are the future, and I am grateful to have the support of investors and partners who believe in being at the forefront.”

Earlier this week, the company unveiled a video demonstrating Figure 01’s capabilities. This robot, connected by a tether, can walk on two legs and uses its fingers to lift a plastic crate. It then proceeds to walk a few additional steps before setting the crate down on a conveyor belt. The company already showcased a robot making coffee in January.

Last month we demonstrated Figure 01 making coffee only using neural networks This is a fully learned, end-to-end visuomotor policy mapping onboard images to low level actions at 200hz Next up: excited to push the boundaries on AI learning with OpenAIpic.twitter.com/DNAZWnaYK3 — Figure (@Figure_robot) February 29, 2024

The beginning of humanoid robots

Last year, the UN’s International Telecommunication Union held its first news conference featuring humanoid social robots. Nine robots, carefully crafted to resemble humans, took center stage at the news conference. One of the robots named Sophia was developed by Hanson Robotics, while others were programmed by Beyond Imagination, the University of Geneva, Hiroshi Ishiguro, Neura Robotics, Aidan Meller, SingularityNET, and Engineered Arts.

The event looked at networking to build new projects, calls to action, and partnerships. It featured talks from thought leaders as well as demonstrations of state-of-the-art AI solutions that could achieve global scale with the support of the international AI for Good community.

1X Technologies also confirmed a breakthrough in teaching skills to its android EVE, thanks to special neural networks, which allow the bots to learn by watching videos of people doing activities. Like Figure AI, the Norway-based humanoid robotics firm is backed by OpenAI.

Featured image: Canva / DoD photo by Senior Master Sgt. Adrian Cadiz",Robotics,Relevant,Relevant,
Is America Running Out of Electrical Power?,https://hardware.slashdot.org/story/24/03/07/2150234/is-america-running-out-of-electrical-power,An anonymous reader quotes a report from The Week Magazine:,General,Irrelevant,Irrelevant,
AI Might Not Be the Future of Fast Food Drive-Thru Lanes After All,https://gizmodo.com/ai-voice-activated-drive-thru-lanes-fast-food-presto-1851308673,"This article originally appeared at The Takeout.

Many fast food restaurants have been experimenting with artificial intelligence in recent months, trying to figure out how best to use the evolving technology to drive sales and increase efficiency. Many restaurant chains have tested AI-assisted drive-thru lanes, but the recent struggles of one AI company illustrate the potential shortcomings of this model.

Get Gorditas From a Tube at Taco Bell 'Defy' CC Share Subtitles Off

English view video Get Gorditas From a Tube at Taco Bell 'Defy'

Presto Automation supplies AI solutions, specifically voice recognition technology, to a number of major fast food chains including Checkers and Rally’s, Del Taco, and both Carl’s Jr. and Hardee’s. Presto’s voice bots are in use across 145 Hardee’s, Carl’s Jr., and Wienerschnitzel restaurants as of February 1, 2024. Restaurant Business reports that the company also supplies digital ordering tablets to casual restaurant chains such as Applebee’s, Chili’s, and Red Lobster.

Advertisement

However, Presto has recently struggled to appease investors; the company is running out of money and has to figure out how to pay its lenders $6 million this month. To make matters worse, Presto is losing some of its biggest clients.

Advertisement

Fast food chains waffle on AI solutions

Del Taco began using Presto’s voice AI in its drive-thru lanes in 2022 and in early 2023 said the technology was “exceeding expectations.” Del Taco made plans to expand its use of the tech across more of its 600 restaurant locations, Restaurant Business reported at the time. Now, however, Del Taco has made the decision to stop using the technology at its restaurants.

Advertisement

Presto’s technology does use AI voice recognition to take down orders in the drive-thru lane, but a significant portion of the process still requires an actual employee’s involvement as well. The bot takes down the order from the customer, but it is still the responsibility of the employees to input the order and ensure its accuracy. The voice assistant technology has gone through multiple iterations, but even its most advanced version is still only completing 30% of orders without the help of a human being.

Other chains such as White Castle and McDonald’s have also tested out AI voice recognition in their drive-thru lanes. However, from the customer perspective these new technologies have been a mixed bag. When McDonald’s first tried out similar tech in one of its drive-thru lanes, internet users roasted the bots online for misinterpreting their orders.

Advertisement

Presto’s AI-powered voice recognition has been the company’s flagship offering since its inception—but even its ordering tablets have apparently failed to impress in the long term. Applebee’s, Chili’s, and Red Lobster have all confirmed they will not be renewing their contracts with Presto.

Presto’s leadership nevertheless appears to be optimistic about the future. “We are experiencing significant interest from franchise operators today who are interested in talking to us about Voice AI,” said Presto CEO Xavier Casanova in a November 2023 press release. “We look forward to generating widespread adoption of our Presto Voice AI solution across North America as brands and franchisees adapt to this new reality.”",AI,Relevant,Relevant,
"Matrix multiplication breakthrough could lead to faster, more efficient AI models",https://arstechnica.com/information-technology/2024/03/matrix-multiplication-breakthrough-could-lead-to-faster-more-efficient-ai-models/,"Computer scientists have discovered a new way to multiply large matrices faster than ever before by eliminating a previously unknown inefficiency, reports Quanta Magazine. This could eventually accelerate AI models like ChatGPT, which rely heavily on matrix multiplication to function. The findings, presented in two recent papers, have led to what is reported to be the biggest improvement in matrix multiplication efficiency in over a decade.

Multiplying two rectangular number arrays, known as matrix multiplication, plays a crucial role in today's AI models, including speech and image recognition, chatbots from every major vendor, AI image generators, and video synthesis models like Sora. Beyond AI, matrix math is so important to modern computing (think image processing and data compression) that even slight gains in efficiency could lead to computational and power savings.

Graphics processing units (GPUs) excel in handling matrix multiplication tasks because of their ability to process many calculations at once. They break down large matrix problems into smaller segments and solve them concurrently using an algorithm.

Perfecting that algorithm has been the key to breakthroughs in matrix multiplication efficiency over the past century—even before computers entered the picture. In October 2022, we covered a new technique discovered by a Google DeepMind AI model called AlphaTensor, focusing on practical algorithmic improvements for specific matrix sizes, such as 4x4 matrices.

By contrast, the new research, conducted by Ran Duan and Renfei Zhou of Tsinghua University, Hongxun Wu of the University of California, Berkeley, and by Virginia Vassilevska Williams, Yinzhan Xu, and Zixuan Xu of the Massachusetts Institute of Technology (in a second paper), seeks theoretical enhancements by aiming to lower the complexity exponent, ω, for a broad efficiency gain across all sizes of matrices. Instead of finding immediate, practical solutions like AlphaTensor, the new technique addresses foundational improvements that could transform the efficiency of matrix multiplication on a more general scale.

Advertisement

Approaching the ideal value

The traditional method for multiplying two n-by-n matrices requires n³ separate multiplications. However, the new technique, which improves upon the ""laser method"" introduced by Volker Strassen in 1986, has reduced the upper bound of the exponent (denoted as the aforementioned ω), bringing it closer to the ideal value of 2, which represents the theoretical minimum number of operations needed.

The traditional way of multiplying two grids full of numbers could require doing the math up to 27 times for a grid that's 3x3. But with these advancements, the process is accelerated by significantly reducing the multiplication steps required. The effort minimizes the operations to slightly over twice the size of one side of the grid squared, adjusted by a factor of 2.371552. This is a big deal because it nearly achieves the optimal efficiency of doubling the square's dimensions, which is the fastest we could ever hope to do it.

Here's a brief recap of events. In 2020, Josh Alman and Williams introduced a significant improvement in matrix multiplication efficiency by establishing a new upper bound for ω at approximately 2.3728596. In November 2023, Duan and Zhou revealed a method that addressed an inefficiency within the laser method, setting a new upper bound for ω at approximately 2.371866. The achievement marked the most substantial progress in the field since 2010. But just two months later, Williams and her team published a second paper that detailed optimizations that reduced the upper bound for ω to 2.371552.

The 2023 breakthrough stemmed from the discovery of a ""hidden loss"" in the laser method, where useful blocks of data were unintentionally discarded. In the context of matrix multiplication, ""blocks"" refer to smaller segments that a large matrix is divided into for easier processing, and ""block labeling"" is the technique of categorizing these segments to identify which ones to keep and which to discard, optimizing the multiplication process for speed and efficiency. By modifying the way the laser method labels blocks, the researchers were able to reduce waste and improve efficiency significantly.

Advertisement

While the reduction of the omega constant might appear minor at first glance—reducing the 2020 record value by 0.0013076—the cumulative work of Duan, Zhou, and Williams represents the most substantial progress in the field observed since 2010.

""This is a major technical breakthrough,"" said William Kuszmaul, a theoretical computer scientist at Harvard University, as quoted by Quanta Magazine. ""It is the biggest improvement in matrix multiplication we've seen in more than a decade.""

While further progress is expected, there are limitations to the current approach. Researchers believe that understanding the problem more deeply will lead to the development of even better algorithms. As Zhou stated in the Quanta report, ""People are still in the very early stages of understanding this age-old problem.""

So what are the practical applications? For AI models, a reduction in computational steps for matrix math could translate into faster training times and more efficient execution of tasks. It could enable more complex models to be trained more quickly, potentially leading to advancements in AI capabilities and the development of more sophisticated AI applications. Additionally, efficiency improvement could make AI technologies more accessible by lowering the computational power and energy consumption required for these tasks. That would also reduce AI's environmental impact.

The exact impact on the speed of AI models depends on the specific architecture of the AI system and how heavily its tasks rely on matrix multiplication. Advancements in algorithmic efficiency often need to be coupled with hardware optimizations to fully realize potential speed gains. But still, as improvements in algorithmic techniques add up over time, AI will eventually get faster.",AI,Relevant,Relevant,
Meta will reportedly showcase prototype AR glasses at Connect 2024,https://www.androidcentral.com/gaming/virtual-reality/meta-will-reportedly-showcase-prototype-ar-glasses-at-connect-2024,"What you need to know

Meta is expected to reveal its ""Orion"" prototype of augmented reality glasses at Connect 2024.

The glasses have been in development for nearly a decade, but are still likely years away from a public release.

Still, Meta may demo the AR glasses prototype at Connect 2024, a developer conference often held in October.

Meta might be looking to capitalize on the buzz around mixed-reality wearables of late. The company is expected to unveil and demo its first pair of true augmented reality (AR) glasses, known as ""Orion,"" at its Connect 2024 conference later this year. Despite the internal ambitions to show off Orion in the fall, a consumer pair of AR glasses is likely years away from public release.

The company's plans to reveal a pair of AR glasses at Connect 2024 were reported by Business Insider. The publication spoke to two people familiar with the matter, and their identities were reportedly confirmed. The report adds that there is “internal pressure to ensure a high level of performance” when the AR glasses are debuted at Connect 2024 (via RoadToVR).

The prototype Orion glasses have been worked on for nine years and aren't likely to be released until 2027 at the earliest. However, Meta hasn't been shy about revealing bits and pieces of its mixed-reality plans. Project Aria, a pair of AR glasses that have been tested in real-world environments since 2020, is a great example of this. The testing done as part of Project Aria likely contributes to Meta's other projects, such as the Orion glasses.

Connect 2024, usually held in October, would make sense as a place to showcase the Orion concept. It's a developer conference that Meta frequently uses to demo its new technologies and products. In fact, the company announced its latest virtual reality headset — the Meta Quest 3 — at last year's Connect event.

(Image credit: Nicholas Sutrich / Android Central)

While plenty of virtual reality headsets and smart glasses have been released in recent years, there are very few true AR offerings available. Aside from the Quest 3, Meta also has the Meta Ray-Ban smart glasses in its wearable portfolio. The company's project Orion will be a blend of those two products, with computing power in the form factor of a pair of glasses.

If this report is accurate, we'll learn more about Meta's AR glasses plans at Connect 2024 later this year.",General,Relevant,Irrelevant,
NASA Ends $2 Billion Satellite Refueling Project After Contractor Accused of ‘Poor Performance’,https://gizmodo.com/nasa-cancels-maxar-osam-1-mission-poor-performance-1851305230,"An ambitious NASA project designed to test satellite refueling in space, known as OSAM-1, has been discontinued after significant technical, cost, and scheduling difficulties. The cancellation comes in the wake of an October 2023 report from NASA’s Office of Inspector General that cited “poor performance” by Maxar, the primary contractor for the project.

First Full-Color Images From Webb Space Telescope CC Share Subtitles Off

English view video First Full-Color Images From Webb Space Telescope

NASA announced the cancellation of the On-orbit Servicing, Assembly, and Manufacturing 1 (OSAM-1) project on Friday March 1. The project aimed to refuel the aging Landsat-7 Earth observation satellite and demonstrate in-space manufacturing technology. It faced “continued technical, cost, and schedule challenges,” leading to its discontinuation. NASA’s decision, revealed in a news release, followed an “in-depth, independent project review.”

Advertisement

A key reason for the cancellation, NASA explained, is the emerging industry trend of designing satellites with built-in capabilities for refueling. OSAM-1 planned to use an orbiting spacecraft with robotic arms to forcibly access the fuel tanks of satellites not originally designed for refueling (this animated video of the concept will give you a good idea of the complexities involved). Such an approach is becoming less relevant as the industry shifts to building satellites with refueling capabilities in mind.

Advertisement

The project’s termination also stems from the “lack of a committed partner,” as NASA put it, presumably referring to Maxar, a key contractor for OSAM-1. A report from NASA’s inspector general in October highlighted Maxar’s “poor performance,” citing the company’s underestimation of the project’s scope and complexity, a lack of full understanding of NASA’s technical requirements, and deficiencies in necessary expertise. The company was already taking a financial loss on its OSAM-1 involvement. The nature of Maxar’s fixed-price contract with NASA, which didn’t “provide NASA adequate flexibility to incentivize Maxar to improve its performance,” contributed to staffing challenges and project delays, according to the OIG.

Advertisement

Maxar Intelligence and Maxar Space Systems are two separate divisions of Maxar Technologies. Maxar Intelligence, through its satellite fleet, focuses on Earth intelligence and geospatial analytics, while Maxar Space Systems designs and manufactures spacecraft and space hardware.

To support OSAM-1, NASA contributed an additional $2 million in labor resources. Despite these efforts, the project experienced significant cost overruns and delays. According to NASA, much of the project’s cost growth and schedule setbacks were due to Maxar’s poor performance, particularly on the spacecraft bus and the Space Infrastructure Dexterous Robot (SPIDER) contracts, with each deliverable approximately two years behind schedule.

Advertisement

The SPIDER system was to include a lightweight 16-foot-long (4.9-meter) robotic arm, adding to the total of three robotic arms on the mission. The rationale behind OSAM-1 was to develop technologies for the improved managing of satellite fleets, getting more bang for the buck on initial investments and to address the mounting problem of orbital debris.

NASA will now commence an orderly shutdown of OSAM-1, which involves deciding the fate of the project’s sensitive hardware, exploring potential partnerships or alternative uses for the hardware, and licensing the project’s technological developments. As MSNBC reports, the agency said it plans to support the approximately 450 personnel involved in OSAM-1 through the fiscal year 2024. It will also find ways to minimize the impact of the cancellation on the workforce at NASA’s Goddard Space Flight Center in Greenbelt, Maryland.

While it’s always unfortunate to see large-scale projects like this come to an end, NASA did what it had to do, pulling the plug after identifying intractable—and costly—challenges. Another NASA partner, Boeing, is currently struggling to develop the CST-100 Starliner spacecraft for crewed trips to space. Despite these struggles, NASA remains committed to the program, trusting Boeing to succeed and needing Starliner as an alternative to SpaceX’s Crew Dragon.

Advertisement

For more spaceflight in your life, follow us on X and bookmark Gizmodo’s dedicated Spaceflight page.",General,Relevant,Irrelevant,
What a Major Solar Storm Could Do to Our Planet,https://www.newyorker.com/magazine/2024/03/04/what-a-major-solar-storm-could-do-to-our-planet,"Ken Tegnell’s first home was on Alcatraz. At the time—this was in the nineteen-fifties—there was, in addition to the federal penitentiary, a preschool, a post office, and housing for prison employees and their family members. That included Tegnell, who lived with his mother and grandfather, a guard, while his father was stationed in Korea. The whole of Alcatraz Island is less than a tenth of a square mile, so, despite all the security measures and “DO NOT ENTER” signs, the inmates and civilians were never very far apart. Yet even given the proximity to the likes of Whitey Bulger, it was a peaceful place to live. The view was spectacular, almost none of the non-incarcerated residents locked their doors, and almost all of them knew one another and shared the camaraderie of an unusual identity. “We were an odd group of people,” Tegnell jokes, “and that’s why I’m strange the way I am.”

When Tegnell’s father returned from Korea, the family moved away, and then moved often. But eventually Tegnell returned to the Bay Area—this time to attend Berkeley, which, by the late nineteen-sixties, was another island of odd people. While taking an astronomy course there, he attended a lecture by a not yet famous scientist named Carl Sagan. Interested in things that happen in the sky and unmoved by the hippie culture around him, Tegnell joined the Air Force, in 1974. The military taught him to use telescopes and radio arrays, then sent him to the Learmonth Solar Observatory, at the northwestern tip of Australia, to gather data about the sun. He served two tours there, twelve hours from anything that could be called a city—a godforsaken place, as Tegnell recalls it, but gorgeous, with beautiful beaches, terrific fishing, and almost no rainfall year-round. Whether working or playing, he spent his days there looking at the sun.

That is still how Tegnell makes a living, although he hung up his wings in 1996. Today, his job is simultaneously so obscure that most people have never heard of it and so important that virtually every sector of the economy depends on it. His official title, one shared by no more than a few dozen Americans, is space-weather forecaster. Ever since leaving the Air Force, Tegnell has worked for the National Oceanic and Atmospheric Administration’s Space Weather Prediction Center, in Boulder, Colorado: ten hours a day, forty hours a week, three decades spent staring at real-time images of the sun. Eleven other forecasters work there as well. The remaining ones are employed by the only similar institution in the country: the Space Weather Operations Center, run by the Department of Defense on Offutt Air Force Base, in Sarpy County, Nebraska.

Regular, Earth-based weather is such a fundamental part of our lives that we are almost always aware of it and very often obsessed with it; it is the subject of everything from idle chitchat to impassioned political debate. By contrast, most people have no idea that there is weather in outer space, let alone what its fluctuations might mean for our planet. That’s because, unlike everyday weather, you can’t experience space weather directly. It doesn’t make you hot or cold, doesn’t flood your basement or take the roof off your home. In fact, until the nineteenth century, it had almost no appreciable effect whatsoever on human activity. Then came a series of scientific revolutions that made certain technologies, from electricity to telecommunications, central to our lives. Only later did we realize that those technologies are vulnerable to the effects of weather in outer space. The potential consequences are as sweeping as our technological dependence. In 2019, the Federal Emergency Management Agency, surveying the landscape of possible disasters, concluded that only two natural hazards have the capacity to simultaneously affect the entire nation. One is a pandemic. The other is a severe solar storm.

That is why Tegnell’s job is so important. But “space-weather forecaster” is an optimistic misnomer; for the most part, he and his colleagues can’t predict what will happen in outer space. All they can do is try to figure out what’s happening there right now, preferably fast enough to limit the impact on our planet. Even that is difficult, because space weather is both an extremely challenging field—it is essentially applied astrophysics—and a relatively new one. As such, it is full of many lingering scientific questions and one looming practical question: What will happen here on Earth when the next huge space storm hits?

The first such storm to cause us trouble took place in 1859. In late August, the aurora borealis, which is normally visible only in polar latitudes, made a series of unusual appearances: in Havana, Panama, Rome, New York City. Then, in early September, the aurora returned with such brilliance that gold miners in the Rocky Mountains woke up at night and began making breakfast, and disoriented birds greeted the nonexistent morning.

This lovely if perplexing phenomenon had an unwelcome corollary: around the globe, telegraph systems went haywire. Many stopped working entirely, while others sent and received “fantastical and unreadable messages,” as the Philadelphia Evening Bulletin put it. At some telegraph stations, operators found that they could disconnect their batteries and send messages via the ambient current, as if the Earth itself had become an instant-messaging system.

Owing to a lucky coincidence, all these anomalies were soon linked to their likely cause. At around noon on September 1st, the British astronomer Richard Carrington was outside sketching a group of sunspots when he saw a burst of light on the surface of the sun: the first known observation of a solar flare. When accounts of the low-latitude auroras started rolling in, along with reports that magnetometers—devices that measure fluctuations in the Earth’s magnetic field—had surged so high they maxed out their recording capabilities, scientists began to suspect that the strange things happening on Earth were related to the strange thing Carrington had seen on the sun.

“This recipe turned out awful despite my substituting every major ingredient.” Cartoon by Mads Horwath Copy link to cartoon Copy link to cartoon Shop Shop

Wonderment over the Carrington Event, as it is now known, faded almost as quickly as the auroras—but sixty years later it happened again. In May, 1921, dazzling lights filled the night sky in places as far from the poles as Texas and Samoa; this time, too, spectacle was followed by debacle. “Electric fluid” leaping from a telegraph switchboard set on fire a railroad station in Brewster, New York, while stray voltage on railway signal and switching systems halted trains in Manhattan and, farther north, started a fire at Albany’s Union Station.

Over the years, at odd intervals, this pattern kept repeating: brilliant night skies followed by troubling consequences, which changed in concert with evolving technologies. Teletype machines ceased to operate; or transatlantic cables stopped working; or worldwide radio circuits fell silent; or hundreds of thousands of miles of transmission lines used to send and receive wire stories all went down at the same time. In May, 1967, all three radar sites of the Ballistic Missile Early Warning Systems then maintained by the U.S. Air Force appeared to have been jammed; worried that the Soviet Union was on the verge of attacking, military officials nearly scrambled nuclear-equipped aircraft. Five years later, during the Vietnam War, the United States started sowing the waters outside North Vietnamese seaports with mines that had magnetic sensors, to trigger explosions when steel-hulled vessels passed overhead. Three months after that program began, many of those mines—four thousand of them, according to one contemporaneous source—detonated almost simultaneously. An investigation determined that the plan had been compromised not by Hanoi but by a newly discovered solar phenomenon called a coronal mass ejection.

In time, aided by each new technological difficulty, astrophysicists began to piece together a better understanding of the weather in outer space. But science can take a long time to make inroads into public awareness, let alone public policy, so space weather remained a mostly marginal subject until 2008, when the National Academy of Sciences convened a group of experts to assess the nation’s capacity to endure its terrestrial effects. Later that year, the N.A.S. published a report on the findings, “Severe Space Weather Events: Understanding Societal and Economic Impacts.”

The title was dry; the contents were not. The report noted that the Earth hadn’t experienced a Carrington-size storm during the space age, or, for that matter, during the age of widespread electrification, and that much of the country’s critical infrastructure seemed unlikely to withstand one. Extensive damage to satellites would compromise everything from communications to national security, while extensive damage to the power grid would compromise everything: health care, transportation, agriculture, emergency response, water and sanitation, the financial industry, the continuity of government. The report estimated that recovery from a Carrington-class storm could take up to a decade and cost many trillions of dollars.

That report made headlines, and also made its way to President Barack Obama—who by then had appointed a new FEMA administrator, a man named Craig Fugate. At the time, very few people even within the emergency-response community knew much about space weather. But, by chance, Fugate had crossed paths with the Space Weather Prediction Center earlier in his career; interested in the center’s work, he had made himself into something of a space-weather expert.

As a result, when the White House came knocking to ask if it should be concerned about the N.A.S. report, Fugate was in a position to offer an emphatic yes. The question, for him, wasn’t whether a major solar storm posed a risk to the nation; it was how best to prepare for it beforehand and recover from it afterward. And so, as he began settling into his job, and getting to know the rest of the senior leaders at FEMA, he made a habit of presenting them with a hypothetical situation. “I asked them what they would do if there was a G5 storm,” Fugate told me, referring to the highest classification on the NOAA Space Weather Scale, akin to an F5 tornado or a Category 5 hurricane. “And they go, ‘What’s a G5 storm?’ ” Hoo boy, Fugate remembers thinking. We got a problem.

In space weather, every day is a sunny day. There is no interstellar rain, no interplanetary snow, no sleet spinning off the rings of Saturn; all the phenomena we call space weather originate on the sun. And so, to start, you must shed the idea—implicit in our meteorology and omnipresent in our metaphors—that the sun is a mild and beneficent force, a bestower of good moods and great tans.

In reality, the sun is an enormous thermonuclear bomb that has been exploding continuously for four and a half billion years. Its inner workings are imperfectly understood even by heliophysicists, who sometimes sound less like scientists than like nineteen-fifties comic-book heroes, enthusiastically invoking things like flux tubes and convection zones and galactic-cosmic-ray dropouts. Fortunately, for our purposes, the only two solar phenomena you need to understand are solar flares and coronal mass ejections, both of which stem from the same thing: a buildup of energy in the magnetic field of the sun.",AI,Relevant,Irrelevant,
Apple’s upcoming Xcode update to feature advanced AI capabilities,https://readwrite.com/apples-upcoming-xcode-update-to-feature-advanced-ai-capabilities/,"Apple is finalizing a new software tool aimed at enhancing app development with AI, positioning itself as a direct competitor to Microsoft. According to a recent Bloomberg report, the tool, part of the forthcoming major update to Xcode, Apple’s primary programming software, is designed to assist developers by predicting and completing code blocks using AI.

Scheduled for release to third-party developers possibly within this year, the tool mirrors functionalities seen in Microsoft’s GitHub Copilot, suggesting Apple’s intent to solidify its presence in the AI-driven software development arena. The initiative also includes exploring AI applications for automating application testing, potentially streamlining a process known for its complexity.

Apple has increased internal testing of these AI features, encouraging engineers to use them in a practice known as “dogfooding” — using one’s own products to ensure they function correctly before public release.

Apple’s AI strategy

The development is part of Apple’s broader strategy to incorporate generative AI and large language models into its ecosystem, technologies that underpin popular AI chatbots like ChatGPT. Despite a perception of lagging behind competitors in AI, Apple has announced plans to reveal more about its AI endeavors later this year, potentially at its annual developers conference in June.

The upcoming iOS and iPadOS 18 updates are expected to introduce a range of AI features, with Apple hinting at significant enhancements in what is being codenamed Crystal. Similarly, the next macOS update, codenamed Glow, will also see AI integrations, though Apple anticipates a phased approach to rolling out these technologies.

In addition to software development tools, Apple is considering AI-driven improvements across its product line, including automated Apple Music playlists and advanced slideshow capabilities in Keynote. A major overhaul of Spotlight, Apple’s search feature, is also in the works, aiming to provide more complex responses and deeper app integration through the use of large language models.

Apple’s AI efforts extend to improving Siri’s response accuracy to complex queries and enhancing customer support and health features through AI. The company’s commitment to AI development reflects the tech industry’s race to leverage AI for a variety of applications, from enhancing user experiences to streamlining development processes.

As Apple progresses with its AI initiatives, it faces competition from companies like Samsung, which has integrated Google AI features into its latest smartphone models.",AI,Relevant,Relevant,
6G Principles Endorsed By US and International Partners,https://tech.slashdot.org/story/24/02/27/0825251/6g-principles-endorsed-by-us-and-international-partners,"""Poor man... he was like an employee to me."" -- The police commisioner on ""Sledge Hammer"" laments the death of his bodyguard",General,Irrelevant,Irrelevant,
Scientists Propose AI Apocalypse Kill Switches,https://politics.slashdot.org/story/24/02/17/0144229/scientists-propose-ai-apocalypse-kill-switches,"""Poor man... he was like an employee to me."" -- The police commisioner on ""Sledge Hammer"" laments the death of his bodyguard",General,Irrelevant,Irrelevant,
nubia Pad 3D II at MWC 2024: Glasses-free 3D tablet gets 5G and AI upgrades,https://www.yankodesign.com/2024/02/27/nubia-pad-3d-ii-at-mwc-2024-glasses-free-3d-tablet-gets-5g-and-ai-upgrades/,"With mixed reality and spatial computing becoming trendy again, 3D content is also seeing a rise in interest, both in terms of creation and especially in consumption. Of course, most of the digital content that we see is in flat 2D, and you need to wear specialized glasses to actually experience those objects in a way that tricks your brain into believing it’s actually 3D. Or at least that’s how things have been traditionally. Outside of cinemas, wearing such glasses is not only uncomfortable and awkward, they’re practically unusable as well. That’s where technologies like the new nubia Pad 3D II come in, offering that same enjoyable experience of immersing yourself in 3D content without having to put anything on your face and without blocking the rest of the world.

Designer: Nubia

Instead of relying on a projector and glasses, the nubia Pad 3D II employs a Diffractive Lighthfield Backlighting (DLB) layer underneath the LCD screen to have the same effect of sending a different set of images to each eye. It uses sensors and eye-detection algorithms to adjust those images depending on where we’re actually looking, giving the same effect without having to wear glasses. That was the concept that nubia proved last year, and the nubia Pad 3D II refines that design with much-needed upgrades.



At the top of that list is 5G connectivity, which is pretty much a minimum requirement for any mobile device today. Given the tablet’s potential for content consumption as well as creation on the go, a fast and stable Internet connection is more than just a convenience; it’s a necessity. Other hardware upgrades include an improvement to the special display with 80% better 3D resolution and 100% boost in 3D brightness. It is powered by some of the current mobile technologies available, including a Qualcomm Snapdragon 8 Gen 2, a whopping 10,000 mAh 66W battery, and a 12.1-inch 2.5K screen.

Unsurprisingly, nubia is also pushing the AI upgrades it made to the second-gen eyewear-free 3D tablet. In addition to utilizing AI to properly detect eye position and adjust the 3D display accordingly, it also uses neural networks for its Neovision 3D Anytime, which can convert any 2D content into 3D in real time. That includes not just photos but also videos, streaming media, and even games. AI 3D Collaboration allows owners of ZTE phones or Miracast devices to wirelessly stream content to the tablet for even more sources for videos, images, and more.

The nubia Pad 3D II is more than just a tablet for watching 3D videos, though. Thanks to an AI-enhanced dual-camera system, it can also take photos or record videos in stereoscopic 3D, letting you easily create 3D content that you can then share with others. The tablet also has a role to play even if you’re creating those 3D images on a different device. Simply drag and drop that 3D model from laptop to tablet for a better way to view your creation. With the new and improved nubia Pad 3D II, 3D no longer has to be something you can experience inside a cinema or with glasses on, opening a whole new world of 3D content that you can enjoy anytime, anywhere.",General,Relevant,Relevant,
Orbital Materials uses AI to create climate-friendly materials,https://readwrite.com/orbital-materials-uses-ai-to-create-climate-friendly-materials/,"AI has been used to produce everything from images, movies, as well as chatbots. Now a former Google DeepMind engineer is said to be utilizing GenAI to create actual physical materials.

Orbital Materials uses new technologies and LLMs to develop novel green materials for clean water, air, and energy. Founded by Jonathan Godwin, he wrote in a blog post in 2023 that “dramatic innovation” was needed in the field of Material Sciences. He continued, “the global market for aviation fuel is projected to be ~$650bn in 2030, and we need a sustainable and, crucially, affordable alternative.”

He called the progress in AI for materials “breathtaking,” stating that the organization aims to take the principles from models like AlphaFold, ChatGPT, and Stable Diffusion and adapt them to their uses.

As a result, the company is said to have developed a foundational model for atoms that can generate materials for applications it has never seen before. Its first target is producing materials relating to carbon capture, sustainable aviation fuel and the removal of harmful chemicals from the environment.

However, according to Dezeen, long-term plans include working on materials for architecture and design, such as lightweight alloys for cars and smart concrete.

Orbital Materials’ AI model

Speaking to TechCrunch, Godwin said, “Technical decision-makers at chemistry and materials companies struggle to develop new products because traditional methods of discovering new advanced materials are too slow and expensive to meet this demand.

“[Yet] demand for new advanced materials … is growing hugely as our economies become electrified and de-carbonized,” he added.

While there have already been projects related to materials research and development, Godwin claims that its proprietary AI model for materials science distinguishes it from others. The model, named Linus, is reportedly inspired by large language models and AlphaFold.

Godwin stated, “In these models, the really important thing is to get lots of different types of data: models like ChatGPT are trained on code, news articles, scientific text and encyclopedias. This diversity is one of the things that gives the models their remarkable capabilities.”

According to Godwin, Linus underwent training on an extensive dataset encompassing simulations and materials, spanning from batteries and semiconductors to catalysts and organic molecules.

The London-based startup has reportedly generated a cheap, more reliable filter for capturing carbon dioxide from the air, with more details expected to be announced later this year. In 2023, Orbital Materials raised a $4.8M seed round from Fly Ventures, Compound, Flying Fish Partners, Character, and Mustard Seed Maze.

Featured image: DALL·E",AI,Relevant,Relevant,
OPPO Air Glass 3 brings AI to your vision to improve your interactions,https://www.yankodesign.com/2024/02/26/oppo-air-glass-3-brings-ai-to-your-vision-to-improve-your-interactions/,"Smart glasses, in contrast to AR headsets and visors, aim for a design that ideally should be indistinguishable from regular glasses. With today’s technologies and knowledge, however, that’s not easily possible, especially when you need to add powerful computing hardware to sophisticated optics. That’s especially the case when you need to offer some kind of smart assistant functionality, especially voice and speech recognition. In the past, you had to settle for rough translations and sometimes misinterpretations; comical but frustrating nonetheless. That definitely sounds like a job for AI, and that’s exactly what OPPO is bringing to the table, or rather to your eyes, with the newest iteration of its lightweight and discreet “assisted Reality” glasses that take a focused approach to wearables.

Designer: OPPO

AI is still the hot thing in tech today, in spite of and despite the bad publicity that misuse of the tool brings. Today’s AIs happen to be great at processing human language, both written and spoken, and they can now run the device itself with very little power, making them perfect for very small devices, including smart glasses. In its third iteration, the OPPO Air Glass 3 prototype harnesses the power of AI, specifically its own self-trained language model AndesGPT, to deliver a more natural way to talk to your glasses and get your job done.

AI might be the technical highlight of the new OPPO Air Glass 3, but its winning feature is going to be its design. OPPO is laying claim to the title of the world’s lightest binocular full-color glasses, and at 50g only, the claim does have merit. It looks just like regular spectacles with very thick frames, but nothing like those complicated and heavy mixed reality glasses. Despite that lightweight design, the Air Glass 3 still boasts a bright 1,000 nits display delivered by a tiny Spark micro projector, ensuring you can clearly see the virtual information even in bright environments. And with an ultra-thin waveguide, you don’t get the rainbow-like patterns that are often seen on optical see-through displays like these.

The OPPO Air Glass 3 manages to offer this more comfortable design thanks to its more focused functions. Rather than trying to cast its net wide with augmented reality, OPPO is instead focusing on “assisted reality” that emphasizes productivity over entertainment. You’ll still be able to see images if you want and control music playback, but the information that’s displayed in front of your eyes is limited to things like navigation, timers, translations, or even a teleprompter. In other words, it’s a sleek way to have all the important information you need right in front of you instead of having to fish out your phone from your pocket and get distracted in the process.

Of course, that means it will need to connect to an external device, particularly your OPPO smartphone. The Air Glass mobile app provides that connection you need with OPPO’s AndesGPT to ensure you’re getting the best performance possible without weighing your head down. OPPO is also laying the groundwork for more AI-enhanced features and experiences by investing heavily in its own AI center in the hopes of empowering all its products, especially its smartphones, with these features.",AI,Relevant,Relevant,
It's not just chips. Nvidia is betting on other tech that could be impacted by AI.,https://www.businessinsider.com/what-is-nvidia-investment-strategy-venture-capital-startups-ai-chips-2024-3,"Nvidia's chips primed the company to leverage the latest artificial-intelligence boom.

But the GPU-maker is targeting other areas where AI could apply.

Nvidia has invested in dozens of startups in 2023, including a company focused on pharmaceuticals.

NEW LOOK Sign up to get the inside scoop on today’s biggest stories in markets, tech, and business — delivered daily. Read preview Thanks for signing up! Access your favorite topics in a personalized feed while you're on the go. download the app Email address Sign up By clicking “Sign Up”, you accept our Terms of Service and Privacy Policy . You can opt-out at any time.

Advertisement

The California chip maker Nvidia is the latest tech company to so far have a blockbuster year as it surpassed expectations and flexed a market cap of more than $2 trillion by the end of February.

That makes Nvidia one of the three largest companies by market cap, behind Microsoft and Apple.

The company's recent boom can be explained by a fairly simple formula.

This story is available exclusively to Business Insider subscribers. Become an Insider and start reading now. Have an account? Log in .",AI,Relevant,Relevant,
Klarna’s AI-powered chatbot is already taking on the load of 700 human workers,https://readwrite.com/klarnas-ai-powered-chatbot-is-already-taking-on-the-load-of-700-human-workers/,"The CEO of fintech giant Klarna has warned that the power of Artificial Intelligence (AI) is “happening right now” as he confirms the company’s AI-powered chatbot is already handling the work of 700 human employees, reports tech.eu.

Klarna announced a partnership with OpenAI, the creators of ChatGPT, last year and has now confirmed their chatbot has handled 2.3 million customer service chats in 35 different languages in its first four weeks of operation. This is the equivalent of 700 full-time customer service operators.

The success of the AI-powered chatbot has led to a Klarna spokesperson confirming plans to reduce the number of customer service agents it currently outsources to 2,300 from around 3,000.

In a press release, Klarna claims the bot has a customer satisfaction rating that is on par with its human equivalent. It also has higher accuracy than humans, with a 25% decrease in repeat inquiries. The time in which support tickets are resolved has also been cut from 11 minutes to less than two.

Posting on X, CEO and founder Sebastian Siemiatkowski, said: “As more companies adopt these technologies, we believe society needs to consider the impact.

“While it may be a positive impact for society as a whole, we need to consider the implications for the individuals affected.

“We decided to share these statistics to raise awareness and encourage a proactive approach to the topic of AI.

“For decision-makers worldwide to recognize this is not just ‘in the future,’ this is happening right now.”

Klarna believes its AI-powered chatbot will help drive $40 million in profit improvements in 2024 alone.

Are humans at risk of being replaced by AI?

Fears of AI eventually being able to replace humans in the workplace are already becoming a reality, it seems.

Earlier this year, an analysis by the International Monetary Fund (IMF) found that 60% of jobs in advanced economies may be impacted by AI, with roughly half of those jobs at risk of succumbing to the technology’s advanced power. The other half likely benefit from AI in the workplace.

The report stresses the need for countries to act quickly to implement specific policies surrounding the use of AI in specific markets. It also urges stronger economies to embrace and prioritize AI innovation while developing regulatory frameworks, which will help “cultivate a safe and responsible AI environment, helping to maintain public trust.”

But as Klarna provides a rather compelling use case for other companies to consider following suit and replacing at least part of their workforce with AI, there is an argument that it might be too late.

Featured Image: Klarna",AI,Relevant,Relevant,
"Satellite images appear to show expanding gravesites, reflecting the mounting death toll of the Russia-Ukraine war",https://www.businessinsider.com/ukraine-russia-war-death-toll-satellite-images-expanding-gravesites-maxar-2024-2,"Hundreds of thousands of soldiers have been killed since Russia invaded Ukraine two years ago.

US officials put the death toll and injuries from both sides at around half a million soldiers.

Satellite imagery of Russian gravesites appears to reflect some of those mounting death tolls.

NEW LOOK Sign up to get the inside scoop on today’s biggest stories in markets, tech, and business — delivered daily. Read preview Thanks for signing up! Access your favorite topics in a personalized feed while you're on the go. download the app Email address Sign up By clicking “Sign Up”, you accept our Terms of Service and Privacy Policy . You can opt-out at any time.

Advertisement

Since Russia invaded Ukraine in February 2022, hundreds of thousands of soldiers from both sides have been killed in the field of battle.

Officials have struggled to provide an exact figure for casualties in part because the Kremlin is believed to undercount how many of its soldiers have died in Ukraine.

US officials have said, with caution, that the estimated troop death and injuries could be around 500,000, The New York Times reported in August.

Some of those losses have already been shown in countless images and footage of Ukranian soldiers carrying the bodies of their fellow troops off the battlefield and sometimes stacked together with other infantrymen.

Advertisement

In Russia, the war's impacts can be seen in what appear to be expanding cemeteries near the home garrisons of ""elite Russian military units,"" according to Maxar Technologies, a private US-based satellite company, which shared satellite imagery with Business Insider.

The images show new grids of gravesites appearing over the course of the two-year war, dotted with what may be gravestones marking every death of another soldier.

Ukrainian President Volodymyr Zelenskyy said in an interview with Fox News' Bret Baier that aired Thursday that the ratio of casualties is one Ukrainian soldier for every five Russian troops.

Related stories

The UK Ministry of Defence estimates that, at the current rate, Russia is on track to lose more than 500,000 troops by the end of 2024.

Advertisement

The satellite images are a quiet but solemn reminder of Russia's mounting death toll as soldiers are thrown into the frontlines that have come to be called the ""meat grinder.""

Mikhaylovsk cemetery near Stavropol, Russia

Satellite image ©2024 Maxar Technologies

The cemetery is associated with the 7th Guards Airborne Division or 7th Guards Mountain Air Assault Division, according to Maxar.

Russian media reported in March 2022 that the division's commanding general, Andrei Sukhovetsky, was killed in combat.

Blyzhnie cemetery near Feodosiya, Crimea

Satellite image ©2024 Maxar Technologies

A cemetery near the town of Feodosiya, Crimea is also associated with the 7th Guards Airborne Division, according to Maxar.

Advertisement

Bogorodskoye cemetery near Ryazan, Russia

Satellite image ©2024 Maxar Technologies

The cemetery near Ryazan, Russia, is associated with the 106th Guards Airborne Division, according to Maxar.

The image from April shows an entirely new grid to accommodate what appear to be more gravesites.",General,Relevant,Irrelevant,
Having double majors could make you less vulnerable to layoffs and AI,https://www.businessinsider.com/having-double-majors-reduce-chance-ai-job-replacement-chatgpt-layoffs-2024-2,"By clicking “Sign Up”, you accept our Terms of Service and Privacy Policy . You can opt-out at any time.

Access your favorite topics in a personalized feed while you're on the go. download the app

Sign up to get the inside scoop on today’s biggest stories in markets, tech, and business — delivered daily. Read preview

Double majoring in college could do more than pad your résumé. It could boost your job security in a future made uncertain by AI .

That finding is from a working paper published by the National Bureau of Economic Research in January. The authors, who include Stanford and Ohio State University professors, analyzed data from the American Community Survey between 2009 and 2019, which included nearly 1.5 million working US adults.

This story is available exclusively to Business Insider subscribers. Become an Insider and start reading now.

Their key finding: Individuals with a double major were 56% less likely than similar single majors to experience negative “earnings shocks” — deviations in earnings related to factors like job losses or pay cuts.

Related stories

In a future where emerging AI technologies like ChatGPT could replace certain job tasks — and entire jobs altogether — double majors could be better positioned, Andrew Hanks, an associate professor of consumer science at Ohio State and the lead author of the working paper, told BI via email.

Advertisement

“Our findings do show that those with a double major tend to have a broader set of skills and work in a broader set of jobs relative to those with single majors,” he wrote. “This might help them adapt more quickly to impacts of AI as they can draw on their broader skill set to adapt and remain competitive in the market.""

While it’s unclear why graduates with double majors offered workers this protection, the researchers speculated that it had something to do with their diversified skillsets.

“Compared to single majors concentrating in a specific occupation or industry, double majors have the flexibility to distance themselves from income shocks originating from that particular occupation or industry,” Bruce Weinberg, an Ohio State economics professor, told BI via email. “For example, when tech firms cut salaries of many computer science graduates, double majors with one major in computer science working in government sectors are not affected at all.""

Double majoring has become more common

Double majoring might do more than help workers avoid earnings shocks. A University of Pennsylvania research paper from 2021 found that double majors tended to earn more money over the course of their careers — STEM and business double majors saw the biggest income boost.

Advertisement

Having a double major has become more popular in recent decades. Between 2000 and 2008, the percentage of students who double-majored nearly doubled to roughly 6% , according to the US Department of Education. As of 2015, about 13% of Americans between ages 20 and 29 were double majors, per American Community Survey data. Roughly 10% of the individuals analyzed in the working paper were double majors.

Majoring in two subjects can be stressful and more expensive for some students. But if it helps prepare them for a future in which AI tools are more common in the workplace, this path could be worthwhile for many of them.",AI,Relevant,Relevant,
"Bankers Will See AI Transform Three-Quarters of Day, Study Says",https://slashdot.org/story/24/02/27/1542200/bankers-will-see-ai-transform-three-quarters-of-day-study-says,AI is likely to replace or at least lend a hand in tasks that take up almost three-quarters of the time bank employees now spend working. From a report:,AI,Relevant,Relevant,
"iOS 17.4 is here with alternative marketplaces, quantum protections, & battery health updates",https://appleinsider.com/articles/24/03/05/ios-174-is-here-with-alternative-marketplaces-quantum-protections-battery-health-updates,"If you buy through our links, we may get a commission. Read our ethics policy

Apple is ready for the DMA

Apple has to comply with the Digital Markets Act, making iOS 17.4 one of the biggest single updates ever, and it is now available to the public.

The latest versions of iOS and the other operating systems have arrived just in time for the EU's Digital Markets Act deadline of March 6. The launch of iOS 17.4 follows iOS 17.3, which released January 22, and iOS 17.2, which released December 11.

The build number for iOS 17.4 is 21E219. It replaces the previous release, iOS 17.3.1, which was build number 21D61.

At the same time as iOS 17.4, Apple has released updates for iOS 16.7.6, build 20H320, and iOS 15.8.2, build 19H384.

The underlying technologies behind Apple's answer to the DMA required more than 600 new APIs, expanded app analytics, functionality for alternative browser engines, and options for processing payments and distributing iOS apps. This change alone makes iOS 17.4 a contender for biggest iOS update ever, at least for developers in the EU.

There's too many details to dive into here, but the simple overview is Apple enables third-party app makers to opt for alternative distribution methods. That means apps can be downloaded from alternative marketplaces that aren't the Apple App Store.

For everyone outside the EU, iOS 17.4 is a little more mundane. It includes updates to the Battery Health menu in Settings, automatic transcripts in Apple Podcasts, a new toggle for Stolen Device Protection, and new emoji.

The Settings, Battery menu has more information under ""Battery Health,"" including Maximum Capacity percentage and Cycle Count, but only for the iPhone 15 lineup

Video reactions are can be set off by default by developers

The toggle for Spatial Video capture in Camera settings now explains that 3D video takes up twice the space as 2D video

Apple Wallet includes new permissions for providing anonymized transaction data to Apple

Apple Podcasts has a now playing bar that hovers above the UI similar to the one in visionOS

Apple Podcasts now includes machine-parsed transcripts

Owners of compatible vehicles with smart instrument clusters can display information from CarPlay

Stolen Device Protection includes a new setting that disables the trusted locations feature

Siri can now respond in multiple languages

Another significant, if invisible feature is included in iOS 17.4 called PQ3, or post-quantum computing level 3. It's a defense against a potential future where quantum computing can crack iMessage encryption.

Despite being introduced with iOS 17.2, Apple still hasn't offered any material improvements to the Journal app. The basic functionality works, but power users still wait for basic features like search and advanced filtering.",General,Relevant,Relevant,
Apple Spent More Than $10 Billion on Apple Car Before Canceling Project,https://www.macrumors.com/2024/02/28/apple-car-10-billion-spent/,"Apple spent more than $10 billion working on the Apple Car over the last decade, according to a report from The New York Times that details the issues the project faced during development. Apple first launched the project in 2014 and let it flounder for more than a decade before calling it off earlier this week.

Money was spent on research and development, along with the thousands of Apple engineers and car experts that worked on the project. Some employees within Apple are said to have suspected that the endeavor was likely to fail from the beginning, and they referred to the car as ""the Titanic disaster"" instead of its ""Project Titan"" codename.

Apple CEO Tim Cook signed off on the project, but members of the car team knew that it was going to be close to impossible. An electric vehicle with self-driving capabilities would need to cost at least $100,000, and it would have razor thin margins and stiff competition.

While Apple reportedly held discussions with Elon Musk about a possible purchase of Tesla, the company decided that building its own car made more sense than attempting to integrate Tesla into Apple. Way back in 2014, Musk said that he had ""conversations"" with Apple, but he said at the time that an acquisition seemed ""very unlikely.""

Apple was never able to find the right leader for the ‌Apple Car‌ project. As we detailed in a look back at the Apple Car's history earlier today, the project had four different leads and was scaled up and scaled back several times over the course of the last 10 years. According to The New York Times, the ultimate reason that it failed was because Apple was simply unable to develop the software and algorithms for a car with autonomous driving.

The more than 2,000 employees that worked on the car project are being redistributed, some will join other teams at Apple to work on AI and other technologies, and some will be laid off. Apple will take what it learned from the car project and apply it to other devices like AI-powered AirPods with cameras, robot assistants, and augmented reality.

More on the downfall of the ‌Apple Car‌ and some of the technologies that Apple came up with can be found in the full The New York Times report.",AI,Relevant,Relevant,
Samsung Making It Harder To Know What Type of OLED TV You're Getting,https://entertainment.slashdot.org/story/24/03/07/1920211/samsung-making-it-harder-to-know-what-type-of-oled-tv-youre-getting,"Samsung's 2024 OLED TV lineup will feature both QD-OLED and WOLED panels, making it harder for consumers to distinguish between the two technologies . The company announced three new series without specifying the panel types, but reports suggest that even within the S90D series, both QD-OLED and WOLED may be used. Samsung's decision to use both panel types is attributed to LG Display's request not to position WOLED as inferior to QD-OLED.",General,Relevant,Irrelevant,
"Exclusive: U.S. Must Move ‘Decisively’ to Avert ‘Extinction-Level’ Threat From AI, Government-Commissioned Report Says",https://time.com/6898967/ai-extinction-national-security-risks-report/,"The U.S. government must move “quickly and decisively” to avert substantial national security risks stemming from artificial intelligence (AI) which could, in the worst case, cause an “extinction-level threat to the human species,” says a report commissioned by the U.S. government published on Monday.

“Current frontier AI development poses urgent and growing risks to national security,” the report, which TIME obtained ahead of its publication, says. “The rise of advanced AI and AGI [artificial general intelligence] has the potential to destabilize global security in ways reminiscent of the introduction of nuclear weapons.” AGI is a hypothetical technology that could perform most tasks at or above the level of a human. Such systems do not currently exist, but the leading AI labs are working toward them and many expect AGI to arrive within the next five years or less.

The three authors of the report worked on it for more than a year, speaking with more than 200 government employees, experts, and workers at frontier AI companies—like OpenAI, Google DeepMind, Anthropic and Meta— as part of their research. Accounts from some of those conversations paint a disturbing picture, suggesting that many AI safety workers inside cutting-edge labs are concerned about perverse incentives driving decisionmaking by the executives who control their companies.

Read More: Employees at Top AI Labs Fear Safety Is an Afterthought, Report Says

The finished document, titled “An Action Plan to Increase the Safety and Security of Advanced AI,” recommends a set of sweeping and unprecedented policy actions that, if enacted, would radically disrupt the AI industry. Congress should make it illegal, the report recommends, to train AI models using more than a certain level of computing power. The threshold, the report recommends, should be set by a new federal AI agency, although the report suggests, as an example, that the agency could set it just above the levels of computing power used to train current cutting-edge models like OpenAI’s GPT-4 and Google’s Gemini. The new AI agency should require AI companies on the “frontier” of the industry to obtain government permission to train and deploy new models above a certain lower threshold, the report adds. Authorities should also “urgently” consider outlawing the publication of the “weights,” or inner workings, of powerful AI models, for example under open-source licenses, with violations possibly punishable by jail time, the report says. And the government should further tighten controls on the manufacture and export of AI chips, and channel federal funding toward “alignment” research that seeks to make advanced AI safer, it recommends.

The report was commissioned by the State Department in November 2022 as part of a federal contract worth $250,000, according to public records. It was written by Gladstone AI, a four-person company that runs technical briefings on AI for government employees. (Parts of the action plan recommend that the government invests heavily in educating officials on the technical underpinnings of AI systems so they can better understand their risks.) The report was delivered as a 247-page document to the State Department on Feb. 26. The State Department did not respond to several requests for comment on the report. The recommendations “do not reflect the views of the United States Department of State or the United States Government,” the first page of the report says.

The report's recommendations, many of them previously unthinkable, follow a dizzying series of major developments in AI that have caused many observers to recalibrate their stance on the technology. The chatbot ChatGPT, released in November 2022, was the first time this pace of change became visible to society at large, leading many people to question whether future AIs might pose existential risks to humanity. New tools, with more capabilities, have continued to be released at a rapid clip since. As governments around the world discuss how best to regulate AI, the world’s biggest tech companies have fast been building out the infrastructure to train the next generation of more powerful systems—in some cases planning to use 10 or 100 times more computing power. Meanwhile, more than 80% of the American public believe AI could accidentally cause a catastrophic event, and 77% of voters believe the government should be doing more to regulate AI, according to recent polling by the AI Policy Institute.

Read More: Researchers Develop New Technique to Wipe Dangerous Knowledge From AI Systems

Outlawing the training of advanced AI systems above a certain threshold, the report states, may “moderate race dynamics between all AI developers” and contribute to a reduction in the speed of the chip industry manufacturing faster hardware. Over time, a federal AI agency could raise the threshold and allow the training of more advanced AI systems once evidence of the safety of cutting-edge models is sufficiently proven, the report proposes. Equally, it says, the government could lower the safety threshold if dangerous capabilities are discovered in existing models.

The proposal is likely to face political difficulties. “I think that this recommendation is extremely unlikely to be adopted by the United States government” says Greg Allen, director of the Wadhwani Center for AI and Advanced Technologies at the Center for Strategic and International Studies (CSIS), in response to a summary TIME provided of the report’s recommendation to outlaw AI training runs above a certain threshold. Current U.S. government AI policy, he notes, is to set compute thresholds above which additional transparency monitoring and regulatory requirements apply, but not to set limits above which training runs would be illegal. “Absent some kind of exogenous shock, I think they are quite unlikely to change that approach,” Allen says.

Jeremie and Edouard Harris, the CEO and CTO of Gladstone respectively, have been briefing the U.S. government on the risks of AI since 2021. The duo, who are brothers, say that government officials who attended many of their earliest briefings agreed that the risks of AI were significant, but told them the responsibility for dealing with them fell to different teams or departments. In late 2021, the Harrises say Gladstone finally found an arm of the government with the responsibility to address AI risks: the State Department’s Bureau of International Security and Nonproliferation. Teams within the Bureau have an inter-agency mandate to address risks from emerging technologies including chemical and biological weapons, and radiological and nuclear risks. Following briefings by Jeremie and Gladstone's then-CEO Mark Beall, in October 2022 the Bureau put out a tender for report that could inform a decision whether to add AI to the list of other risks it monitors. (The State Department did not respond to a request for comment on the outcome of that decision.) The Gladstone team won that contract, and the report released Monday is the outcome.

The report focuses on two separate categories of risk. Describing the first category, which it calls “weaponization risk,” the report states: “such systems could potentially be used to design and even execute catastrophic biological, chemical, or cyber attacks, or enable unprecedented weaponized applications in swarm robotics.” The second category is what the report calls the “loss of control” risk, or the possibility that advanced AI systems may outmaneuver their creators. There is, the report says, “reason to believe that they may be uncontrollable if they are developed using current techniques, and could behave adversarially to human beings by default.”

Both categories of risk, the report says, are exacerbated by “race dynamics” in the AI industry. The likelihood that the first company to achieve AGI will reap the majority of economic rewards, the report says, incentivizes companies to prioritize speed over safety. “Frontier AI labs face an intense and immediate incentive to scale their AI systems as fast as they can,” the report says. “They do not face an immediate incentive to invest in safety or security measures that do not deliver direct economic benefits, even though some do out of genuine concern.”

The Gladstone report identifies hardware—specifically the high-end computer chips currently used to train AI systems—as a significant bottleneck to increases in AI capabilities. Regulating the proliferation of this hardware, the report argues, may be the “most important requirement to safeguard long-term global safety and security from AI.” It says the government should explore tying chip export licenses to the presence of on-chip technologies allowing monitoring of whether chips are being used in large AI training runs, as a way of enforcing proposed rules against training AI systems larger than GPT-4. However the report also notes that any interventions will need to account for the possibility that overregulation could bolster foreign chip industries, eroding the U.S.’s ability to influence the supply chain.

Read More: What to Know About the U.S. Curbs on AI Chip Exports to China

The report also raises the possibility that, ultimately, the physical bounds of the universe may not be on the side of those attempting to prevent proliferation of advanced AI through chips. “As AI algorithms continue to improve, more AI capabilities become available for less total compute. Depending on how far this trend progresses, it could ultimately become impractical to mitigate advanced AI proliferation through compute concentrations at all.” To account for this possibility, the report says a new federal AI agency could explore blocking the publication of research that improves algorithmic efficiency, though it concedes this may harm the U.S. AI industry and ultimately be unfeasible.

The Harrises recognize in conversation that their recommendations will strike many in the AI industry as overly zealous. The recommendation to outlaw the open-sourcing of advanced AI model weights, they expect, will not be popular. “Open source is generally a wonderful phenomenon and overall massively positive for the world,” says Edouard, the chief technology officer of Gladstone. “It’s an extremely challenging recommendation to make, and we spent a lot of time looking for ways around suggesting measures like this.” Allen, the AI policy expert at CSIS, says he is sympathetic to the idea that open-source AI makes it more difficult for policymakers to get a handle on the risks. But he says any proposal to outlaw the open-sourcing of models above a certain size would need to contend with the fact that U.S. law has a limited reach. “Would that just mean that the open source community would move to Europe?” he says. “Given that it's a big world, you sort of have to take that into account.”

Read More: The 3 Most Important AI Policy Milestones of 2023

Despite the challenges, the report’s authors say they were swayed by how easy and cheap it currently is for users to remove safety guardrails on an AI model if they have access to its weights. “If you proliferate an open source model, even if it looks safe, it could still be dangerous down the road,” Edouard says, adding that the decision to open-source a model is irreversible. “At that point, good luck, all you can do is just take the damage.”

The third co-author of the report, former Defense Department official Beall, has since left Gladstone in order to start a super PAC aimed at advocating for AI policy. The PAC, called Americans for AI Safety, officially launched on Monday. It aims to make AI safety and security ""a key issue in the 2024 elections, with a goal of passing AI safety legislation by the end of 2024,"" the group said in a statement to TIME. The PAC did not disclose its funding commitments, but said it has ""set a goal of raising millions of dollars to accomplish its mission.""

Before co-founding Gladstone with Beall, the Harris brothers ran an AI company that went through YCombinator, the famed Silicon Valley incubator, at the time when OpenAI CEO Sam Altman was at the helm. The pair brandish these credentials as evidence they have the industry’s interests at heart, even as their recommendations, if implemented, would upend it. “Move fast and break things, we love that philosophy, we grew up with that philosophy,” Jeremie tells TIME. But the credo, he says, ceases to apply when the potential downside of your actions is so massive. “Our default trajectory right now,” he says, “seems very much on course to create systems that are powerful enough that they either can be weaponized catastrophically, or fail to be controlled.” He adds: “One of the worst-case scenarios is you get a catastrophic event that completely shuts down AI research for everybody, and we don't get to reap the incredible benefits of this technology.”

Are you an employee at an AI lab and have concerns that you might consider sharing with a journalist? You can contact the author of this piece on Signal at billyperrigo.01",AI,Relevant,Relevant,
Palantir Wins US Army Contract For Battlefield AI,https://tech.slashdot.org/story/24/03/08/2356216/palantir-wins-us-army-contract-for-battlefield-ai,"Lindsay Clark reports via The Register:On Thursday, Palantir was one of the companies included in a new U.S. consortium assembled to support the safe development and deployment of generative AI.",AI,Relevant,Relevant,
When You Have to Make a Strategic Decision Without Much Data,https://hbr.org/2024/03/when-you-have-to-make-a-strategic-decision-without-much-data,"New!

HBR Learning

Sharpening Your Business Acumen Course

Accelerate your career with Harvard ManageMentor®. HBR Learning’s online leadership training helps you hone your skills with courses like Sharpening Your Business Acumen. Earn badges to share on LinkedIn and your resume. Access more than 40 courses trusted by Fortune 500 companies.

Take your career to the next level by learning business and finance basics, and developing an enterprise mindset.",General,Relevant,Irrelevant,
Apple reportedly testing AI-driven ad placements in App Store strategy,https://readwrite.com/apple-reportedly-testing-ai-driven-ad-placements-in-app-store-strategy/,"Apple is reportedly experimenting with an AI-driven advertising platform, partnering with a select group of collaborators, according to Business Insider. This cutting-edge tool is allegedly designed to optimize ad placements within the App Store, potentially enhancing the performance of App Store Search Ads. While AI in advertising is not new, with giants like Google and Facebook already implementing such technologies, Apple’s foray into this space marks a significant development, given its relatively limited advertising options.

Presently, Apple offers a few ad formats within the App Store, allowing developers to promote their apps in the Today tab, the Search tab, top of search results, and at the bottom of app product pages. The company also manages advertising campaigns for the News and Stocks apps, though these are largely coordinated through third parties like NBCUniversal.

Despite being in its infancy, Apple’s advertising venture is poised for substantial growth, with some analysts projecting the company’s ad business to surge to $6 billion by 2025, fueled primarily by Search Ads contributing $4.1 billion, according to a recent AppleInsider report.

The shift toward AI-driven advertising is reshaping the industry, offering targeted efficiency for advertisers and personalized experiences for users. With AI, advertisers can pinpoint their audience with greater accuracy, improving ad spend effectiveness and user engagement. This technology allows for real-time analysis of user preferences, ensuring ads displayed are more relevant and appealing.

Business Insider speculates that the adoption of AI for ad placement could signal Apple’s intentions to expand its ad-supported services, not only within the App Store but across its ecosystem. An AI placement tool could become increasingly vital as Apple potentially introduces more Search Ads slots and explores new avenues for ad display, including other system apps.",AI,Relevant,Relevant,
Robo Dog based on German Shepard can bound up stairs. Meet Tecno 1,https://readwrite.com/techno-1-robo-dog-unleashed-at-mwc-barcelona/,"Chinese firm Tecno has set their robot dog, the Tecno Dynamic 1, loose at the Mobile World Conference 2024 (MWC2024). The conference is a showcase of the best-in-show of mobile developments and updates coming to consumers in the near future.

“MWC Barcelona is the largest and most influential event for the connectivity ecosystem. Whether you’re a global mobile operator, device manufacturer, technology provider, vendor, content owner, or are simply interested in the future of tech, you need to be here,” says the site’s announcement page.

The event is taking place in Barcelona , Spain, and attendees of MC2024 got to see the mobile company’s cybernetic canine up close.

Based on a German Shepard, the robot dog has been designed with a coolant system inside the joints to copy man’s best friend’s motions but looks like it is straight out of a dystopian world with its sleek black design and intimidating stance.

The robot can beg, ask for a paw, and bound up a flight of stairs, setting an impressive pace at 8.3 miles an hour. The device has a battery life of 90 minutes for continuous use and charges via a 15,000mAh battery. So there will be a limit to how much the powered pooch can play a part in the life of a prospective owner.

Android Headlines captured footage of loyal companion in action and posted it to X:

This is the Tecno Dynamic 1! We thought robots were gonna replace humans…it might be dogs that get replaced. pic.twitter.com/CLgRT7FtDr — Android Headlines (@Androidheadline) February 26, 2024

Droid Dog

The metal hound’s head boasts four microphones to pick up audio commands that are interpreted by an artificial intelligence recognition system.

The mobile company has designed the dog to be fully controllable via smartphone across Bluetooth and home WiFi devices and comes with 64GB of internal storage.

Its AI HyperSense Fusion System is powered by an 8-core central processing unit and an Intel RealSense D430 depth camera module to help the binocular sensors and infrared sensors interpret the world around it and detect obstacles.

This cybernetic companion is just one of a raft of announcements in the robotics world as the technology becomes more ever-present in the real world.",Robotics,Relevant,Relevant,
‘Too Close for Comfort’: Two Satellites Nearly Collide Above Earth,https://gizmodo.com/satellite-near-miss-leo-labs-fcc-rules-space-safety-1851293980,"In a tense moment for space safety, two satellites—NASA’s TIMED spacecraft and the defunct Russian Cosmos 2221—came alarmingly close to smashing into each other above Earth, prompting concerns about the risks of space debris.

Taking out the Trash (in Space) CC Share Subtitles Off

English view video Taking out the Trash (in Space)

The near miss happened at approximately 1:30 a.m. ET Wednesday, as the two satellites brushed past each other some 378 miles (608 kilometers) above Earth, according to LeoLabs, a California-based company specializing in tracking and analyzing objects in Low Earth Orbit.

Advertisement

The satellites in question were NASA’s Thermosphere Ionosphere Mesosphere Energetics and Dynamics Mission (TIMED) spacecraft, launched in 2001 to study the Sun and Earth’s upper atmosphere, and the Russian Cosmos 2221, a defunct defense satellite launched in 1992. LeoLabs reported that the two satellites came within a mere 66 feet (20 meters) of each other. Considering the speed at which these objects travel–over 17,500 miles per hour (28,165 kilometers per hour)–this was “too close for comfort,” as the company said on X. Both of these spacecraft lack maneuverability, leaving ground observers with no choice but to watch helplessly, without the ability to intervene.

Advertisement

Advertisement

“Indeed, the two satellites likely passed within 20 meters of each other,” LeoLabs’ senior technical fellow Darren McKnight explained to Gizmodo in an email. “We monitor over 20,000 objects in Low Earth Orbit (LEO) using our 10 phased array radars worldwide. We can identify and update the orbital trajectories of all of these objects several times a day.”

NASA, in a statement, acknowledged that, had the satellites collided, it would have led to “significant debris generation.” Such an event would have increased the risk of further collisions in a wide area of LEO, particularly affecting the lower orbits frequently used by satellite constellations and crewed space missions.

Advertisement

LeoLabs further analyzed the potential impact of a collision, suggesting it could have generated approximately 2,000 to 7,000 trackable fragments. This estimate considers the total mass, construction, relative velocity, and the angle of impact of the spacecraft. As of February 15, there are around 12,000 fragments in LEO, and this incident could have potentially increased this number by 50%, the company claims.

Such near-misses are rare, according to LeoLabs, with only six events in the past two years featuring a miss distance of less than 66 feet between “two intact, non-maneuverable objects.” Clearly, this latest incident highlights the growing concerns over space debris and the need for improved monitoring and mitigation strategies to ensure the safety of current and future space missions.

Advertisement

“This event is indicative of an increasing number of near misses in LEO,” McKnight said. “Some altitude regions are worse than others, but generally half of the population in LEO is comprised of fragments and massive derelict objects,” including abandoned rocket bodies and non-operational payloads. Large derelict objects represent just 12% of the total number in space, he said, yet they account for 45% of the total mass. This is significant, as collisions between these large objects can create thousands of fragments, escalating the risk of further impacts. “Lastly, constellations of smallsats are being deployed on a regular basis and their resiliency requires space traffic coordination processes and technologies to ensure their long-term safe operations,” McKnight added.

To date, only once has a satellite smashed into another. This occurred in 2009 when Iridium 33, a U.S. communications satellite, and Kosmos-2251, a defunct Russian military satellite, collided in orbit some 490 miles (789 kilometers) above Siberia. It’s the most “severe accidental fragmentation on record,” with the event producing more than 1,800 pieces of debris larger than 3.9 inches (10 centimeters), according to NASA.



Advertisement

Thankfully, incidents like this should decrease over time owing to newly implemented rules from the Federal Communications Commission, which require satellite providers to retire their satellites within five years of completing their missions, reducing the risk of space debris and potential collisions.

For more spaceflight in your life, follow us on X (formerly Twitter) and bookmark Gizmodo’s dedicated Spaceflight page.",General,Relevant,Irrelevant,
AI and wearables are scaring the wellbeing out of workers,https://www.theregister.com/2024/03/14/advanced_workplace_tech_study/,"A survey of UK workers suggests that quality of life declines as exposure to newer technology including wearables, robotics, and AI rises in the workplace.

The study, published by the Institute for the Future of Work (IFOW), quizzed thousands of workers to come up with its conclusion, which it said has significant implications for policy, regulation, and employers.

Not all technologies are tied negatively to wellbeing, however.

""Results showed that digital information and communication technologies correlated with improved quality of life, whereas newer and more advanced technologies were correlated with reduced wellbeing,"" the study [PDF] says. Those correlations held across various demographics and roles and ""after accounting for more influential factors,"" the study notes.

In other words, give workers access to computers, messaging tools, and other connected technologies that give them the ability to work with more freedom and flexibility and they're happy. Force them to wear smart devices or inject AI into their jobs and the opposite is true.

It's hardly surprising, but as the report points out, it's the first time someone's bothered to actually do the work to triangulate worker wellbeing and tech exposure.

""Research and public policy have tended to treat technology and wellbeing separately, and disproportionately focus on job loss and employment,"" the authors write in a summary brief [PDF]. ""Far less attention has been given to how workplace technologies are impacting job quality, and workers' quality of life.""

If you've followed recent news about cutting-edge business technologies like AI you probably aren't too surprised about the IFOW's findings – after all, we've been reporting on the threats to jobs posed by AI and corresponding reports that the technology would ""augment"" millions of jobs in the next few years with regularity.

Companies like IBM have even said openly that they intend to replace workers with AI. It's no wonder the tech makes worker wellbeing suffer – when employees hear their boss has AI aspirations or plans to monitor them more closely at work, it's natural for the cortisol levels to spike.

The study didn't investigate the cause of that negative correlation with exposure to new technology, but said previous research has demonstrated why AI, robotics, and worker monitoring technologies may be a stressor.

""Such technologies may exacerbate job insecurity, workload intensification, routinisation and loss of work meaningfulness, as well as disempowerment and loss of autonomy, all of which detract from overall employee wellbeing,"" the study says.

Good vs bad automation

That doesn't mean new technologies necessarily spell doom for employee happiness – it's all about implementation.

In organizations with HR philosophies that emphasize employee wellbeing over productivity, there was a positive correlation with quality of life, and the same goes for workplaces where employees feel they have their rights respected at work.

""The results of this research lead us to hypothesise that the relationship between technology use and wellbeing may be mediated by a range of factors including work-related capabilities and job quality,"" the authors conclude. They note, however, that such a hypothesis needs additional research, and caution against using the results as a one-size-fits-all view of tech in the workplace.

Employers who don't want an office filled with miserable drudges should involve everyone affected by new technologies in the implementation process, and ensure they have access to information needed to help them understand the role such technology will play in their work. Policies also need to be enacted to incentivize firms adopting advanced tech to prioritize employee wellbeing, the paper notes.

""A future of 'good automation' is possible … but this will take concerted action and alignment across different departments and domains,"" the researchers say. ®",Communications Technologies,Relevant,Relevant,
The AI party is just getting started': Here's what Wall Street expects from Nvidia's 4th-quarter earnings,https://markets.businessinsider.com/news/stocks/nvidia-earnings-preview-what-wall-street-expects-nvda-ai-2024-2,"Nvidia is set to report its fourth-quarter earnings after the market close on Wednesday.

The highly anticipated report will shed light on the booming AI business in the tech space.

Here's what Wall Street expects from Nvidia's upcoming earnings report.

NEW LOOK Sign up to get the inside scoop on today’s biggest stories in markets, tech, and business — delivered daily. Read preview Thanks for signing up! Access your favorite topics in a personalized feed while you're on the go. download the app Email address Sign up By clicking “Sign Up”, you accept our Terms of Service and Privacy Policy . You can opt-out at any time.

Advertisement

All eyes are on Nvidia as it is scheduled to report its fourth-quarter earnings results on Wednesday after the market close.

Nvidia has spearheaded the excitement seen in artificial intelligence technologies, and investors will look to the company's results to see if the hype can continue.

Wall Street analysts are laser focused on the company's demand outlook for its AI-enabled H100 GPU chips, which can sell for upwards of $40,000, as well as its planned product roadmap over the next year.

Here are the quarterly figures Wall Street expects from Nvidia, according to data from Bloomberg:

Advertisement

Revenue: $20.41 billion

$20.41 billion GAAP earnings per share: $4.23

$4.23 Adjusted earnings per share: $4.60

$4.60 Gross margin: 75.4%

While Nvidia has seen incredible demand for its chips from cloud hyperscalers like Microsoft and Amazon, regulatory hurdles have curtailed its ability to sell chips to China, which made up about 20% of its total revenue last year.

Driving much of the strength in Nvidia's business has been its exposure to data-centers. Investors will be looking to see just how much demand could be left for the data-center market, and whether Nvidia has lost any market share to its competitors like AMD.

Here's what Wall Street analysts are saying about Nvidia's upcoming earnings report.

Advertisement

1. Wedbush: 'Get the popcorn ready'

Wedbush analyst Dan Ives said in a note on Monday that Nvidia's quarterly results and outlook will hinge on enterprise spending.

""The AI revolution starts with Nvidia and in our view the AI party is just getting started,"" Ives said.

""While the Street across the board is anticipating another major 'beat and raise' special from Jensen & Co. its all about the pace of data center AI driven spending as the only game in town for GPUs to run generative AI applications all go through Nvidia. We believe peak spending is still ahead for the AI market as many enterprises head down the AI use case path over the next few years and we are expecting more good news from the Godfather of AI this week,"" Ives said.

""We are laser focused on what the trajectory of GPU orders and demand flow looks like from enterprises,"" Ives said.

Advertisement

2. Bank of America: 'Notable but measured beat'

Bank of America expects Nvidia to modestly beat analyst expectations on Wednesday, but not by the margins it has in the past.

The bank said Nvidia could beat earnings by 3% and raise its outlook by 5%, which would be significantly lower than the company's prior earnings beat of 10% and guidance boost of 22%.

""The more measured pace will also be seen as creating more fertile ground for continued growth in CY25 and beyond,"" Bank of America said.

The bank expects investors' focus on Nvidia after earnings will be its product roadmap, which could be showcased at its GPU Tech Conference in mid-March.

Advertisement

Bank of America rates Nvidia at ""Buy"" and calls it a ""Top Pick"" with a $800 price target.

Bloomberg Intelligence: 'Nvidia to maintain stronghold in data-center market'

Bloomberg Intelligence associate Oscar Tejada said in a Friday note that Nvidia will likely impress investors on Wednesday.

""With supply visibility for Nvidia's GPUs improving, yet still behind demand, and appetite for generative AI not slowing, Nvidia will likely report another solid 4Q, with a positive outlook toward 2025,"" Tejada said.

But another double-digit beat and raise from Nvidia is unlikely amid rising supply of Nvidia's GPUs and shortened lead times for its customers.

Advertisement

""Nvidia's focus on securing more supply and diversifying into Enterprise and Sovereign projects should reaffirm continued demand through 2025. Also, hyperscale cloud service providers like Meta and Microsoft continue to invest in AI-powered data centers, despite proprietary chip projects,"" Tejada said.",AI,Relevant,Relevant,
Three Interpretations of Matrix Products,https://www.linearalgebraforprogrammers.com/blog/matmul_animations,"Three interpretations of matrix products

This article explores three different interpretations of matrix products with the help of animations. Each of them provides a different perspective on the matrix product and can be useful in different contexts.

0. Prerequisites and notations

A row vector is shown as a horizontal rectangle and a column vector as a vertical rectangle. The scalar numbers are shown as circles.

A circle next to a rectangle represents the scalar multiplication of the number with the vector. The color of the circle and the rectangle are the same to indicate that they are related.

column vector row vector number number * column vector number * row vector

Finally, the outer product of a column vector and a row vector is shown as a vertical rectangle joined with a horizontal rectangle on the top left corner. This visual aid should make sense if you are familiar with the concept of outer products.

= An outer product of a column vector and a row vector

That's it! On to the visualizations now.

1. Interpretation #1: Weighted sum of columns or rows

Scaling a vector by a scalar quantity defined as multiplying each of the vector's components by the scalar. Adding two vectors is defined as adding their corresponding components. This interpretation is quite useful when using matrices in geometry or any visual application. Eg taking a convex sum of n points in a 2D plane (or any higher-dimensional space).

1.1 Matrix vector product as a weighted sum of columns

+ + A matrix vector product can be seen as scaling the columns and then adding them up

1.2 Vector matrix product as a weighted sum of rows

+ + A vector matrix product can be seen as scaling the rows and then adding them up

Note the duality between the two interpretations. The first one is useful when you want to think of the matrix as a collection of columns and the second one is useful when you want to think of the matrix as a collection of rows.

This is covered in more detail in Geometry of weighted sums

2. Interpretation #2: Dot products of columns or rows with input vector

A dot product is a function that takes two vectors of equal length and returns a scalar quantity. It is defined as the sum of the products of the corresponding components of the two vectors.

2.1 Matrix vector product as a dot product of rows with input vector

= A matrix vector product can be seen as list of dot products of each row with the input vector.

2.2 Vector matrix product as a dot product of columns with input vector

= A vector matrix product can be seen as a list of dot products of each column with the input vector.

One needs to have some understanding of the dot product to appreciate this interpretation. It is covered in more detail in The Dot Product of Two Vectors (paywalled).

3. Interpretation #3: Matrix-matrix product as the sum of outer products

This is a less common interpretation but is quite useful. An outer product is a function that takes two vectors of arbitrary lengths and returns a matrix. There are two ways to look at this matrix:

1. Each column of the output matrix is the first vector scaled by the corresponding component of the second vector. 2. Each row of the output matrix is the second vector scaled by the corresponding component of the first vector.

A matrix-matrix product can be seen as a sum of outer products of the columns of the first matrix with the rows of the second matrix. This interpretation is useful in studying the spectral properties of symmetric matrices. Eg the product of a symmetric matrix with a vector can be seen as a sum of projections of the vector onto the eigenvectors of the matrix (scaled by the corresponding eigenvalues).

= + + A matrix vector product can be seen as scaling the columns and then adding them up

This is covered in more detail in Symmetric Mv Product (paywalled).

I find this interpretation quite beautiful. Note that when the number of columns in the second matrix is one, it reduces to the weighted sum of columns interpretation. Similarly when the number of rows in the first matrix is one, it reduces to the weighted sum of rows interpretation.",General,Relevant,Irrelevant,
Nvidia sued over AI training data as copyright clashes continue,https://arstechnica.com/tech-policy/2024/03/novelists-sue-nvidia-to-stop-spread-of-ai-models-trained-on-copyrighted-books/,"Book authors are suing Nvidia, alleging that the chipmaker's AI platform NeMo—used to power customized chatbots—was trained on a controversial dataset that illegally copied and distributed their books without their consent.

In a proposed class action, novelists Abdi Nazemian (Like a Love Story), Brian Keene (Ghost Walk), and Stewart O’Nan (Last Night at the Lobster) argued that Nvidia should pay damages and destroy all copies of the Books3 dataset used to power NeMo large language models (LLMs).

The Books3 dataset, novelists argued, copied ""all of Bibliotek,"" a shadow library of approximately 196,640 pirated books. Initially shared through the AI community Hugging Face, the Books3 dataset today ""is defunct and no longer accessible due to reported copyright infringement,"" the Hugging Face website says.

According to the authors, Hugging Face removed the dataset last October, but not before AI companies like Nvidia grabbed it and ""made multiple copies."" By training NeMo models on this dataset, the authors alleged that Nvidia ""violated their exclusive rights under the Copyright Act."" The authors argued that the US district court in San Francisco must intervene and stop Nvidia because the company ""has continued to make copies of the Infringed Works for training other models.""

A Hugging Face spokesperson clarified to Ars that ""Hugging Face never removed this dataset, and we did not host the Books3 dataset on the Hub."" Instead, ""Hugging Face hosted a script that downloads the data from The Eye, which is the place where ELeuther hosted the data,"" until ""Eleuther removed the data from The Eye"" over copyright concerns, causing the dataset script on Hugging Face to break.

Advertisement

Nvidia's spokesperson told the Wall Street Journal that “we respect the rights of all content creators and believe we created NeMo in full compliance with copyright law.""

Demanding a jury trial, authors are hoping the court will rule that Nvidia has no possible defense for both allegedly violating copyrights and intending ""to cause further infringement"" by distributing NeMo models ""as a base from which to build further models.""

AI models decreasing transparency amid suits

The class action was filed by the same legal team representing authors suing OpenAI, whose lawsuit recently saw many claims dismissed, but crucially not their claim of direct copyright infringement. Lawyers told Ars last month that authors would be amending their complaints against OpenAI and were ""eager to move forward and litigate"" their direct copyright infringement claim.

In that lawsuit, the authors alleged copyright infringement both when OpenAI trained LLMs and when chatbots referenced books in outputs. But authors seemed more concerned about alleged damages from chatbot outputs, warning that AI tools had an ""uncanny ability to generate text similar to that found in copyrighted textual materials, including thousands of books.""

Uniquely, in the Nvidia suit, authors are focused exclusively on Nvidia's training data, seemingly concerned that Nvidia could empower businesses to create any number of AI models on the controversial dataset, which could affect thousands of authors whose works could allegedly be broadly infringed just by training these models.

There's no telling yet how courts will rule on the direct copyright claims in either lawsuit—or in the New York Times' lawsuit against OpenAI—but so far, OpenAI has failed to convince courts to toss claims aside.

Advertisement

However, OpenAI doesn't appear very shaken by the lawsuits. In February, OpenAI said that it expected to beat book authors' direct copyright infringement claim at a ""later stage"" of the case and, most recently in the New York Times case, tried to convince the court that NYT ""hacked"" ChatGPT to ""set up"" the lawsuit.

And Microsoft, a co-defendant in the NYT lawsuit, even more recently introduced a new argument that could help tech companies defeat copyright suits over LLMs. Last month, Microsoft argued that The New York Times was attempting to stop a ""groundbreaking new technology"" and would fail, just like movie producers attempting to kill off the VCR in the 1980s.

""Despite The Times's contentions, copyright law is no more an obstacle to the LLM than it was to the VCR (or the player piano, copy machine, personal computer, Internet, or search engine),"" Microsoft wrote.

In December, Hugging Face's machine learning and society lead, Yacine Jernite, noted that developers appeared to be growing less transparent about training data after copyright lawsuits raised red flags about companies using the Books3 dataset, ""especially for commercial models.""

Meta, for example, ""limited the amount of information [it] disclosed about"" its LLM, Llama-2, ""to a single paragraph description and one additional page of safety and bias analysis—after [its] use of the Books3 dataset when training the first Llama model was brought up in a copyright lawsuit,"" Jernite wrote.

Jernite warned that AI models lacking transparency could hinder ""the ability of regulatory safeguards to remain relevant as training methods evolve, of individuals to ensure that their rights are respected, and of open science and development to play their role in enabling democratic governance of new technologies."" To support ""more accountability,"" Jernite recommended ""minimum meaningful public transparency standards to support effective AI regulation,"" as well as companies providing options for anyone to opt out of their data being included in training data.

""More data transparency supports better governance and fosters technology development that more reliably respects peoples’ rights,"" Jernite wrote.",AI,Relevant,Relevant,
T-Mobile parent company wants to create an AI phone with no apps,https://readwrite.com/t-mobile-parent-company-wants-to-create-an-ai-phone-with-no-apps/,"An app-free smartphone is the future goal of Deutsche Telekom which is championing a first-ever artificial intelligence (AI) phone concept together with Qualcomm Technologies, Inc. and Brain.ai.

Announced via a press release on the Telekom website last Thursday (Feb. 15), the idea involves: ‘An assistant based on artificial intelligence replac(ing) the countless apps on the smartphone. Like a concierge, the assistant understands your goals and takes care of the details.’

An app-free smartphone design is being created where the AI can predict and generate the next interface contextually, based on the user’s flowing thoughts. The AI will be located in the cloud.

The aim is for this to take over the functions of a wide range of apps, with the ability to carry out all daily tasks via voice command. The Deutsche Telekom’s generative interface will be powered by Brain.ai. The German company, known for its telecommunications brand T-Mobile, is set to present its idea at the Mobile World Congress 2024 which takes place in Barcelona next week (26 – 29 Feb).

Chief Product and Digital Officer Jon Abrahamson shares more via the company website: “Artificial intelligence and Large Language Models (LLM) will soon be an integral part of mobile devices.

“We will use them to improve and simplify the lives of our customers. Our vision is a magenta concierge for an app-free smartphone. A real everyday companion that fulfills needs and simplifies digital life.”

Announcements at the Mobile World Congress 2024

More information is likely to be shared next week when the idea is unveiled with industry experts. Deutsche Telekom will be showcasing another version of an AI smartphone alongside this idea, which will be powered by the Snapdragon® 8 Gen 3 Reference Design.

The conference will be attended by global mobile operators, device manufacturers, technology providers, vendors, and content owners. This will include the likes of Meta Platforms Inc, Orange, 3Tech Corporate Limited, and many more.

Featured Image: Photo by Rahul Chakraborty on Unsplash",AI,Relevant,Relevant,
UK offers £15M to space tech projects for commercial astronaut mission,https://thenextweb.com/news/uk-funding-space-tech-projects-commercial-astronaut-mission,"The UK Space Agency has opened two funding calls for tech and science projects to fly onboard a prospective, commercially-sponsored mission.

The calls are in preparation of an agreement between the UK and Axiom Space, a US company that organises visits to the International Space Station (ISS). The partnership aims to launch a British astronaut mission, potentially to the ISS. The £15mn (€17.5mn) funding will depend on whether the mission will actually proceed.

“We want to keep the UK space sector at the forefront of scientific discovery and technological innovation, so this has been front and centre of our work with Axiom Space since October,” said Annelies Look, Deputy CEO of the UK Space Agency.

Space tech wanted

The UK is calling for technology demonstrators that can support exploration and test innovative solutions within a space environment.

It’s primarily seeking projects from the following technologies: AI, engineering biology, future telecommunications, semiconductors, and quantum. It’s also looking for solutions that align with the space agency’s tech roadmap, which prioritises advanced manufacturing, in-situ resource utilisation, life support, and crew performance

Interested candidates can apply until April 29. Awarded projects need to start by June 2024, with the development process lasting 18 months.

UK pushes for space tech leadership

The UK has been betting heavily on space tech, aiming to benefit from the growing commercialisation of space exploration and the global space economy — estimated to reach $1tn (€897bn) by 2040.

Besides public investment, the country boasts significant private funding. According to data by VC firm Seraphim, in the third quarter of 2023, the UK almost doubled its total year-on-year investment to $326mn (€301.7mn). The country also aims to host the first vertical rocket launches from Western Europe, while it’s home to many startups innovating in the sector, including Open Cosmos and Space Forge.",General,Relevant,Relevant,
Alibaba headlines record funding for $2.5 billion Chinese AI startup,https://readwrite.com/alibaba-headlines-record-funding-for-2-5-billion-chinese-ai-startup/,"Alibaba Group Holding Ltd. is the headline backer supporting the largest single financing round for a significant Chinese artificial intelligence (AI) initiative.

The e-commerce giant led the funding in Moonshot AI, with the $1 billion round turbo-charging the new company’s valuation to the tune of $2.5 billion, according to sources close to Bloomberg. Existing backers Monolith Management, Long-Z, and Hongshan also returned to the table.

Alibaba’s backing for the startup appears to indicate the allocation of capital in the pursuit of growth, as it follows the path taken by the likes of Tencent Holdings and Microsoft in placing faith in Generative AI. It is the emerging technology powering applications such as ChatGPT as industries move toward AI.

Change of direction

Under the new leadership of chairman Joseph Tsai and CEO Eddie Wu, Alibaba aims to reverse its fortunes after two years of struggles beset by regulatory scrutiny and an economic downturn. The duo are leading the foray into new technologies with key investments while also diverging business lines into areas such as cloud tech and logistics.

Tsai indicated the cloud space now hosts half of China’s Generative AI firms while also serving around 80% of the country’s technology companies.

Moonshot AI will mark its first anniversary next month, so this landmark valuation on the back of the funding deal will provide a timely boost as it aims to build on its reputation as a player in the Chinese AI field. It has ambitions to eventually challenge OpenAI and Google, having launched its Kimi chatbot last November, followed by a platform for developers to build AI applications plugged into its model.

The news has emerged, with the parties involved appearing reticent to comment on developments. At the time of writing, there has been no official statement from Moonshot, while Monolith and Alibaba have not offered any comment on the investment funding, first reported by local Chinese media, including 36kr.

Image: Alibaba/X",AI,Relevant,Relevant,
Company Trying to Resurrect a Mammoth Makes a Stem Cell Breakthrough,https://gizmodo.com/colossal-biosciences-elephant-stem-cells-woolly-mammoth-1851312096,"Colossal Biosciences, which calls itself “the world’s first de-extinction company,” has created stem cells it thinks will hasten the company’s marquee goal of resurrecting the woolly mammoth. The team’s research describing the accomplishment will be hosted on the preprint server bioRxiv.



What Drew John Boyega Back Into Sci-Fi? | io9 Interview CC Share Subtitles Off

English view video What Drew John Boyega Back Into Sci-Fi? | io9 Interview

The cells are induced pluripotent stem cells (iPSC), a type of cell that can be reprogrammed to develop into any other type of cell. The cells are especially useful in bioengineering, for their applications in cell development, therapy, and transferring genetic information across species. Colossal’s new iPSCs are the first engineered elephant cells converted into an embryonic state, a useful development if you’re in pursuit of a woolly mammoth. Or rather, an animal that looks like a woolly mammoth.

Advertisement

“In the past, a multitude of attempts to generate elephant iPSCs have not been fruitful. Elephants are a very special species and we have only just begun to scratch the surface of their fundamental biology,” said Eriona Hysolli, who heads up Colossal’s biological sciences team, in a statement. “The Colossal mammoth team persisted quite successfully as this progress is invaluable for the future of elephant assisted reproductive technologies as well as advanced cellular modeling of mammoth phenotypes.”

Advertisement

According to the Colossal release, the new stem cells were able to differentiate into the three germ layers that result in every cell type. “It opens the door to establishing connections between genes and traits for both modern and extinct relatives—including resistance to environmental extremes and pathogens,” said George Church, a geneticist and co-founder of Colossal, in a press release.

Advertisement

The animals Colossal hopes to produce will be Asian elephants (E. maximus), genetically engineered to be resistant to the cold and, most notably, covered in shaggy hair à la woolly mammoth, their extinct cousin. Colossal also has plans to produce approximate (or “proxy”) species of the Tasmanian tiger or thylacine, which went extinct around 1936, and the dodo, a flightless bird native to Mauritius, which was gone by 1681. Other companies—namely Revive & Restore—have similar aims with other species, including the heath hen and passenger pigeon.

A proxy species isn’t truly the old creature brought back to life. As described in a 2016 report by the International Union for Conservation of Nature’s Species Survival Commission, “Proxy is used here to mean a substitute that would represent in some sense (e.g. phenotypically, behaviourally, ecologically) another entity – the extinct form.” The group added that “Proxy is preferred to facsimile, which implies creation of an exact copy.”

Advertisement

One expert who spoke to Gizmodo previously referred to the end-goals of these companies as “something out of Lovecraft” and the elephantine effort as a “simulacrum that has no phylogenetic relationship with actual mammoths.”

Advertisement

It’s not just a question of having biological material from an extinct animal. Researchers exploring the possibility of ‘resurrecting’ the Christmas Island rat found that some genetics were simply lost to time, in spite of the amount that could be gleaned from historic tissues and its nearest extant relatives. One member of the team told Gizmodo that ​​“We aren’t actually planning to do it, as probably the world doesn’t need any more rats, and probably the money it would take to do the best job possible could be spent on better things, e.g., conserving living things.” (That researcher is now a member of Colossal’s advisory board.) Nevertheless, the production of elephant iPSCs is a step toward producing these proxy animals, an aim that many scientists see as likely but fewer see as useful.

Once Colossal produces a herd of proxy mammoths, its intention is to decelerate the melting of the permafrost by loosing the animals on a swath of Siberia. Ultimately, Colossal says, the mammoth steppe—the ancient ecosystem in which the giant proboscideans roamed—could be restored, helping fight climate change and pushing new technologies in gene editing in the process, helping extant elephants, which face their own survival threats.

Advertisement

But other technological breakthroughs will be necessary to make any of that possible. As noted by Nature, Church intends to use artificial elephant wombs to produce the proxy mammoths, so as to not require Asian elephant surrogates. Asian elephants are an endangered species; to use them as surrogates for proxy mammoths would be the cherry-on-top of an ethical dilemma sundae.

We’re still a long way off from Colossal’s ultimate goals, but this recent achievement is a significant one, and a reminder that these ‘de-extinction’ efforts involve serious science.",General,Relevant,Irrelevant,
OpenAI claims New York Times misused ChatGPT to fabricate lawsuit evidence,https://readwrite.com/openai-claims-new-york-times-misused-chatgpt-to-fabricate-lawsuit-evidence/,"OpenAI has requested a federal judge to dismiss parts of a copyright lawsuit filed by The New York Times, accusing the newspaper of employing deceptive tactics to generate misleading evidence, according to a recent Reuters report. The lawsuit, which centers around the alleged unauthorized use of the Times’ copyrighted material to train OpenAI’s artificial intelligence systems, including the popular ChatGPT, has sparked a heated debate over the boundaries of copyright law and AI technology.

OpenAI’s defense, articulated in a recent filing in Manhattan federal court, argues that The New York Times contravened OpenAI’s terms of use by using “deceptive prompts” to force the AI to reproduce the newspaper’s content. OpenAI contends that this strategy was designed to create evidence for The New York Times’ lawsuit, undermining the integrity of the legal process. The filing criticizes the Times for not adhering to its own high journalistic standards, suggesting that the newspaper hired an external party to manipulate OpenAI’s products deliberately.

At the heart of this legal battle is the controversial question of whether AI’s training on copyrighted materials constitutes fair use — a principle that allows limited use of copyrighted material without permission for purposes such as news reporting, teaching, and research. Tech companies, including OpenAI, argue that their AI systems’ usage of copyrighted content is a fair use, essential for the development of AI technologies that could potentially shape a multitrillion-dollar industry. However, copyright owners, including The New York Times, contend that such practices infringe on their copyrights, unduly benefiting from their extensive investments in original content.

What is the case against OpenAI and Microsoft about?

The case against OpenAI and its primary financial supporter, Microsoft, is part of a broader trend of copyright lawsuits targeting tech companies over AI training practices. However, courts have yet to provide a clear verdict on the fair use question in the context of AI, with some infringement claims being dismissed due to insufficient evidence of AI-generated content resembling copyrighted works closely.

OpenAI’s filing emphasizes the challenges in using ChatGPT to systematically reproduce copyrighted articles, arguing that the instances cited by the Times were anomalies resulting from extensive manipulation. The company also posits that AI models acquiring knowledge from various sources, including copyrighted materials, is inevitable and cannot be legally prevented, drawing a parallel with traditional journalistic practices of re-reporting news.

As the lawsuit progresses, the outcome could have profound implications for the future of AI development and the application of copyright law in the digital age. A ruling in favor of OpenAI could solidify the legal standing of AI’s fair use of copyrighted materials, potentially accelerating the growth of AI technologies. Conversely, a decision favoring The New York Times could impose new limitations on how AI can be trained, impacting the evolution of AI capabilities and the tech industry’s trajectory.",AI,Relevant,Relevant,
Vision Pro helps surgeons plan and visualize operations carried out with a surgical robot,https://9to5mac.com/2024/03/11/surgeons-plan-and-visualize-operations/,"Vision Pro is being used for a wide range of applications in the field of health and medicine, with Apple highlighting an app which helps surgeons plan and visualize operations which are carried out with the help of a surgical robot.

The company says that the device is also helping to familiarize nurses with new medical equipment, in a way that reduces anxiety when they start using the kit in real-life applications …

Apple says that Vision Pro developers are creating apps which transform healthcare in a range of ways.

With the unique capabilities of visionOS, healthcare developers are creating new apps that were not previously possible, transforming areas such as clinical education, surgical planning, training, medical imaging, behavioral health, and more.

Surgical planning

One surgical planning app combines two technologies: robot-assisted knee and hip surgery, with Vision Pro.

When surgeons use Stryker’s Mako SmartRobotics for total hip, total knee, and partial knee replacements, it can help lead to better patient outcomes like less pain and shorter recovery times, compared to traditional joint replacement surgeries. With the new myMako app, Stryker is extending a surgeon’s experience in and beyond the operating room with Apple Vision Pro and iPhone. For better preparation, myMako allows surgeons to visualize and review patients’ Mako surgical plans at any time in a brilliant, immersive visual experience. “The myMako app for Apple Vision Pro allows surgeons the ability to access intricate surgical plan details and insights at their fingertips in a 3D-native, intuitive, and dynamic way. This level of insight — anytime, anywhere — was previously not possible,” said Robert Cohen, Stryker’s president of Digital, Robotics, and Enabling Technologies. “With Apple Vision Pro, Stryker’s market-leading enabling technologies such as Mako SmartRobotics have the exciting potential to transform the way surgeons think about preoperative planning and the intraoperative experience, all consistent with Stryker’s mission to make healthcare better.”

Familiarising nurses with new medical equipment

When new equipment is introduced, conventional training can leave nurses feeling like they have the theoretical knowledge of how to use it, but not the familiarity they have with the devices it is replacing. That’s a problem the CyranoHealth app aims to fix.

Boston Children’s Hospital developed a comprehensive learning experience in a safe, universally accessible virtual environment. Created for Apple Vision Pro, CyranoHealth places a spotlight on skills related to new medical equipment, like medical infusion pumps, helping improve confidence and reduce anxiety for frontline workers, beginning with nurses. This immersive, multisensory approach allows students to familiarize themselves with the latest advancements in healthcare technology, helping to prepare them to navigate real-world challenges. “CyranoHealth utilizes spatial computing to revolutionize the training of healthcare professionals, offering immersive, lifelike simulations to enhance learning and combat burnout. The app represents a significant leap forward in healthcare training, blending technology and medicine to create a future-ready workforce,” said John Brownstein, Ph.D., Boston Children’s chief innovation officer.

Apple goes on to describe other medical applications for Vision Pro, like viewing “immersive, interactive holograms of the human body captured through medical scans” and an easier way for doctors to complete charting tasks. Check out the full press release here.",Robotics,Relevant,Relevant,
Intel Gaudi2 chips outperform Nvidia H100 on diffusion transformers,https://stability.ai/news/putting-the-ai-supercomputer-to-work,"In our last installment, we spoke about how we plan to utilize our state-of-the-art AI Supercomputer.

In this installment, we delve deeper into performance benchmarks and benefits of various compute solutions.

Our commitment to developing cutting-edge open models in multiple modalities necessitates a compute solution capable of handling diverse tasks with efficiency. To this end, we conducted a performance analysis, training two of our models, including the highly anticipated Stable Diffusion 3.

In our analysis, we compared the training speed of Intel Gaudi 2 accelerators versus Nvidia's A100 and H100, two of the most common choices for startups and developers training LLMs.

Model 1:

Stable Diffusion 3 is our most capable text-to-image model, soon to be in early preview.

Upon public release of Stable Diffusion 3, it will be available in sizes ranging from 800M to 8B parameters. Our analysis utilized the 2B parameter version and showed pleasantly surprising results.

We measured the training throughput for the 2B Multimodal Diffusion Transformer (MMDiT) architecture model with d=24, BFloat16mixed precision, optimized attention (xFormers for A100 and the FusedSDPA for Intel Gaudi). We call this model version MMDiT-ps2-d24.

First, let’s examine our training benchmark results across 2 nodes, a total of 16 accelerators (Gaudi/GPU). Here’s an excerpt of the raw data:",AI,Relevant,Relevant,
Disney’s 10th Accelerator Program invests in four AI startups,https://readwrite.com/disneys-10th-accelerator-program-invests-in-four-ai-startups/,"The 10th year of the Disney Accelerator Program has been announced, with a strong focus on AI as four out of the five chosen companies are in the artificial intelligence space.

Announced on Wednesday (Feb. 21) via a press release, the Walt Disney Company shares how it’s ‘exploring how emerging technologies can be used as tools to foster human creativity and imagination and help shape the future of media and technology.’

The Accelerator Program results in an investment of time, money, and resources, usually into a select group of start-ups and entrepreneurs. Disney has connected more than 60 global companies through this scheme, including the likes of Epic Games, Kahoot!, Illumix, and Inworld.

This year, the following companies have been chosen to take part:

AudioShake: They use AI to separate layers of recorded sound in order to make audio interactive, editable, and customizable.

ElevenLabs: A voice AI research and deployment company that creates realistic, versatile, and contextually aware AI audio.

We are thrilled to be a part of the 2024 Disney Accelerator. Disney is one of the world's most globally recognizable brands and has held a special place in our hearts since childhood. This type of unprecedented access to the creativity and imagination of Disney will be… pic.twitter.com/4rAtuovkCW — ElevenLabs (@elevenlabsio) February 22, 2024

Nuro: An autonomous vehicle company that builds custom, electric, zero-occupant vehicles for the delivery of goods.

PrometheanAI: They provide a suite of tools for virtual world creation and digital asset management using natural language prompts.

StatusPro: Immersive entertainment that leverages virtual and augmented reality to create first-person sports gaming experiences.

The press release further touches on the selection of AI businesses, “the companies in the 2024 Disney Accelerator share in Disney’s commitment to exploring the benefits that artificial intelligence may offer to enable human imagination and creativity in a responsible and ethical way.”

Marking their first decade, the entertainment conglomerate aims to continue to find ways to innovate and use technology in the service of storytelling. Just a couple of weeks ago, news came of a $1.5 billion investment into Epic Games from Disney, helping the gaming company build out a metaverse-like Disney immersive universe.

Featured image: Image by Gary Ullah",AI,Relevant,Relevant,
Adobe previews cutting-edge generative AI tools for custom audio,https://readwrite.com/adobe-previews-cutting-edge-generative-ai-tools-for-custom-audio/,"Adobe has announced new experimental generative AI tools the company hopes will revolutionize how people create and edit custom audio.

Called Project Music GenAI Control, the tools allow users to generate original music simply by providing text prompts. Users can then finely edit the AI-generated audio to fit their exact needs.

The new tools build on Adobe’s Firefly image generation system which has already been used to create over six billion images. Adobe says Project Music GenAI Control makes generative AI a “co-creator” that assists people in crafting customized music and audio for projects like podcasts and videos.

Explore the future of sonic creativity 🔊 with Project Music GenAI Control! Emerging experimental tech from the Adobe Research team can create audio tracks using text prompts and even transform your music based on reference melodies. Learn more: https://t.co/hy9J4qOXfO pic.twitter.com/6HBBIxsptF — Adobe (@Adobe) February 28, 2024

“With Project Music GenAI Control, generative AI becomes your co-creator. It helps people craft music for their projects, whether they’re broadcasters, or podcasters, or anyone else who needs audio that’s just the right mood, tone, and length,” says Nicholas Bryan, Senior Research Scientist at Adobe Research and one of the creators of the technologies.

How does Adobe’s Project Music GenAI Control work?

After entering a text prompt like “suspenseful rock” or “cheerful pop”, the AI generates a unique audio clip. A simple interface then allows for granular editing changes – transforming melodies, adjusting tempo and song structure, extending length, remixing sections, and more. This gives users pixel-level control similar to Photoshop but for audio waveforms instead of images.

The tools aim to solve workflow issues around producing custom intro/outro music and background audio. Rather than manually editing existing songs, Project Music GenAI Control makes it easy to generate precisely what you need.

The technology was developed alongside researchers from UC San Diego and Carnegie Mellon University. The research team claims AI co-creation can enhance human creativity rather than replace it. Time will tell if that is the case.

Adobe says transparency and ethics are crucial, so AI-generated content will include “nutrition label” metadata showing its origins.

Featured image: Adobe",AI,Relevant,Relevant,
Microsoft mocked after developer account shares ‘hideous’ AI image,https://readwrite.com/microsoft-mocked-after-developer-account-shares-hideous-ai-image/,"As far as extolling the virtues of artificial intelligence (AI) goes, in tandem with promoting a strong, vibrant brand identity, Microsoft appears to have dropped a masterclass on how not to do it.

The US tech giant has been ridiculed after a developer shared what some called a “hideous” AI image, with significant potential to go viral on social media.

The Microsoft update from its Windows Develop account on X was intended to detail support information when migrating from UWP to WinUI 3 platforms but it appears something has been lost, in transit perhaps?

What's supported when migrating from UWP to WinUI 3 WinUI 3 and the Windows App SDK are new technologies and, when compared to UWP, there are some features that aren't supported. This topic lists which features are supported before you attempt migration.https://t.co/oLF44YayNv pic.twitter.com/2yQ6u9MGxe — Windows Dev Docs (@WindowsDocs) March 11, 2024

An AI image depicted the movement of boxed goods from one large vehicle to another, to represent the named platforms.

However, it is fair to say the reaction online has ranged from amusement to mockery.

Microsoft met with derision over AI image

One Twitter user, @oacoello_ stated, “Microsoft UWP app development is as lazy as this AI image.” Another fired back with “That image is hideous. Don’t use AI for this.”

@douglascamata was sharp in his commentary, opining “Running too short in cash to get a human designer to do properly illustrate this? The worst is that MS thought that this would be accepted on the internet without becoming an instant meme and source of mockery.”

Then in a rather scathing and succinct critique, @pyke_64 unleashed the rebuke, “If this is a sign of the quality of your upscaling tech for PC, don’t bother.”

That is just a selection of the responses on X, alone.

Please tell me where I can get those versions of Windows pic.twitter.com/kcXr8doItL — Bronze (@Bronze87415846) March 12, 2024

It may have been intended as an informal or fun image to accompany the developer information, serving a purpose but the impact has been an unwanted one from a brand and PR perspective.

Image: @WindowsDocs/X",General,Irrelevant,Relevant,
Italy to pump 1 billion euros into AI projects,https://readwrite.com/italy-to-pump-1-billion-euros-into-ai-projects/,"Italy sets its sights on AI, with plans to set up an investment fund to promote artificial intelligence projects.

Speaking via video message at the ‘Artificial Intelligence for Italy’ conference in Rome, on Tuesday (Mar. 12), Prime Minister Giorgia Meloni announced a one-billion-euro fund.

This is being backed by CDP Venture Capital, a unit of state lender Cassa Depositi e Prestiti (CDP), the fund could go on to raise a further 2 billion euros from the private sector, the company’s chief executive Agostino Scornajenchi said.

According to Reuters, the PM expanded further by saying: “We are convinced that there can and must be an Italian way to artificial intelligence,”

Alongside the one-billion-euro investment fund, he also said they’ll be looking at a law to regulate AI: “The government is preparing a law that aims to establish some principles and set rules that are complementary to the European regulation that is in the process of being approved and identify the most effective measures to stimulate our productive capabilities.”

Giorgia Meloni continues: “We are also working to identify the most suitable body to act as the competent authority for the use of technologies based on artificial intelligence.”

The planned legislation will be officially presented in the coming weeks and it’ll sit under the national AI strategy.

This comes in the midst of other countries announcing AI plans, with President Biden signing an executive order to oversee and invest in AI in October of last year. This order is broad, but suggests funding for the U.S. government to further invest in the technology.

In the UK’s 2024 Budget announcement (Mar. 6) the Chancellor announced the doubling of investment for the Alan Turing Institute which is the internationally leading body for data science AI, bringing its total funding to £100 million.

How different countries are approaching AI

Since its inception, countries worldwide have had mixed feelings about incorporating the use of AI.

A December 2023 cluster analysis created by James S. Denford, Gregory S. Dawson, and Kevin C. Desouza has highlighted differences and similarities between countries’ national AI strategies. The authors found that the U.S. has one of the most complete AI strategies, but is focused heavily on the dangers of AI. They report this to be the case across many Western countries.

They highlight China as paving the way and being in the lead, with an almost exclusive interest in research and development.

According to research, places like China, Spain, and the U.S. plan to deploy AI in all industries other than defense and tourism.

Featured image: Photo by Caleb Miller on Unsplash",AI,Relevant,Relevant,
How Georgia became America's green-manufacturing capital,https://www.businessinsider.com/how-georgia-became-green-manufacturing-capital-2024-3,"When Robert Howey joined the US Navy right after high school, he didn't expect to return home anytime soon.

Howey, now 30, grew up in northwestern Georgia near Dalton, a small city known as the ""carpet capital of the world."" If he'd stayed in the area, he likely would have pursued a career in the carpet industry.

""That's one of the reasons why I wanted to leave,"" Howey told Business Insider.

This story is available exclusively to Business Insider subscribers. Become an Insider and start reading now.

Advertisement

Howey spent four years as an aerographer's mate analyzing the conditions above and below the ocean. But after being stationed in Japan during the Fukushima earthquake in 2016, he realized the military wasn't his long-term career.

He missed home and moved back to Dalton, where a job in carpet manufacturing was indeed the best-paying option. That was until 2018, when Howey heard about a new company moving into Dalton. A local staffing agency was recruiting for Qcells, a solar-panel manufacturing company owned by the South Korean conglomerate Hanwha Group.

""I didn't even know what a solar panel was,"" Howey, now a master training coordinator at Qcells, said. ""In the beginning, it was just about getting a job where I could grow. Now I believe in the mission of completely clean energy.""

Howey is among the 1,800 employees Qcells has hired since opening a solar assembly plant in 2019. The company finished an expansion in October, and it plans to open another factory in Cartersville, about an hour south of Dalton, to make smaller parts of solar panels, including ingots, wafers, and cells. Those parts are currently being imported from South Korea and Malaysia.

Qcells has hired at least 1,800 employees since opening a solar assembly plant in Dalton in 2019. Catherine Boudreau/Business Insider

Qcells is part of a broader transformation of Georgia's economy into a renewable-energy manufacturing hub, accelerated by tax breaks in the Inflation Reduction Act that President Joe Biden signed in August 2022. Since then, more than $15 billion worth of investment has been announced in the state – the second-largest amount behind North Carolina, according to E2, a nonpartisan business group that advocates climate policy. Most of the money is for new battery plants to supply Georgia's growing electric-vehicle sector, while about $2.6 billion is set to go toward solar manufacturing, led by Qcells. E2 has estimated the projects could create 15,400 jobs statewide.

All the activity has made Georgia a key testing ground for the Biden administration's promise that tackling the climate crisis would create good-paying jobs and help reshore American manufacturing. Though companies have announced billions of dollars' worth of investments, efforts to build a domestic supply chain of solar panels and electric vehicles are still in their infancy and face stiff competition from China.

Aggressive recruitment

Experts in economic and workforce development say it's no accident this manufacturing is taking off in Georgia.

Bob Keefe, the executive director of E2, said southeastern states view economic development as ""a blood sport."" Attracting new companies is a priority for leaders in Georgia, North Carolina, and South Carolina, and the states typically offer generous tax breaks.

Advertisement

Keefe added that land and labor in the Southeast tend to be more affordable, in part because few workers are unionized. Many workers are also already skilled in manufacturing.

Beyond Qcells, the German auto-parts maker Gedia opened a factory in Dalton to supply the burgeoning EV industry in Georgia and the broader Southeast. In nearby Cartersville, two South Korean conglomerates, SK On and Hyundai, are building a battery plant to supply the electric vehicles Hyundai plans to assemble at a massive new complex in Savannah; both sites are expected to open in 2025. India's Rayzon Solar, which makes solar panels, chose Atlanta for its first US factory. SolarCycle, which reclaims old solar panels to make new ones, in February announced plans for a glass factory.

SK On and Hyundai are building an electric vehicle battery factory in Cartersville, Georgia. Catherine Boudreau/Business Insider

Pat Wilson, the commissioner of the Georgia Department of Economic Development, told BI that recruiting solar and electric-vehicle companies was strategic. Wilson said that on a trip to Germany his department organized with Gov. Brian Kemp shortly after he took office in 2019, executives they met with at Porsche and Mercedes-Benz talked at length about electric vehicles.

Qcells had already selected Dalton for its new solar-panel factory by the time Kemp was elected. Wilson said that was partly because of Georgia's decadeslong business relationship with South Korea, where the state established an office in 1985.

Wilson said he met with SK On's officials several times before it looked to open a battery factory in the Southeast. SK On opened two battery plants in Commerce, Georgia, in 2018 and hired some 3,000 workers, though it recently laid off more than 100 employees as automakers slowed EV investments, the Financial Times reported.

Beyond the ties to South Korean conglomerates, Georgia invests more than $100 million dollars a year in workforce training, budget documents show. A state-funded program known as Quick Start can be tailored to the technical skills companies are looking for and offered for free to workers. Georgia's network of 22 technical colleges also partners with local companies to prepare students for work.

Heidi Popham, the president of Georgia Northwestern Technical College, said the state agency that oversees that network of technical colleges developed an electric-vehicle-technician certificate, given the massive growth of that industry. She expects her college will offer that certification soon.

""The students in our automotive-technician program that work on the vehicles will have to have those skills,"" Popham told BI.

Advertisement

China looms large

Georgia's strategy in recruitment and workforce development is only part of the reason for the boom in renewable-energy-technology companies.

In 2018, President Donald Trump slapped tariffs on imports of solar panels and cells, with the goal of helping US manufacturers compete with cheaper imports from China and Southeast Asia. The tariffs were requested by two American companies, including Suniva, which had once been the fastest-growing solar company in the US before filing for bankruptcy protection in 2017.

Foreign companies shipping to the US, including Hanwha, were forced to reevaluate their supply chains.

""We have factories in Korea and Malaysia that were impacted by that duty,"" said Scott Moskowitz, the director of strategy and market intelligence at Qcells. ""The US was our largest market, and we had long wanted to build a factory here. But that trade policy jump-started us making the investment.""

Qcells' latest expansion plans were buoyed by the Inflation Reduction Act. The law authorized big tax credits for companies making renewable-energy technologies, including solar panels, batteries, and electric vehicles, in the US.

Those subsidies could increase if companies use what's known as domestic content: components of those technologies that are also sourced from the US. The Treasury Department is still working on final guidance for which components would qualify. An initial draft covers solar modules and cells but not wafers and polysilicon. In February, a dozen senators, including Sen. Jon Ossoff of Georgia, asked the Biden administration to include wafers and polysilicon to help reshore more of the solar-panel supply chain.

That change would benefit Qcells. Its parent company, Hanwha, invested in a polysilicon factory in Washington state, reviving operations after a nearly five-year hiatus.

Moskowitz said that though the law has spurred the most investment in US manufacturing in decades, these renewable supply chains still face headwinds, primarily from China. He added that China had compensated for its cratering real-estate sector by rapidly investing in export-oriented manufacturing inside and outside its borders.

According to BloombergNEF, China spent $676 billion on the green-energy transition in 2023, while the US spent $303 billion. The year prior, China spent $546 billion while the US spent $141 billion.

Advertisement

As a result, China dominates the renewable-energy supply chain, from metals to polysilicon to solar components to batteries. The investment has also led to a global oversupply of solar panels and components that's sent prices plunging, and it's made China a major player in the EV market.

While the US doesn't import solar panels directly from China, the Biden administration last year determined that certain Chinese companies were shipping products through Southeast Asian countries like Malaysia and Vietnam. This allowed those companies to avoid tariffs, which the administration had waived for two years, through June 2024. According to S&P Global, the US imported more than two-thirds of its solar panels from Southeast Asia last year.

The moves reflect the delicate balance the White House is trying to strike between meeting its climate and renewable-energy goals — which rely on imports — and bolstering a domestic manufacturing base.

Moskowitz said that despite the difficult market conditions, Qcells was committed to its US expansion plans. The tax breaks in the Inflation Reduction Act are in effect for 10 years, which he said reduced some risk for the company. Qcells also has an eight-year supply deal with Microsoft, which is building out renewable-energy projects to power its operations.

Once the Qcells factory in Cartersville is finished, the company said it will produce about 8.4 gigawatts of solar power capacity a year, or about a fourth of what the US installed in 2023.

A new era in the carpet capital

Qcells' arrival in Dalton marked a new era in Whitfield County, which was devastated by the Great Recession. The housing-bubble burst, rippled through the carpet industry, and cost the county more than 10,000 jobs. The unemployment rate peaked at about 14% in early 2009 and the county's population, which had steadily grown for decades, plateaued. New housing construction halted.

Carl Campbell, the executive director of the Dalton-Whitfield County Joint Development Authority, said that while carpet makers like Shaw Industries and Mohawk Industries survived, the industry never returned to prerecession employment levels because of consolidation and automation.

The decline led economic-development officials to try to diversify businesses in the area. Campbell said the local workforce already valued manufacturing because of the community's long history in carpet. This — combined with Dalton's proximity to Interstate 75, a freight-rail depot, and a generous 10-year property-tax abatement — helped close the deal with Qcells.

Advertisement

Since Qcells opened its doors in 2019, Whitfield County's population has slowly started increasing, but not nearly as fast as Georgia's overall population, which grew by 1.7% between 2020 and 2022.

Jevin Jensen, the chairman of the Whitfield County Board of Commissioners, said part of the problem is a lack of housing. Each day, Jensen said, 30,000 people come to the county for work and then leave to go home.

""Surely some of those people want to live here but can't find a place they like or a place that's new,"" Jensen told BI. ""We haven't had any new apartments in 20 years.""

Dalton Station is among the new apartment complexes opening in the city in 2024. Catherine Boudreau/Business Insider

But a lot can change in a year. Jensen said Dalton would have 1,200 new apartments by the end of 2024. In early February, he attended a ribbon-cutting ceremony at a chic new studio-apartment complex that's close to downtown and designed to appeal to young professionals. Amenities include a gym, a common area with a pool table, and cornhole on the patio.

Afterward, Jensen gave BI a driving tour of three other developments around Dalton, including a multifamily apartment complex at an old jail site.

""The younger generation doesn't want to spend time on a remodel,"" Jensen said. ""They want move-in-ready, mixed-use, with retail and restaurants in one area. We had nothing like that for young professionals.""

Howey, the Qcells employee, lives about 30 minutes outside the city, in Calhoun. He's noticed the new housing popping up in the area, along with EV chargers. When he sees solar panels atop the chargers, he feels pride in his job.

""We are helping power our vehicles and homes in a way that isn't going to kill our planet,"" Howey said.

Advertisement

He's also a father to two stepchildren — he said he's glad they'll have more job opportunities than he did when he graduated.

""I think the solar industry has created a whole new atmosphere in the area,"" he said, ""where people want to come here to succeed and move forward.""",Green Computing,Relevant,Relevant,
T-Mobile just set another 5G speed record,https://www.digitaltrends.com/mobile/t-mobile-just-set-another-5g-speed-record-news/,"Digital Trends may earn a commission when you buy through links on our site. Why trust us?

T-Mobile’s rivals may be nipping at its heels in the 5G race, but the Uncarrier is determined to stay ahead of the game. It not only boasts the fastest and most expansive 5G network in the U.S., but it’s actively working on technologies that will help it reach even greater peak speeds.

Two years ago, T-Mobile used a relatively new technique known as 5G Carrier Aggregation ( 5G CA) to achieve the kind of 3Gbps download speeds on midband frequencies that had previously been the exclusive domain of extremely high (and extremely short-range) mmWave technologies. Now, it’s chalked up another 5G first by taking advantage of the latest developments to shatter the traditional cap on upload speeds over sub-6GHz frequencies.

Recommended Videos

T-Mobile’s newest 5G record

The new technique is known as uplink transmit (UL Tx) switching, and it’s similar in basic principle to the 5G CA technique used to reach 3Gbps download speeds, except that it uses more channels to deliver more capacity.

However, UL Tx goes a big step beyond that. With 5G CA, T-Mobile combined multiple 5G channels across three discrete frequency bands from 1.9GHz to 2.5GHz to give it more bandwidth. UL Tx switching stands on the shoulders of those carrier aggregation technologies to combine different frequencies into a single uplink band, but then adds single-user multiple input, multiple output (SU-MIMO) to the mix to send multiple streams and seamlessly switch between frequencies to take maximum advantage of all the capacity that’s available across that entire spectrum.

To use the description from T-Mobile’s press release, “It’s like taking the 5G superhighway and adding new faster lanes with spare capacity for traffic to zoom faster than ever.”

The result is that T-Mobile has been able to achieve speeds of 345Mbps on its 5G standalone network, breaking its own previous record of 275Mbps that it announced less than a month ago.

The Uncarrier didn’t name the specific smartphone used to conduct the test, saying only that it was “powered by a flagship Snapdragon Modem-RF system from Qualcomm Technologies.” However, some might consider it telling that last month’s record was announced alongside the availability of the Snapdragon 8 Gen 3-powered Samsung Galaxy S24 lineup.

“This achievement is a testament to our relentless pursuit of innovation and our commitment to delivering an even better network experience to our customers,” said Ulf Ewaldsson, president of technology at T-Mobile. “Uplink transmit switching has the potential to significantly boost upload speeds and capacity, and we implore our partners around the globe to build the capability into the 5G ecosystem moving forward.”

The fastest speeds at the best range

What makes T-Mobile’s accomplishment so groundbreaking isn’t just the raw speeds it’s been able to achieve, but the fact that it’s done so using midband 5G frequencies.

We’ve long seen reports of 5G technology delivering download speeds of up to 4Gbps and upload speeds above 1Gbps. A mere 345Mbps may not seem that impressive by comparison.

The problem is that those blazing-fast speeds have traditionally only been available on mmWave networks, which operate at extremely high frequencies that typically run above 24GHz. This spectrum offers incredible capacity, but also has a range of about a city block.

There’s an inverse relationship between range and capacity; as frequencies increase, so do speeds, but the range goes down. On the other end of the spectrum from mmWave, low-band 5G can reach for miles, but you won’t get speeds that are much better than what 4G/LTE can deliver.

That’s why the midband frequencies — the ones from 2GHz to 6GHz — have long been considered the sweet spot for the future of 5G . These are also sometimes referred to as C-band spectrum, although that’s not entirely accurate, as the C-band frequencies make up only a tiny portion of that spectrum, specifically a 3.7GHz to 3.98GHz slice in the middle. C-band is used mainly by Verizon and AT&T, while T-Mobile has set up its base camp in the 2.5GHz zone.

The midband spectrum offers the best balance between range and capacity, but it’s also clear that speeds are beginning to plateau with the limitations of existing 5G technologies. That’s why T-Mobile has been aggressively experimenting with new techniques like 5G CA and UL Tx to change the rules and allow it to deliver unprecedented speeds that don’t sacrifice range.

In practical terms, this means the same towers that T-Mobile has deployed today could someday deliver speeds that rival the best mmWave networks without the need to deploy the tens of thousands of additional transceivers necessary to blanket a densely populated city with mmWave coverage.

Editors' Recommendations",Communications Technologies,Relevant,Relevant,
How a lizard-like robot could help the Navy 'prevent catastrophes': decorated veteran,https://www.foxnews.com/tech/lizard-like-robot-help-navy-prevent-catastrophes-decorated-veteran,"A lizard-like robot and other devices relying on artificial intelligence could soon be major military game changers, according to a defense expert investing in the tech.

The devices include a drone that can operate even in warzones with jammed communications, an AI system that can serve as a pilot and a robot capable of identifying weak spots in some equipment, including Navy vessels, according to Snowpoint Ventures co-founder Doug Philippone.

""The critical thing of moving forward in the threats that we see around the world, we have to be able to make decisions really quickly and do something about it as fast as possible,"" said Philippone, who’s also served as Palantir Technologies’ global defense head since 2008.

WHAT IS ARTIFICIAL INTELLIGENCE (AI)?

One company within Philippone’s portfolio is Shield AI, which created the V-BAT, a fully autonomous drone capable of vertical take-off and staying airborne for 10 hours. But the major draw, Philippone said, is that it can still complete its missions and return home even if communications are severed, such as in battle zones like Ukraine.

""Securing boarders, hunting drugs, finding threats,"" Shield AI states. ""The most tactical, most logistically simple [unmanned aircraft system] in the world.""

A second firm, Merlin Labs, meanwhile, has developed AI capable of serving as a second pilot for cargo aircraft — though Philippone stressed that it wasn't pursuing use in commercial flying.

WATCH MORE FOX NEWS DIGITAL ORIGINALS HERE

AMERICA UP FOR ‘REALLY WILD YEAR’ AS ALLIES, ENEMIES EVALUATE PRESIDENTIAL CANDIDATES: DEFENSE EXPERT

""The Merlin Pilot is capable of navigating and recommending trajectory adjustments as needed"" and can communicate directly with air traffic control, Merlin Labs’ website states.

""They’re years into the certification process,"" Philippone told Fox News. ""And in the meantime, they've been working with the U.S. military as well.""

He said the tech could be used to help fill gaps from any pilot shortages.

‘THIS SCARES ME’: AS CHINA WATCHES, THIS DECORATED VETERAN SOUNDS ALARM ON AN AMERICA STRETCHED TO ITS LIMITS

Gecko Robotics, meanwhile, ""invented these crazy robots that climb and scale"" infrastructure ""like a gecko lizard"" and make a digital copy, Philippone said.

""Using advanced AI techniques, they can now detect exactly where these things will fail,"" he continued. ""You can prevent catastrophes. You can do smart maintenance.""

""Our robots collect 1,000x more information with continuous data capture at speeds an average of 10x faster than previous methods,"" Gecko’s website boasts. ""Using specially-designed sensor payloads, the robots can inspect wall thickness, pitting, and many other forms of degradation.""

CLICK HERE TO GET THE FOX NEWS APP

The Navy, in particular, could benefit from Gecko since it would allow more targeted maintenance rather than replacing entire portions that officials aren’t even certain need repair, according to Philippone.

""It ends up being really expensive for no particular reason,"" he said. ""They don't actually know that that panel needs to be replaced.""

Still, Philippone emphasized that these devices are only one part of the equation. Humans must still be the ones call the shots, he said.

""All of this technology should assist humans in making decisions, not make the decisions for them,"" Philippone told Fox News. ""I firmly believe that you need a human to do that to really encapsulate the risks of those decisions.""

Ramiro Vargas contributed to the accompanying video.",Robotics,Relevant,Relevant,
Google is reportedly paying some news sites to use its AI for writing articles,https://www.androidcentral.com/apps-software/google-paying-news-publishers-to-publish-ai-content,"What you need to know

Google's latest experiment provides independent publishers with access to a beta AI platform for generating news articles.

Publishers are expected to create and publish three articles daily, one weekly newsletter and one monthly marketing campaign using AI.

Google is reportedly offering significant amounts to small publishers for trying out generative AI tools.

Google has reportedly kicked off an experimental program that gives independent publishers access to a beta AI platform that churns out news articles.

Last year, Google was spotted testing ""Genesis,"" an AI tool aimed at assisting journalists in writing news articles. A new report from Adweek suggests that Google is throwing around five-figure amounts to get small publishers to try out generative AI tools for publishing stories.

The trial for Google's yet-to-be-released AI platform is on a small scale but supposedly demands regular usage. As part of the deal, publishers are expected to publish three articles daily, one newsletter per week, and one monthly marketing campaign, all crafted using AI.

Google's platform operates by pulling content from a curated list of websites and putting it all together on a dashboard. A human editor can then use the AI tool to transform any new post on the dashboard into a news article. Afterward, the human editor fine-tunes the articles before publishing them.

News outlets are supposed to publish these AI-generated articles over a 12-month period, and in return, they provide analytics and feedback to Google. As per Adweek, the program is presently focusing on a ""handful"" of smaller outlets.

It's worth mentioning that using this tool doesn't apparently mandate publishers to tag these articles as AI-generated. Additionally, the websites whose content is aggregated are not notified that their material is being used to generate AI-written stories on other platforms.

The trial is reportedly a component of the Google News Initiative (GNI), a program that's been around for a while, supporting media literacy projects and providing resources for newsrooms. However, venturing into generative AI publishing tools would mark a new and potentially contentious move for Google.

This move is likely to draw renewed attention to the use of generative AI tools by publishers. Publications, such as CNET, have faced significant backlash for trying to present AI-authored articles as if they were crafted by humans.

In a statement to Adweek, Google reassured us that it's not out to dismantle journalism. The company mentioned being in the initial phases of exploring ideas to potentially offer AI-enabled tools to assist journalists in their work.

A spokesperson from the company added that the AI tools are not meant to substitute for the crucial role that journalists play in ""reporting, creating and fact-checking their articles.""

There are concerns about the AI tool, as the articles it generates could divert readers from the original sources. Since the AI-assisted stories aren't contributing new information, some argue that the program is essentially taking credit for others' work.

But Google clarified that in an email to Android Central that ""publishers remain in full editorial control of what is ultimately published on their site."" A Google representative stated that the program's goal is to offer journalists and publishers the ability to use these ""technologies in a way that enhances their work.""",AI,Relevant,Relevant,
MDN Curriculum,https://developer.mozilla.org/en-US/curriculum/,"Beginner's level

Self-paced

Free

The go-to resource for the essential skills and knowledge every front-end developer needs for career success and industry relevance.

Developed by Mozilla and refined with insights from the broader MDN community.

Learn more",General,Relevant,Irrelevant,
On-Device AI Is a Whole New Way of Experiencing Artificial Intelligence - CNET,https://www.cnet.com/tech/mobile/on-device-ai-is-a-whole-new-way-of-experiencing-artificial-intelligence/,"At Mobile World Congress last week, the show floor was abuzz with AI. It was the same at CES two months earlier: The biggest theme of the biggest consumer tech show was that AI suddenly seemed to be part of every single product. But the hype can make it hard to know what we should be excited about, what we should fear and what we should dismiss as a fad.

""Omnipresent ... but also overwhelming."" That's how CCS Insight Chief Analyst Ben Wood described the MWC moment. ""For many attendees, I felt, it was rapidly reaching levels that risked causing AI fatigue.""

But there was a positive side as well. Said Wood: ""The most impressive demos were from companies showing the benefits AI could offer rather than just describing a service or a product as being AI-ready.""

At last year's MWC, the popular generative AI tool ChatGPT was only around 3 months old, and on-device AI was mostly a twinkle in the eye of the tech companies present. This year, on-device was a reality, and attendees — like me — could experience it on the show floor.

I got to experience several demos featuring AI on devices, and the best of them brought artificial intelligence to life in ways I'd never seen before. In many cases, I could see that products we're already familiar with — from smartphones to cars — are getting a new lease on life thanks to AI, with some offerings using the technology in unique ways to set themselves apart from rivals. In other cases, new types of products, like AI-focused wearables and robots, are emerging that have the potential to displace what we know and love.

Above all, it was clear that on-device AI isn't a technology for tomorrow's world. It's available right here, right now. And it could impact your decision as to what piece of technology you buy next.

The age of AI phones has arrived

One of my biggest takeaways from MWC was that while all tech companies now have a raft of AI tools at their disposal, most are choosing to deploy them in different ways.

Take smartphones. Samsung has developed Gauss, its own large language model (the tech that underlies AI chatbots), to focus on translation on the Galaxy S24, whereas Honor uses AI to include eye tracking on its newly unveiled Magic 6 Pro — which I got to try out at its booth. Oppo and Xiaomi, meanwhile, both have on-device generative AI that they're applying to phone cameras and photo editing tools.

It goes to show that we're entering a new period of experimentation as tech companies figure out what AI can do, and crucially how it can improve our experience of using their products.

Samsung's Y.J. Kim, an executive vice president at the company and head of its language AI team, told reporters at an MWC roundtable that Samsung thought deeply about what sort of AI tools it wanted to deliver to users that would elevate the Galaxy S24 above the basic smartphone experience we've come to expect. ""We have to make sure that customers will see some tangible benefits from their day-to-day use of the product or technologies that we develop,"" he said.

Conversely, there's also some crossover in AI tools between devices because of the partners these phone-makers share. As the maker of Android, the operating system used by almost all non-Apple phones, Google is experimenting heavily with AI features. These will be available across phones made by Samsung, Xiaomi, Oppo, Honor and a host of others.

Google used its presence at MWC this year to talk about some of its recently introduced AI features, like Circle to Search, a visual search tool that lets you draw a circle around something you see on screen to search for it.

Google's Circle to Search was featured heavily at the company's MWC booth. Katie Collins/CNET

The other, less visible partner that phone-makers have in common is chipmaker Qualcomm, whose chips were in an entire spectrum of devices at MWC this year. Its Snapdragon 8 Gen 3 chip, announced late in 2023, can be found in many of the phones that are now running on-device generative AI.

It's been only a year since Qualcomm first showed a basic demo of what generative AI on a phone might look like. Now phones packing this technology are on sale, said Ziad Asghar, who leads the company's AI product roadmap.

""From our perspective, we are the enablers,"" said Asghar. ""Each and every one of our partners can choose to commercialize with unique experiences that they think are more important for their end consumer.""

At MWC, the company launched its AI Hub, which gives developers access to 75 plug-and-play generative AI models that they can pick and choose from to apply to their products. That number will grow, and it means any company making devices with Qualcomm chips will be able to add all sorts of AI features.

The Galaxy S24 Ultra showing the new chat translation feature. Lisa Eadicicco/CNET

As well as deciding which AI features to develop, one of the next big challenges phone-makers will have to tackle is how to get AI onto their cheaper devices. For now AI is primarily reserved for the top-end phones — the Galaxy S24s of the world — but over time this will change. There will be a trickle-down effect where this tech ends up on a wider range of a company's devices.

There will naturally be a difference in quality and speed between what the most expensive and the cheapest devices can do, said Asghar, as is currently the case with a phone's camera tech.

AI is changing how we interact with our devices

AI enhancements to our phones are all well and good, but already we're seeing artificial intelligence being used in ways that have the power to totally change how we interact with our devices — as well as potentially changing what devices we choose to own.

In addition to enabling companies to bring AI to their existing device lines, Qualcomm's tech is powering concept phones like the T Phone, created by Deutsche Telekom and Brain.AI. Together, these two have tapped Qualcomm's chipset to totally reimagine your phone's interface, creating an appless experience that responds to you based on your needs and the task you're trying to accomplish and generates, on the fly, whatever you see on screen as you go.

This interface was generated in real time based on a request to find flights. Andrew Lanxon/CNET

In the demo I saw at MWC, AI showed it has the potential to put an end to the days of constant app-swapping as you're trying to make a plan or complete a task. ""It really changes the way we interface with devices and becomes a lot more natural,"" said Asghar.

But, he said, that's only the beginning. He'd like to see the same concept applied to mixed reality glasses. He sees the big benefit of the AI in allowing new inputs through gesture, voice and vision that don't necessarily rely on us tapping on a screen. ""Technology is much more interesting when it's not really in your face, but it's solving the problems for you in an almost invisible manner,"" he said.

His words reminded me of a moment in the MWC keynote presentation when Google DeepMind CEO Demis Hassabis asked an important question. ""In five-plus years time, is the phone even really going to be the perfect form factor?"" said Hassabis. ""There's all sorts of amazing things to be invented.""

As we saw at CES with the Rabbit R1 and at MWC with the Humane AI Pin, these things are starting to become a reality. In my demo with the AI Pin — a wearable device with no screen that you interact with through voice and touch — it was clear to me that AI is creating space for experimentation. It's allowing us to ask what may succeed the phone as the dominant piece of technology in our lives.

Watch this: Humane AI Pin Hands-On: Tiny Wearable Phonelet Beams Light Like R2-D2 06:30

It's also opening up new possibilities for tech that's been around awhile but for whatever reason hasn't quite struck a chord with consumers and found success outside of niche use cases.

Many of us have now played around with generative AI chatbots such as ChatGPT, and we're increasingly growing familiar with the idea of AI assistants. One company, Integrit from South Korea, brought a robot to the show that demonstrated how we may interact with these services in public settings, such as hotels or stores. Its AI and robotics platform, Stella AI, features a large, pebble-shaped display on a robotic arm that can swivel to address you directly.

Where this differs from previous robots I've encountered in customer service settings, such as the iconic Pepper, is that Stella is integrated with the latest AI models, including OpenAI's GPT-4 and Meta's Llama. This means it's capable of having sophisticated conversations with people in many different languages.

Rather than featuring a humanoid robot face like Pepper does, Stella uses generative AI to present a photorealistic human on its display. It's entirely possible that people will feel more comfortable interacting with a human, even one that isn't real, than a humanoid robot, but it feels very early to know this for sure.

Integrit's Stella combines robotics with AI in a fresh way. Andrew Lanxon/CNET

What is clear is that this is just the beginning. This is the first generation of devices to really tap into the power of generative and interactive AI, and the floodgates are now well and truly open.

""I think we'll look back at MWC 2024 as being a foundational year for AI on connected devices,"" said Wood, the CCS Insight analyst. ""All the pieces of the jigsaw are falling into place to enable developers to start innovating around AI to deliver new experiences which will make our interactions with smartphones and PCs more intuitive.""

If this is the beginning, I'm intrigued to check back a year from now to see how AI continues to change our devices. Hype aside, there's a lot already happening to be excited about.

Editors' note: CNET is using an AI engine to help create some stories. For more, see this post.",AI,Relevant,Relevant,
"NVIDIA hits the 'iPhone moment of AI' highlighting its latest RTX advancements for PC across gaming, creating, and everyday use",https://www.windowscentral.com/hardware/nvidia/nvidia-hits-the-iphone-moment-of-ai-highlighting-its-latest-rtx-advancements-for-pc-across-gaming-creating-and-everyday-use,"What you need to know

NVIDIA is also on the AI bandwagon and is leveraging its capabilities across its GPUs to make computing, gaming, and creating more accessible for users.

The company has freely made its NVIDIA Broadcast app available to users, which can be used to improve video conferencing and live streams using AI capabilities.

NVIDIA DLSS has been updated to version 3.5, which introduces Ray Reconstruction for a richer, more immersive gaming experience.

With AI's emergence, even more companies are integrating the technology into their products, services, and workflows. NVIDIA arguably contributed to the accelerated shift to AI computing, especially with the debut of RTX technologies alongside the first consumer GPU built for AI.

According to the company, 500 AI-powered apps have emerged from its early investment in AI on RTX PCs and workstations, with more than 100 million users benefitting from these advances. Generative AI in GeForce RTX GPUs provides a smooth gaming experience featuring higher frame rates.

GeForce RTX AI PCs and NVIDIA RTX workstations ship with sophisticated hardware to help AI run faster. The AI accelerators are called Tensor Cores and help boost AI performance, especially when using resource-hungry apps.

For context, AI performance is measured in teraops or trillion operations per second (TOPS). GeForce RTX GPUs AI performance ranges from 200 to 1,300 AI TOPS. This is a significant bump from the 10 to 45 TOPS range on the current generation of AI PCs without GPUs.

These advances aren't limited to power users, everyone gets to benefit

(Image credit: Windows Central)

Besides performance, RTX GPUs feature capabilities that make work easier for everyone. In February, NVIDIA unveiled its AI-powered chatbot dubbed Chat with RTX. But unlike chatbots like ChatGPT and Microsoft Copilot, it runs locally on your PC with GeForce RTX PCs and NVIDIA RTX workstations and doesn't send your data to cloud servers.

The capabilities include video upscaling, which can improve the quality of low-resolution videos to 4K high-resolution, high dynamic ranges using a single click on Microsoft Edge and Google Chrome.

Next is the NVIDIA Broadcast app, which is accessible for free to all RXT users. The app ships with AI capabilities to improve video conferencing and live streams. It can achieve this by eliminating the unwanted background clicky noise from keyboards during meetings. You can also remove or blur your background during the meeting. Additionally, it enhances and improves low-quality images using its VIdeo Noise Removal feature.

AI has undoubtedly contributed to enhanced and improved gameplay over the past few years. NVIDIA aims to build on this premise with the latest version of DLSS 3.5, which ships with Ray Reconstruction. The feature enhances the visual aesthetic appeal of games as it features a richer and more immersive gaming experience.

According to NVIDIA:

""There are now over 500 games and applications that have revolutionized the ways people play and create with ray tracing, DLSS, and AI-powered technologies.""

The technology will also improve how gamers interact with characters in games and remaster classic games for better gameplay. Finally, NVIDIA is also leveraging AI to automate recurring and tedious tasks for creators, allowing them to explore their potential fully.",AI,Relevant,Relevant,
China's Rush To Dominate AI Comes With a Twist: It Depends on US Technology,https://news.slashdot.org/story/24/02/21/2026232/chinas-rush-to-dominate-ai-comes-with-a-twist-it-depends-on-us-technology,"In order to dial out, it is necessary to broaden one's dimension.",General,Irrelevant,Irrelevant,-
UK and EU to sign new deal on small boat crossings,https://www.bbc.co.uk/news/uk-politics-68379392,"The agreement states that generally both the UK and the EU will cover their own costs for activities carried out under it. However, it says the UK will pay Frontex for certain activities, with the details to be decided in a separate agreement.",General,Relevant,Irrelevant,-
"Ex-google engineer charged for stealing ai secrets, working with Chinese firms",https://readwrite.com/ex-google-engineer-charged-for-stealing-ai-secrets-working-with-chinese-firms/,"A former Google software engineer has been charged over the theft of trade secrets from the Alphabet company whilst working covertly with two other firms based in China.

Linwei Ding, also known as Leon Ding, was charged this week by a federal jury in San Francisco on four counts of trade secret theft, which could see the Chinese national punished with up to 10 years in prison. In addition, Ding could be hit with a fine of $250,000 for each count.

The indictment revealed the 38-year-old stole detailed information regarding the hardware infrastructure and software capability that enables Google’s vast data centers to train artificial intelligence (AI) models via machine learning.

Thanks to his position, Ding was able to leak this extensive knowledge on chips and systems, including blueprints designed to gain leverage over cloud rivals Amazon and Microsoft (which design their own), as well as to reduce reliance on GPUs from Nvidia.

How have authorities responded to the charge?

The case against Ding was announced at a press conference hosted by the American Bar Association in San Francisco, with various law enforcement figures present, including Attorney General Merrick Garland and FBI Director, Christopher Wray.

“The Justice Department just will not tolerate the theft of our trade secrets and intelligence,” implored Garland.

“Today’s charges are the latest illustration of the lengths affiliates of companies based in the People’s Republic of China are willing to go to steal American innovation,” stated Wray.

“The theft of innovative technology and trade secrets from American companies can cost jobs and have devastating economic and national security consequences.”

This development comes just over 12 months after the Biden administration instigated a multiagency Disruptive Technology Strike Force to help prevent advanced technology from falling into the reach of countries such as China and Russia, or any similar activity which would threaten national security.

AI is thought to be at the top of the DTSF enforcement priority list, such is the importance of the technology in the battlefield of competition between major nation-state actors. This was alluded to by Attorney General Garland who added, “As with all evolving technologies, AI has pluses and minuses, advantages and disadvantages, great promise and the risk of great harm.”

Ding was first hired by Google in 2019, then three years later he allegedly began his nefarious thefts at the same time he was supposedly being headhunted for a senior position at a Chinese tech startup.

By mid-2023, he had uploaded more than 500 confidential files belonging to Google but by the end of the year, the tech giant had become suspicious, taking away his laptop on 4 January 2024, one day prior to the date he intended to resign his position.

Image credit: Brett Jordan/Pexels",General,Relevant,Relevant,
An unknown company just set a new standard for smartphone cameras,https://www.digitaltrends.com/mobile/an-unknown-company-tecno-just-set-a-new-standard-for-smartphone-cameras/,"In addition to showing off some fascinating concept phones at Mobile World Congress (MWC) 2024, Tecno has also announced a groundbreaking new image processing system that could change the way we capture videos on our smartphones.

The innovative technology brand is calling it the PolarAce Imaging System, and it’s powered by a Sony imaging chip that allows it to capture full 4K HDR video at 30 frames per second with AI-based noise reduction technology — an industry first.

Recommended Videos

A new era of smartphone video

In developing PolarAce, Tecno worked with Sony’s Lytia division and the Sony CXD5622GG imaging chip to provide the image processing power, on which it then laid on its own multi-skin tone and AI imaging technologies to create a unique video processing chip that goes beyond what most integrated system-on-a-chip (SoC) solutions can deliver.

For example, Tecno explains that many smartphone users struggle with capturing video in low-light or night environments along with full-scene HDR videography. Sony’s imaging chip has the horsepower to address these issues thanks to its unique floating-point computing capabilities that allow PolarAce to provide almost lossless image quality and far lower energy consumption than other image signal processors (ISPs).

The PolarAce ISP uses four engines in its processing pipeline. NeuroNR Turbo first uses AI to reduce noise in the RAW image, after which NeuroColor Turbo optimizes the colors for true-to-life skin tones, NeuroHDR Turbo improves the video quality, and NeuroFPS Turbo smooths things out, even for longer recordings.

The AI engines have also been tuned to handle low light in a whole new way, bringing what Techo calls 4K Ultra Night Vision. Tecno’s AI-powered Universal Tone technology provides accurate skin tones for diverse subjects.

Powerful AI features

PolarAce also includes generative AI technology for capturing portraits, with AI One Click Erase similar to Google’s Magic Eraser, and the ability to let users generate their own portrait disguised and backgrounds, placing them in wedding dresses, cartoon dolls, formal attire, and more, without the need for third-party apps.

“Our commitment and goal has always been to deliver the best mobile imaging experience to Tecno users around the world to meet diverse imaging needs,” said Jack Guo, General Manager of Tecno. “Previously, we have revolutionized smartphone imaging with innovations such as the advanced RGBW Ultra-Sensitive Sensor and the world’s first retractable portrait lens. Tecno PolarAce, our first imaging system with an independent imaging chip, leverages our partnership with Sony to signal a new era of extraordinary smartphone video imaging.”

Tecno will be launching the PolarAce Imaging System in its upcoming Camon 30 Premier 5G smartphone, set to arrive in the second quarter of 2024. It will include a 70mm periscope lens for ideal portrait shots with less barrel distortion and a hybrid zoom of up to 60x. Sony’s chip will serve as the ISP alongside a MediaTek Dimensity 8200 as the primary chipset.

Editors' Recommendations",Communications Technologies,Relevant,Relevant,
What Happened After Peter Thiel Paid 271 Students to Drop Out of College?,https://news.slashdot.org/story/24/02/24/2311221/what-happened-after-peter-thiel-paid-271-students-to-drop-out-of-college,"Since 2010, billionaire tech investor Peter Thiel has offered to pay about 20 students $100,000 to drop out of school each year ""to start companies or nonprofits,"" reports the Wall Street Journal . His program has now backed 271 people, and this year the applicant pool ""is bigger than ever.""So how's it going?",General,Relevant,Irrelevant,
Hackers Could Use ChatGPT to Target 2024 Elections,https://time.com/6717129/hackers-ai-2024-elections/,"The rise of generative AI tools like ChatGPT has increased the potential for a wide range of attackers to target elections around the world in 2024, according to a new report by cybersecurity giant CrowdStrike.

Both state-linked hackers and allied so-called “hacktivists” are increasingly experimenting with ChatGPT and other AI tools, enabling a wider range of actors to carry out cyberattacks and scams, according to the company’s annual global threats report. This includes hackers linked to Russia, China, North Korea, and Iran, who have been testing new ways to use these technologies against the U.S., Israel, and European countries.

With half the world’s population set to vote in 2024, the use of generative AI to target elections could be a “huge factor,” says Adam Meyers, head of counter-adversary operations at CrowdStrike. So far, CrowdStrike analysts have been able to detect the use of these models through comments in the scripts that would have been placed there by a tool like ChatGPT. But, Meyers warns, “this is going to get worse throughout the course of the year.”

If state-linked actors continue to improve their use of AI, “it’s really going to democratize the ability to do high-quality disinformation campaigns” and speed up the tempo at which they’re able to carry out cyberattacks, Meyers says.

“Given the ease with which AI tools can generate deceptive but convincing narratives, adversaries will highly likely use such tools to conduct [information operations] against elections in 2024,” the report’s authors say. “Politically active partisans within those countries holding elections will also likely use generative AI to create disinformation to disseminate within their own circles.”

Read More: How Tech Giants Turned Ukraine Into an AI War Lab.

The CrowdStrike report highlights how the digital battleground has expanded beyond active conflict zones like Ukraine and Gaza. In 2023, groups linked to Yemen, Pakistan, Indonesia and Turkey targeted entities in the U.S. and Europe “in retaliation against real or perceived support of Israel.” In October, a Yemeni group claimed credit for a DDoS attack against an unidentified U.S. airport, according to the CrowdStrike report. A South Asian hacktivist group claimed a similar attack against a British military website, which was “accompanied by references to U.K. support for Israel.” And an Indonesian group claimed to have breached the personal data of 790,000 doctors in the U.S. “reportedly in retaliation against U.S. support for Israel as well as to show support for Palestinians,” according to the report.

Some of the tech companies developing AI tools have been sounding the alarm themselves. Last month, OpenAI announced it would be rolling out new policies meant to combat disinformation and the misuse of its tools ahead of the 2024 elections,including verified news and image-authenticity programs. Microsoft has warned that state-backed hackers from China, Iran, and Russia have been using OpenAI’s large language models to improve their cyberattacks, refining scripts and improving their targeting techniques. While Microsoft has not yet found evidence of “significant attacks’” employing their large language models, cybercrime groups, nation-state threat actors, and other adversaries “are exploring and testing different AI technologies as they emerge, in an attempt to understand potential value to their operations and the security controls they may need to circumvent,” Microsoft said.

Read More: Election Workers Face Surge of Cyberattacks.

In one recent case, Microsoft and OpenAI analysts say they detected attempts from attackers working with Russia’s military intelligence to use their tools to understand satellite communication protocols and radar imaging technologies. ”These queries suggest an attempt to acquire in-depth knowledge of satellite capabilities,” Microsoft said in a statement. One China-affiliated actor known as “Salmon Typhoon” used OpenAI tools to “translate technical papers, retrieve publicly available information on multiple intelligence agencies and regional threat actors, assist with coding, and research common ways processes could be hidden on a system,” the company said in a post on Feb. 14.

While it’s not clear to what extent these attacks will succeed in influencing upcoming elections, they have already caused disruptions. Taiwan’s elections last month saw a sharp spike in cyberattacks targeting government offices from suspected China-linked actors, according to an analysis shared with TIME by U.S.-based cybersecurity firm Trellix. “Malicious cyber activity rose significantly from 1,758 detections on January 11 to over 4,300 on January 12,” the day before the election, according to Trellix analysts, before dropping dramatically again. “The timing suspiciously [suggests] a goal of influencing election outcomes.”",AI,Relevant,Relevant,
US awards $1.5bn to GlobalFoundries for domestic semiconductor production,https://readwrite.com/us-awards-1-5-bn-to-globalfoundries-for-domestic-semiconductor-production/,"Vice President Kamala Harris has announced that the US government will award $1.5 billion to expand semiconductor production. You can read the briefing-room official statement here.

US-based GlobalFoundries (GFS.O), the world’s third-largest contract chipmaker, will receive $1.5 billion to expand semiconductor production. On Monday, the Biden administration announced the decision, highlighting the need to “make progress on global supply chain challenges” and “secure domestic supply chains.”

The company will build a new semiconductor production facility in Malta, New York, while also expanding existing operations there and in Burlington, Vermont, as laid out in an initial agreement with the Commerce Department.

This is part of a long-standing push from the US government to strengthen US production of semiconductors and reduce reliance on imports from China.

“This investment will also create more than 10,000 good jobs over the next decade, including many union construction jobs that pay fair wages and offer benefits like child care services,” the Vice President said in a statement. “Additionally, the domestic production of these chips will provide more supply chain stability to the auto and aerospace industries across the United States that currently rely on the shipment of these chips from overseas.”

What do semiconductors do?

The tiny chips are primarily used in satellite and space communications and the defense industry. Everyday uses for semiconductors also include blind spot and collision detection in cars and EVs and cellular and wifi connections in smartphones and other connected devices. All in all, they are incredibly common and vital for many everyday technologies.

In addition, the new GFS.O facility in Malta will produce a specific type of chip not currently made elsewhere in the country. In Burlington, the production will focus on high-volume production of next-generation gallium nitride on silicon semiconductors to be used in electric vehicles, the power grid, and smartphones, according to a statement from Commerce Secretary Gina Raimondo at a press briefing, as reported by Reuters.

Featured image: Pexels",Communications Technologies,Relevant,Relevant,
Cognition Emerges From Stealth To Launch AI Software Engineer 'Devin',https://tech.slashdot.org/story/24/03/13/2347209/cognition-emerges-from-stealth-to-launch-ai-software-engineer-devin,"Longtime Slashdot reader ahbond shares a report from VentureBeat:Currently, Devin is available only to a select few customers. Bloomberg journalist Ashlee Vance wrote a piece about his experience using it here ""The Doom of Man is at hand,"" captions Slashdot reader ahbond. ""It will start with the low-hanging Jira tickets, and in a year or two, able to handle 99% of them. In the short term, software engineers may become like bot farmers, herding 10-1000 bots writing code, etc. Welcome to the future.""",AI,Relevant,Relevant,
A new satellite will track climate-warming pollution. Here's why that's a big deal,https://www.npr.org/2024/03/05/1235694992/a-new-satellite-will-track-climate-warming-pollution-heres-why-thats-a-big-deal,"A new satellite will track climate-warming pollution. Here's why that's a big deal

Enlarge this image toggle caption Courtesy SpaceX Courtesy SpaceX

VANDENBERG SPACE FORCE BASE, Calif. — Not far from the Pacific Ocean, where just to the south, oil platforms dot the horizon, a SpaceX Falcon 9 rocket blasted into space Monday with dozens of satellites on board.

Four miles away from the launch site, a crowd including scientists, engineers, and their families erupted into celebration. They were applauding largely for one satellite on board: MethaneSAT, which is built to detect methane. That's a gas that in the short term packs an even bigger planet-warming punch than carbon dioxide.

MethaneSAT – led by the Environmental Defense Fund – will have a targeted focus: to spot methane from the oil and gas industry, which leaks at various parts of the fossil fuel production process. Sometimes oil companies deliberately burn methane gas if they can't pipe it somewhere.

Reducing methane pollution can help the world meet its climate targets, but for years researchers had little understanding of where exactly methane leaks were coming from. Recent projects have helped give a clearer picture, but the data hasn't always been public, or precise – especially from oil fields, says Steven Hamburg, chief scientist for the Environmental Defense Fund (EDF) who led the MethaneSAT project.

The goal of MethaneSAT is to have a granular picture of where exactly methane comes from in oil and gas operations around the globe, in places like Texas, Russia and Nigeria. ""For the first time [we'll] have high quality empirical data for an entire sector across the globe,"" Hamburg says.

The oil and gas industry has historically had a culture of confidentiality, says Antoine Halff, chief analyst at Kayrros, a climate analytics firm. ""They like to keep their data private,"" he says. ""There's, I think, a cultural discomfort with the transparency provided by independent monitoring.""

When this satellite is fully operational in the coming months, it will provide data that will be free to the public. That will allow governments, researchers and others to have an unbiased view from space of most oil and gas operations, says Adam Brandt, a professor in the Department of Energy Science and Engineering at Stanford University who was not involved with the project.

""The beauty of having MethaneSAT,"" Brandt says, is ""we don't have to ask [oil companies] permission nicely to go on site and make measurements, right?""

toggle caption Julia Simon/NPR

The decision to look at oil and gas pollution

About 30% of global warming comes from human-caused methane pollution. Mark Brownstein, a senior vice president at EDF, says the question for a long time was how much methane comes from the oil and gas sector?

Other sectors also create methane pollution. Agriculture – specifically gas-belching cows and gas-emitting manure – is the single biggest source of methane in the U.S., according to data from the Environmental Protection Agency (EPA).

But focusing on the oil and gas sector was strategic, Hamburg says. Oil and gas has a concentrated number of players, with bigger budgets to clean up their operations. ""The ability to remediate is much greater and it's cost-effective,"" he says.

In the past six years EDF put together a team – including scientists from Harvard University and other groups – to build a satellite to get a better picture of the oil industry. The satellite has sensors specifically designed to pick up the fingerprint of the methane molecule. The sensors now orbiting in space will then send data back to Earth in the coming months.

The hope is that regulators will use this data, Hamburg says. ""There's interest. There's conversations, not just with the U.S. EPA, but in other governments and other regulators,"" he says.

Late last year the EPA made a new rule that for the first time requires oil and gas operators to monitor, detect, and fix methane leaks.

A spokesperson for the EPA said in an emailed statement that the EPA's new rule ""has a mechanism for third-party notifiers using approved remote sensing technologies to be certified – enabling them to notify EPA of methane super-emitter events."" Super-emitter events happen when large amounts of methane are released. ""EDF, along with other owners of remote sensing technologies, may apply to be certified,"" the EPA said.

Aaron Padilla, vice president of corporate policy at the American Petroleum Institute, the country's largest oil and gas lobby, says his industry has many years of experience using their own satellites and technologies to identify and then reduce methane emissions.

""Our industry's experience shows that one really needs to use a range of technologies working together across their strengths and weaknesses in order to get a truly accurate picture of where you have methane emissions,"" Padilla says.

Ultimately, Hamburg says he hopes that data from the MethaneSAT will move more oil and gas companies to clean up methane pollution.

""This is an industry that recognizes that their reputation, their markets are under threat,"" Hamburg says. ""So, if you're going to compete in a world in which the demand is going down, you want to prove that you're a better actor.""",Green Computing,Relevant,Relevant,
Egypt is building a mysterious 16-foot-high wall near the border with Gaza and it won't say why,https://www.businessinsider.com/egypt-building-giant-wall-gaza-border-report-israel-2024-2,"Egypt has begun construction of a wall near its border with Gaza, according to reports.

Its purpose remains unclear, leading to speculation it could be used to hold those crossing the border.

This comes amid increased border security in anticipation of Israeli attacks.

NEW LOOK Sign up to get the inside scoop on today’s biggest stories in markets, tech, and business — delivered daily. Read preview Thanks for signing up! Access your favorite topics in a personalized feed while you're on the go. download the app Email address Sign up By clicking “Sign Up”, you accept our Terms of Service and Privacy Policy . You can opt-out at any time.

Advertisement

Egypt is building a wall near Gaza's border, but the government has refused to say what it will be used for, CNN and The New York Times reported.

Images of a large section of land being bulldozed and a wall being built between the Egypt and Rafah buffer zone are visible in newly-released satellite images taken by Maxar Technologies.

Construction began at the beginning of February, according to CNN and The Times' respective analyses of the images.

An overview of the construction. Satellite image ©2024 Maxar Technologies

It's unclear when it is due to be completed, or its purpose.

Advertisement

One possibility, The Times reports, is that the wall could be used to hold Palestinians crossing the border. However, if this scenario were true, it would be a significant shift in the Egyptian government's previous refusal to accept Palestinian refugees.

A spokesperson for the Egyptian government declined to provide details on the construction when contacted by The Times, but instead referred to previous statements issued by the government, which highlighted the fortification of the border, the publication said.

Related stories

Egyptian security officials told CNN on Friday that the country's border security has increased as a precaution ahead of an expected Israeli attack in Rafah, where around 1.4 million Palestinians are seeking shelter.

Representatives for the Egyptian government did not immediately respond to BI's request for comment.

Advertisement

An unnamed contractor and engineer who said they were working on the construction told The Times that the Egyptian army had ordered it. They said the wall is set to be five meters high, about 16 feet, and will close off a five-square-kilometer plot of land.

The project began on February 5, and construction of the wall on Tuesday, they said. The source provided the information anonymously due to fear of reprisals, according to The Times.

A spokesperson for the Sinai Foundation for Human Rights told CNN that two local contractors had confirmed to them that the project was commissioned by the Egyptian army.

The organization, which focuses on marginalized areas in Egypt, did not immediately respond to BI's request for comment.

Advertisement

This comes after sources who spoke anonymously to Reuters said a desert area on the border ""with some basic facilities"" for Palestinians is being set up as a contingency plan.

However, the head of Egypt's State Information Service told the publication that this was not the case.",General,Relevant,Irrelevant,
Machine learning vs AI vs deep learning: The differences explained,https://www.androidauthority.com/machine-learning-vs-ai-vs-deep-learning-3420062/,"In today’s digital age, terms like machine learning, deep learning, and AI are often used interchangeably, leading to a common misconception that they all mean the same thing. However, these terms have distinct technical differences that are important to understand. This article aims to explore these terms in detail, but feel free to check out the video above as well.

What is machine learning and deep learning? Machine learning is a subfield of computer science that emphasizes the development of algorithms and statistical models. These models enable computers to perform tasks without explicit instructions, relying instead on patterns and inference. Unlike traditional computer programs where you specify the steps, machine learning presents examples from which the system learns, deciphering the relationship between different elements in the example.

Machine learning is a subfield of computer science that emphasizes the development of algorithms and statistical models.

Machine learning involves two distinct phases: training and inference. A computer algorithm analyzes many samples or training data to extract relevant features and patterns during the training stage. This data can include numbers, text, images, speech, and videos. The models analyze the data, identify different features in the dataset, and learn to distinguish one thing from another.

There are different methods of conducting the training stage. The first one, supervised learning, involves learning that explicitly maps the input to the output. Other types of training include unsupervised learning, where the patterns are not labeled, and reinforcement learning.

Inference, the second stage, is the output stage. Here, the model, drawing from everything it learned, is queried about something not included in the training data.

Calvin Wankhede / Android Authority

Numerous models can be used, and not all are neural networks. However, neural networks, which mimic how the neurons in the brain work, are pretty popular today. These digital neurons are arranged in layers, each having weights and biases. The network adjusts these weights and biases during the learning phase to produce the correct answer.

Deep learning relates to neural networks, with the term 'deep' referring to the number of layers inside the network.

There are various types of neural networks beyond classic examples, including convolutional neural networks, recurrent neural networks (RNNs) like long short-term memory networks (LSTMs), and more recently, transformer networks. Deep learning relates to neural networks, with the term “deep” referring to the number of layers inside the network.

How does AI differ from machine learning?

C. Scott Brown / Android Authority

Many machine learning systems we use daily, such as face detection, speech recognition, object detection, and more, are all types of machine learning, not AI. However, due to marketing strategies, these are often labeled as AI. AI, which originally referred to human-like intelligence in machines, now refers to any aspect of technology that partially shares attributes with human intelligence. In this sense, AI is very narrow and is essentially machine learning.

The Turing Test, a game where three people communicate via text messages, has been made obsolete by Language Models (LLMs) as they can imitate without thinking, thus invalidating the imitation game to answer the original question, “Can machines think?” This leads us to Artificial General Intelligence (AGI), a term used to describe a type of artificial intelligence that is as versatile and capable as a human. AGI is currently a theoretical idea with no existing systems. To be considered AGI, a system must learn and apply its intelligence to various problems, even those it hasn’t encountered before. A true human AGI would need to possess consciousness and self-awareness.

Comments",AI,Relevant,Relevant,
A Fully Automatic British Breakfast: Ready While You Sleep,https://hackaday.com/2024/03/17/a-fully-automatic-british-breakfast-ready-while-you-sleep/,"Among all the amazing technologies that were promised to us, there is one that is much more egregious than the lack of flying cars and real hovering hoverboards: the lack of fully automated breakfast-maker machines. Instead we find ourselves handling the same dumb appliances each morning as we make a healthy breakfast that we then have time to wolf down before rushing out of the door to still be a few minutes late for work. When [Greg] researched machines that could automatically prepare breakfast, he came up empty, which led him down the rabbit hole of the Autochef-9000.
 

 Although often featured in movies – ranging from Back to the Future to Wallace and Gromit – the contraptions in those are rarely practical, and real-life attempts often suffer the problem of feature creep as they have to handle too many ingredients and operations. This is where [Greg] found redemption in the simplicity of a proper British breakfast: beans, toast, sausages (sossys), and eggs. Months of CAD, welding, breadboarding, and writing Arduino code later, he made a machine that can open a can of beans, toast bread, boil eggs, fry up sausages, and deposit it all on a plate, all ready for that morning breakfast first thing when you stroll into the kitchen.
 

 Thanks to [htky] for the tip.",Robotics,Relevant,Relevant,
Our Era Is One of Defensive Nationalism. It’s Happened Before,https://time.com/6695953/defensive-nationalism/,"In late 2023, voters in Argentina and the Netherlands elected right-wing populists promising dramatic changes. But these two countries aren’t alone. Around the world, nations have become deeply polarized. Tense elections involving far right candidates have occurred across the globe in Peru, Israel, and Italy, among others. And, of course, the United States is headed for another nail-biter of an election in 2024.
 

 At the same time, violent conflicts have escalated. A recent report found that in 2022 deaths from internal and external conflicts increased 96% from the previous year. The carnage in Israel and Gaza will likely drive these numbers even higher.
 

 What could be the cause of these disturbing trends?
 

 We appear to be in the midst of an era of what I label “defensive nationalism.” Defensive nationalism is a form of national-populism, or a people’s movement focused on protecting the nation against globalizing forces, whether in the form of trade, finance, or immigration.
 

 Defensive nationalist movements emerge when revolutionary changes in transportation and communications shorten time and reduce distance. These globalizing changes produce wealth and internationalism. But they also dramatically disrupt societies, generating widespread unease and apprehension. Populist politicians capitalize on the generalized fear, painting international forces as a threat that must be countered. Economic protectionism is made to seem paramount, diplomacy takes a back seat, and the military becomes the bulwark of the nation.
 

 The result is an inward populist turn that pushes many people toward radical domestic politics and nations towards violence.
 

 Read More: A Make-or-Break Year for Democracy Worldwide
 

 The first era of defensive nationalism began in the 1860s after dramatic advances in railroads, steamships, printing, and the telegraph of the Second Industrial Revolution linked the world as never before.
 

 The rapid expansion of railways made toilsome mule-drawn trains and stagecoaches obsolete. Overland travel was democratized. Newspapers and journals could now be widely and rapidly distributed. Media sales soared across Europe and the United States. Even mail carriage was transformed. For example, in the 1850s, most Americans received fewer than five letters annually; by 1900, they averaged 94 pieces of mail.
 

 Steamships altered overseas travel as profoundly. Before the 1860s, oceanic travel was arduous, painfully slow, and costly. Few people willingly chose to emigrate to new continents. The largest movement of peoples across the seas occurred by brutal force, through the Atlantic slave trade. But with the advent of steamships, by the 1880s intensive emigration had spread from every corner of the globe.
 

 At the same time, the first in­tercontinental telegraph wire was laid in 1858, connecting North America to Europe. News across the Atlantic now flowed at the speed of an electrical impulse. Soon, telegraph cables were laid around the world. Accompanying the telegraph was tickertape. Traders had “up-to-the-minute” access to stock, gold, grain, cotton, and oil quotations. Metal markets, ship brokering, and insurance became global businesses, and capital markets grew internationally.
 

 In this new age of steal and steam, transatlantic trade costs dropped by roughly 60%. From 1870 to 1900, an unprecedented volume of goods was conveyed, at unprecedented speeds, and with greater efficiency.
 

 Read More: Elites Who Want to Fix the World's Problems Should Start By Looking in the Mirror
 

 The Gilded Age, as these decades came to be known, began with wonderment at technology’s astonishing ability to connect peoples and spread prosperity. But the bright hopes for a new era of peace and good will were quickly eclipsed by a dramatically polarized world that ultimately produced communism, fascism, and World Wars.
 

 The technological revolutions that connected the globe destroyed existing social structures. Industrialization uprooted traditional agriculture and artisan trades. It brought forth unprecedented levels of urbanization with never-before-seen slum conditions and led to deepening inequality.
 

 Added to this, unconstrained international speculation sparked global ec­onomic crises that further destabilized people’s lives. The first global financial panic came in 1873, when international wheat prices plummeted. Banking across Europe imploded, and pandemonium broke out on Wall Street. A decade-long, world-wide depression ensued. In 1893, the world was walloped by a second panic and depression that hit the United States particularly hard.
 

 At the same time, the first form of mass ""fake news"" materialized, known as “Yellow Journalism.” With reduced printing costs and rapid information sharing came fierce competition over emerging media markets. To capture market share, publishers emphasized lurid scandals and dangerously blurred fact and fiction. William Randolph Hearst’s New York Journal was even accused of triggering the Spanish-American war by publishing unfounded claims that a Spanish explosive device destroyed the American warship, the U.S.S. Maine.
 

 All these forces culminated in protectionist politics.
 

 The world’s first restrictive immigration laws were passed. In the 1880s, the United States, Canada, and Australia banned entry to Chinese laborers. Soon after immigration restrictions were adopted in Denmark, Germany, Argentina, and Brazil. By the 1890s, across Europe and the United States poor European immigrants were subject to surveillance, arrest, and mob violence. Over the following three decades, immigration restrictions in the United States became more expansive, while in Europe several states, including Ottoman-Turkey, Romania, and Russia, expelled or violently propelled the emigration of ‘unwanted’ populations.
 

 Economic nationalism gained ascendance. Almost as soon as international trade had been liberalized, anti-trade tariffs were instituted across Europe. By the 1880s, protectionist policies were adopted in Russia, Austria-Hungary, Spain, France, and Sweden. But the era’s highest tariffs were adopted by the United States, with the passage of the McKinley Tariff Act of 1890 that included duties on imports as high as 49.5 percent.
 

 Advanced societies became polarized. From the 1890s to the 1910s, socialist populist movements flourished that sought to protect farmers and factory workers from industrialists, bankers, and the corrupt elite. So too did pre-fascist movements that propagated a racialized version of nationalism. The most extreme form of these movements, the so-called völkisch movements, idealized the wholesomeness of the heartland and traditional peasant society (the “folk” or “volk” in German), while disparaging the modern city as a racially mixed cesspool threatening the nation’s purity.
 

 Thus ended the first liberal global order—at its height in the 1870s and finished off by the anarchist’s bullet that felled Archduke Franz Ferdinand in 1914, sparking World War I.
 

 Read More: Why So Many Politicians Are Talking About World War III
 

 Today, we appear to be undergoing similar changes.
 

 Transportation and communications technologies have once again compressed time and space, accelerating and democratizing the spread of information, increasing prosperity, and connecting peoples and economies in previously unfathomable ways.
 

 Yet, as in the last century, these positive changes have produced negative effects. Since the 1990s, waves of migration not seen in a hundred years have created destabilizing demographic shifts. Offshoring turned thriving industrial centers to rust. The complex global financial system has bred contagious economic crises. New forms of mass communication now threaten democracy globally. Even today’s extreme wealth concentration is on par with the Gilded Age.
 

 And so, nations are again turning inward. The world has been engulfed by an anti-global, anti-immigrant backlash. International systems are feared, economic protectionism has surged, and societies are once again splitting into opposing political camps.
 

 Over the past two decades, national populists have won an increasing percentage of the vote share. In Spain, populist parties roughly doubled their share of votes between 2015 and 2019. In Belgium and France, both right- and left-leaning populist parties made advances. Elsewhere, much of the gains are on the right. In the 2022 Italian election, the right-wing populist party, Brothers of Italy, secured the highest vote share of any single party. So did the Swedish nationalist right-wing party, the Sweden Democrats, emerging as that nation’s second-most popular party in 2022. In the Netherlands, right-leaning populist parties garnered around 16% of the vote in 2021. In the United States, an extreme right-wing faction of the Republican Party, the House Freedom Caucus, almost doubled their congressional seats, from 29 in 2016 to 46 in 2022.
 

 Defensive nationalism seems here to stay. This is worrisome. Dysfunctionally polarized domestic politics, decreased trust in the international order, and a ""my-nation-first"" ideology present a recipe for conflict. We have witnessed this with Putin’s war on Ukraine, Xi Jinping’s saber rattling in the South China seas, and Netanyahu’s brutal bombardment of Gaza.
 

 Unfortunately, political polarization, rising fascism, and violent conflict are trends that do not appear to be abating any time soon. If history is our guide, we should brace ourselves for more of the same.
 

 B. S. Rabinowitz is an Associate Professor of Political Science at Rutgers University, Camden and author of the book, Defensive Nationalism: Explaining the Rise of Populism and Fascism in the 21st Century.
 

 Made by History takes readers beyond the headlines with articles written and edited by professional historians. Learn more about Made by History at TIME here. Opinions expressed do not necessarily reflect the views of TIME editors.",General,Relevant,Irrelevant,
Apple's AI training 'breakthroughs' retain privacy while making LLMs more flexible,https://appleinsider.com/articles/24/03/17/apples-ai-training-breakthroughs-retain-privacy-while-making-llms-more-flexible,"If you buy through our links, we may get a commission. Read our ethics policy
 

 Article Hero Image
 

 Apple researchers have hit on a new multi-modal method of quickly training large language models (LLMs) that can enable more flexible and powerful machine-learning and ""AI"" type systems.
 

 A research paper posted by the company to research site arxiv.org earlier this week revealed that Apple has used what it calls a ""careful mix"" of image-caption, interleaved image-text, and text-only data to train LLMs. The mix of visual and language data allowed the models to handle tasks like intelligently captioning images or infer natural-language meanings.
 

 As part of the research, it was determined that the choice of image encoder and the resolution of images it processes has a big impact on performance, more than the design of the vision-language connector.
 

 In one instance, using a 30-billion-parameter MM1 model, it was found that there were strong in-context learning abilities. The discovery means it can perform multi-step reasoning over multiple images with few ""chain of thought"" prompts.
 

 According to Venturebeat, Apple is continuing its tradition of being a ""fast follower"" rather than a ""first mover"" when it comes to groundbreaking technologies. CEO Tim Cook recently acknowledged that the company was spending $1 billion per year on incorporating ""AI"" into its existing technologies.
 

 Cook said the company would be sharing ""details of our ongoing work in AI later this year."" Apple is expected to make some announcements about its advances at WWDC this June.
 

 The company is both catching up to rivals in the use of AI-related technologies. It is also developing methods that would preserve user privacy while augmenting its existing machine-learning abilities.
 

 The latter concern for privacy and security has not been a feature of existing ""chatbot"" type services, and increases the challenge for Apple.",AI,Relevant,Relevant,
China's Nio and CATL team up to develop longer-life EV batteries,https://www.autoblog.com/2024/03/17/chinas-nio-and-catl-team-up-to-develop-longer-life-ev-batteries/,"A Nio EC6 SUV at one of the company's battery swap stations. (Getty Images)
 

 BEIJING — Chinese electric vehicle maker Nio has signed a partnership agreement with battery giant CATL to develop longer life batteries as part of efforts to lower overall EV costs.
 

 The partnership will leverage technologies from both companies seeking to lower the so-called ""full life cycle"" costs of batteries — key for the operating costs of Nio's thousands of battery-swapping and charging stations, William Li, Nio's founder and CEO, told reporters in Beijing.
 

 “One of the most important problems that has fundamentally not been solved nor attracted widespread attention is battery life,” Li said.
 

 “This is not only a problem that Nio needs to solve, but one that the whole industry must work together to solve.""
 

 Warranties typically cover EV batteries for eight years. Between 2025 and 2032, nearly 20 million EV battery warranties in China will expire, Nio said, pointing to the shorter life of batteries versus cars and the expense of replacing power packs.
 

 Nio said it had extended the lifespan of swappable batteries through its research efforts, retaining 80% of capacity after 12 years.
 

 The company also announced a cut of up to 33% in monthly rental fees for batteries for Nio users in a battery rental scheme, which works to lower EV purchase costs by as much as 128,000 yuan ($18,000).
 

 After receiving more than $3 billion from Abu Dhabi investor CYVN Holdings last year, Nio has strived to become profitable more quickly by trimming its workforce and deferring long-term investments to improve efficiency.
 

 The company, however, said it would still keep investing in developing core technologies such as batteries on its own. It has commercialized 150 kilowatt hour (kWh) semi-solid-state batteries for its EVs, manufactured by Beijing Welion New Energy, which have a range of up to 1,000 km (620 miles).
 

 Nio has also invested heavily in infrastructure for battery charging and swapping. It currently has 2,382 swapping stations and 21,652 public charging stations, according to Li, who added that charging has turned profitable for Nio but that it is still losing money in battery swapping.
 

 Swapping could help to ease the strain on power grids at peak times when drivers recharge, but industry analysts and executives expect it will only become mainstream if batteries become more standardized.
 

 While some have criticised swapping stations as a costly investment, Nio says they can be both a quick solution to powering up EVs and an energy storage facility to improve grid stability.
 

 Nio expects to unveil its second brand, known as Ledao in Chinese, in May, the company's president Qin Lihong said. Nio has been developing two sub-brands to target a wider range of consumers and the project code name for Ledao was Alps.
 

 Nio currently buys most of its batteries from CATL and has been exploring battery supplies from new partners such as CALB.",Green Computing,Relevant,Relevant,
Did the Plastic Industry Knowingly Push Recycling Myths For Decades?,https://news.slashdot.org/story/24/03/17/0157225/did-the-plastic-industry-knowingly-push-recycling-myths-for-decades,"Reducing plastic production ""to a level that is more manageable with recycling systems.""
 

 Getting rid of types of plastic that are ""especially hard to recycle or you can't recycle.""
 

 ""Being more transparent about what chemicals go into this stuff that again make recycling hard.""
 

 A PBS reporter ""digs into a new report covering the plastic industry's tactics to push recycling — and avoid regulation,"" according to a new video from PBS News Weekend In the video NPR correspondent Michael Copley says ""I think it's always striking, when you see a report like this that unearths new statements, new quotes, and to see the way in which they really seem to view recycling as sort of public relations tool, as opposed to an environmental tool that they sort of presented publicly...""A plastics trade group accused the report of citing ""outdated, decades-old technologies"" and ""mischaracterizing the current state of the industry,"" saying they're looking to have all plastic packaging be ""reused, recycled, and recovered by 2040.""But PBS's reporter counters that there's ""deep skepticism"" of the economics from market analysts — as well as from material scientists. ""Obviously the industry has put out this promise. I think that its critics will say, 'We have been hearing these promises, or promises like it, for decades now, and that there's nothing in the record to think that now is any different.""He adds that activists and businesses agree that government regulation will ultimately play a big role. ""That gets back in large part to the economics of this. If companies don't have to deal with these costs, it's hard to imagine that they will in a sustained way create systems to deal with this if they don't have to.""So what's the solution? Some ideas being seriously discussed:",General,Relevant,Irrelevant,
Infinix NOTE 40 phones blend sleek urban aesthetic with super-fast charging,https://www.yankodesign.com/2024/03/18/infinix-note-40-phones-blend-sleek-urban-aesthetic-with-super-fast-charging/,"Of the many things that smartphone buyers look for, cameras and battery life probably rank the highest, even over display quality. Capturing memories is a very important part of what people use smartphones for, but an extremely short battery life can ruin even the most powerful smartphone. In fact, the more powerful a device is, the faster it will drain its battery. While batteries themselves haven’t evolved as fast as smartphones, charging technologies have been growing in leaps and bounds. In the past, super-fast charging speeds have been exclusive to high-end, premium phones, but the new Infinix NOTE 40 smartphones are bringing that technology and convenience to a wider and younger audience that also cares just as much about style as they do the rest of the phone’s specs.
 

 Designer: Infinix
 

 Although there are research and innovations that attempt to improve the quality of smartphone batteries, they’re pretty much still the same packs that we’ve been using for years. Manufacturers have poured their efforts into improving charging speeds instead, making sure that people spend as little time as possible when they do need to plug the phone in. That’s what Infinix’s new All-Round FastCharge 2.0 technology is trying to accomplish, bringing speed and versatility to users’ charging experience.
 

 This technology supports rapid charging at 70W for the new Infinix NOTE 40 and NOTE 40 Pro (4G), as well as blazing fast 100W speeds for the Infinix NOTE 40 Pro (5G) and NOTE 40 Pro+ 5G. Thanks to Infinix’s self-developed Cheetah X1 chip, these phones can boast reaching 50% in just minutes (8 minutes for the Infinix NOTE 40 Pro+ 5G, to be precise) while still providing safety and longevity. Additional charging highlights include Bypass Charging 2.0 to minimize heat generation when playing games while the phone is plugged in, 20W wireless charging, and, perhaps most interesting, Infinix’s own brand of magnetic wireless charging technology, MagCharge.
 

 The Infinix NOTE 40 series is designed to cater to a younger audience that appreciates a more distinctive and livelier aesthetic than most gray, black, or even white phones in the market. That’s why Infinix adopted an urban theme for the phone’s designs, creating a sleek and modern appearance through smooth curves, colors, and materials. The Vintage Green, for example, tries to evoke a sense of charm for retro styles and uses vegan leather to add a bit of luxury to the finish. Titan Gold’s mix of blue and yellow tries to capture the image of the sun setting over the city’s horizon.
 

 In terms of hardware, the Infinix NOTE 40 runs on MediaTek’s mid-range chips, paired with 8 or 12GB of RAM. All four models in this series get a 108MP main camera, though only the Pro variants put optical image stabilization (OIS) on it. The brand also introduces an AI-powered Active Halo lighting feature for dynamic notifications and accents to give a little life to your smartphone usage. The Infinix NOTE 40 series launches globally this month, available in Vintage Green, Obsidian Black, and Titan Gold colorways. A special BMW DesignWorks Racing Edition will be coming later this year to truly drive home the phone’s super-fast charging speed.",Communications Technologies,Relevant,Relevant,
Nvidia Backs Little-Known Upstart in India’s Biggest AI Bet Yet,https://finance.yahoo.com/news/nvidia-backs-little-known-upstart-110030317.html,"(Bloomberg) -- It’s a sultry March evening in the suburbs of Mumbai and a group of men hovers anxiously at the back gate of a startup called Yotta Data Services. They pace, pause and fret. It’s approaching midnight, 10 hours late, when a truck pulls up with the precious cargo they’ve been waiting for: semiconductors from Nvidia Corp.
 

 Most Read from Bloomberg
 

 The company’s products are so coveted because they’re essential for the development of artificial intelligence, the technology that’s set off a frenzy in industries around the world. While companies like OpenAI and Google have poured billions of dollars into such chips in the US, Yotta is making India’s largest bet yet on the promise of AI.
 

 Sunil Gupta, chief executive officer and co-founder, has gotten a jump on the country’s better-known technology players and conglomerates in part because of the relationship he’s forged with Jensen Huang, Nvidia’s celebrity CEO. Yotta is expected to feature at Nvidia’s developer conference Monday in California, an early example of the potential for AI in markets beyond the US.
 

 “I’m ambitious, I’m hungry,” said Gupta, 52. “I’m willing to take a bet on the future of AI.”
 

 Yotta’s strategy is to offer high-performance computing capabilities from data centers in India so the country’s corporations, startups and researchers will be able to develop their own AI services. Nvidia’s chips, the most advanced on the market, are essential for training large language models and building applications like OpenAI’s ChatGPT and Microsoft Corp.’s coding assistant, GitHub Copilot. Gupta figures he’s got an edge over cloud computing services outside the country because of latency issues, and he vows to offer the least expensive access to Nvidia AI chips in the world. He’s even considering letting Indian startups with tight budgets give him equity instead of cash.
 

 Story continues
 

 Demand is on his side. The global AI market is projected to grow from $168.5 billion in 2022 to over $2 trillion by 2032, according to a report by Spherical Insights & Consulting.
 

 “This is a gold rush,” said Stacy Rasgon, an analyst at Sanford C. Bernstein. “It’s still the early days of AI, and companies just can’t buy enough of this stuff.”
 

 The new era got off to a rocky start this month in India. The country’s customs officials were flummoxed by the unusually high value of the Nvidia chips that Yotta had purchased, leading to requisitions of additional paperwork and bureaucratic approval. Back in his data center outside Mumbai, Gupta paced the marble floors of the lobby for the better part of a day, working the phones to get his chips released.
 

 The delivery truck finally pulled up and workers unloaded the first of more than 4,000 H100 chips that Yotta ordered from Nvidia. The beefy graphics processing units, or GPUs, run $30,000 to $40,000 each and are called Hoppers in a nod to computer science pioneer Grace Hopper.
 

 The delivery was a religious experience for Gupta, quite literally. A priest adorned the boxes with red vermilion marks and strings of yellow chrysanthemum flowers, while hymns in ancient Sanskrit filled the night air. A camera-carrying drone recorded as Gupta symbolically smashed a coconut on the floor near the truck. “It’s a dream moment,” he said, amid exploding party poppers.
 

 Yotta’s haul of Nvidia chips, which will reach about 20,000 by June, isn’t huge by global standards. Tech giants like Microsoft Corp. purchase them by the tens of thousands, and Meta Platforms Inc.’s Mark Zuckerberg said he aims to get 350,000 H100s by year-end. Still, Nvidia’s supply is far short of demand so CEO Huang has to calibrate allocations as corporate titans and heads of state press for allotments.
 

 India is getting special attention. In September, Huang met with Prime Minister Narendra Modi and said he would prioritize any orders from data center operators in country. “You have the data, you have the talent,” Huang said at the time. “This is going to be one of the largest AI markets in the world.”
 

 The next day, Gupta got a call from the Nvidia team asking him if he could meet the CEO in the western city of Pune. Though it was late evening and the meeting would be the next morning, Gupta quickly agreed. He jumped in his car and drove three and a half hours through the night for the confab. It was a demonstration that Yotta would go above and beyond.
 

 Gupta has serious bona fides in the field. He’s been working for decades on data center businesses and co-founded Yotta in 2019 with the backing of real estate billionaire Niranjan Hiranandani. As a cloud computing operator, Yotta offers companies like Wells Fargo & Co. access to data storage and computing power they can scale up or down as needed, without buying and installing their own hardware.
 

 Tata Group and Reliance Industries Ltd., two of the country’s largest conglomerates, plan to develop AI infrastructure too, but have yet to order Nvidia’s most advanced chips.
 

 Follow Bloomberg India on WhatsApp for exclusive content and analysis on what billionaires, businesses and markets are doing. Sign up here.
 

 An Nvidia spokeswoman declined to comment on the specifics of Yotta’s order, pointing out that more will be revealed this week. Gupta is speaking at Nvidia GPU Technology Conference, and he has been told Huang will discuss Yotta during his keynote on Monday.
 

 One reason for the attention is a global imbalance in AI. If the technology has the potential to transform virtually every industry, as Huang and Microsoft CEO Satya Nadella argue, then countries like India, Indonesia or Turkey are at risk without access. In India, that could stymie scientific research, startup development and, more broadly, Modi’s ambitions to create a technology superpower. “GPU disparity” is an increasingly popular term for the dilemma.
 

 “Countries who don’t have their own AI infrastructure and models will woefully lose the AI race,” said Umakant Soni, co-founder of a nonprofit AI and robotics research park called ARTPARK.
 

 Gupta sees a clear need to develop India-built AI models, trained with local languages and cultural diversity. “India needs sovereign AI, India needs sovereign models,” he said.
 

 Geopolitics is helping his case. Rising tensions between the US and China have led the Biden administration to levy sweeping controls over the export of technologies to its geopolitical rival, including the very H100 Nvidia chips Yotta is buying. Cloud providers in the Middle East have also come under scrutiny after a key US lawmaker urged the Commerce Department to probe the Chinese connections of Abu Dhabi-based AI firm G42.
 

 Gupta figures he can supply Indian customers and others in Asia and the Middle East. Yotta already has half-dozen data centers in four Indian cities, and a new one opening in India’s northeast. The entrepreneur named his company after the number eight in ancient Greek, representing one septillion.
 

 “India is playing a bit of catchup,” said Nruthya Madappa, a partner with the venture capital firm 3one4 Capital. “But because of the talent base, we see the catchup being very, very fast.”
 

 The seven-floor data center outside Mumbai is surrounded by electric fences, equipped with 850 cameras and includes seven layers of security. Mammoth diesel storage tanks hold enough fuel to run the facilities for 48 hours if the power goes out.
 

 Gupta’s partnership with Nvidia mandates such rigid protocols, along stringent specs for building the AI cloud business. He’s sealed off the facility’s entire sixth floor for that purpose. An Nvidia team will arrive in the coming weeks to get the network up and running, with a target of starting operations in mid-May. Gupta calls the first H100 cloud service Shakti, the Hindi word for power.
 

 He says he’s sold out capacity for the day his network goes live, and has a waiting list of companies from India and beyond. Gupta is already looking forward to the next delivery of Nvidia chips, more than 16,000 scheduled for June. He’ll do at least one thing differently though: hire guards since the value of the shipment could run into the hundreds of millions of dollars.
 

 “Security?! I never thought of that!” said Gupta. “A lot of people want these.”
 

 Most Read from Bloomberg Businessweek
 

 ©2024 Bloomberg L.P.",AI,Relevant,Relevant,
Liebreich: Net Zero Will Be Harder Than You Think – and Easier. Part II: Easier,https://about.bnef.com/blog/liebreich-net-zero-will-be-harder-than-you-think-and-easier-part-ii-easier/,"By Michael Liebreich, Senior Contributor, BlooombergNEF
 

 

 

 Welcome to the second part of my two-part article exploring the bull and bear cases for the net-zero transition.
 

 In September last year, I laid out the bear case, highlighting the Five Horsemen of the Transition that will make achieving net zero difficult, perhaps impossible. By way of reminder, these were: poor economics of clean solutions beyond wind, solar and batteries; inadequacy of our current electrical grid; soaring demand for critical minerals; political and social inertia; and regulatory capture and predatory delay. Five formidable challenges.
 

 I finished that piece by noting that the Five Horsemen of the Transition were not necessarily showstoppers – each of them might be overcome with the right leadership, focus, innovation and resources.
 

 Now it is time to present the bull case – the five forces even more powerful than the Five Horsemen which give cause for optimism. Not powerful enough, in all likelihood, to get us to net zero in 2050 and hold the temperature increase to 1.5C, but powerful enough to get us to net zero by 2070 and keep to a Paris-compliant “well below 2C”.
 

 Say hello to the Five Superheroes of the Transition.
 

 Superhero 1: Exponential Growth
 

 Twenty years ago, in 2004, it took an entire year to install a single gigawatt of solar PV. By 2010, it took the world one month to install a gigawatt. By 2016, one week. Last year saw single days on which a gigawatt of solar PV was installed.
 

 Cumulative solar PV installations have doubled ten times in that period, and it is doublings that drive down costs. Solar PV has been delivering a learning rate of around 25% per doubling for the past five decades, chopping the cost of modules from $106 per Watt of capacity in 1975 to $0.13/W in November 2023 (according to BloombergNEF’s solar price index), a factor of 820.
 

 The wind sector has doubled six times over the past 20 years – relatively staid, but only by comparison with solar PV. In 2004, 8 gigawatts of wind power were installed; in 2023 the figure was around 110GW, including 12GW of offshore wind. Wind’s costs too have plummeted, from $0.12/kWh for the best projects twenty years ago to around $0.02/kWh for onshore wind and $0.05/kWh for offshore.
 

 As a result, wind and solar together make up the fastest-growing source of electricity in history. Twenty years ago, they accounted for less than one percent of global power; 10 years ago, the figure edged up to 3%. By the end of last year, it had surged to 15%. The growth of nuclear in the 1980s is often held up as the fastest-growing source of clean energy. Not even close: in its best year, nuclear power output increased by 230 terawatt-hours, adding 2.6% to the global electricity supply. Last year enough new wind and solar capacity was installed to deliver an expected 800 TWh each year, which would fulfill 2.8% of global power demand – and the rate of adding wind and solar – the second derivative – is continuing to accelerate.
 

 In 2004, the largest operating wind turbine had a capacity of 2.5 megawatts. Ten years ago it was 8MW. Today it is 15MW. The next generation wind platform, being developed in China, will deliver more than 20MW per turbine. In solar, manufacturing capacity, which was around 1.5GW in 2004 and 48GW at the end of 2014, is expected to pass the TW mark by 2025. At the COP28 meeting in Dubai, the world agreed to triple installed renewables by 2030; in its latest Renewables Report, the IEA forecasts that achieving two-and-a-half times would not even require new policies.
 

 The same thing has been happening for batteries – they have in fact been racing through doublings even faster than solar: five of them in the last eight years. In 2015, some 36GWh of lithium-ion batteries were produced; last year the total was around 1TWh. Over the past decade, cell costs have come down from $1,000 to $72 per kWh, and at the same time energy density has doubled and degradation per cycle has halved. We are also seeing new battery chemistries such as iron-air and sodium-ion that promise to be even cheaper than lithium-ion.
 

 Now, before you reach for your keyboard to object that no physical technology can exhibit exponential growth, it can only follow a logistic S-curve, with eventual saturation, please stop: I know. I calculated my first S-curve, for the replacement of cellulose packaging with oriented polypropylene, nearly 40 years ago. It turned out that polypropylene was so much cheaper and better than cellulose that it kept creating new markets for itself and outstripped demand for cellulose by several orders of magnitude. The lesson I learned is that until you know the ultimate market size for a new technology, don’t hang your hat on what I call Saturation Theory.
 

 In 1993, a group of German utilities placed full-page ads in German newspapers stating that “renewable energies like sun, water and wind will not be able to cover more than 4% of our power demand, even in the long term”. In 2023, renewables provided over 50% of German electricity. In 2017, a group of Norwegian academics wrote a paper entitled Limits to growth in the renewable energy sector, predicting that global wind and solar capacity would saturate in 2030 at 1.7TW. By 2023, the half-way mark of their forecast, the figure already surpassed 2.1TW and the installation rate hit 0.5TW per year.
 

 Saturation Theory is systemically embedded in the models run by official energy forecasters like the IEA, the US’s EIA and the IPCC, which is why their forecasts have repeatedly proven worthless. Deep in the small print you’ll find either explicit limits to the extent or growth of any resource, or floor prices below which cost curves are not allowed fall. The developers of these models come up with all sorts of justifications for these manual limits, but the real reason is simple: if they didn’t include them, solar, wind and batteries would dominate all scenarios – to an extent the modellers believe would be implausible, career-limiting or both.
 

 The real world, however, doesn’t care about such concerns: industries can and do pass through singularities to become ubiquitous. There are no limits to learning curves: doublings may slow as industries mature, but cost reductions never reach an end point. There is also no fundamental lack in the earth’s crust of the critical minerals needed for the transition. Taken together, this means that there are no fundamental limits to the penetration of clean energy technologies into the world’s energy system.
 

 I’m the last person to claim we are headed to a world of 100% wind, water and solar. Nuclear and geothermal power, bio-based solutions, CCS and carbon removal will all play a role. I’m just saying that the growth of wind and solar is likely to look exponential for a long time to come.
 

 

 

 Superhero 2: Systems Solutions
 

 Many people find it hard to accept the idea of a power system with cheap, abundant wind, solar and batteries at its heart, citing the inability of batteries to cover periods over a day or so when wind and solar output fall away dramatically.
 

 The answer to variability, however, is not batteries. It is a system solution – a combination of demand response, interconnections, excess generating capacity, pumped storage, nuclear power, CCS, hydrogen and biogas long duration storage, integrated by means of an extensive grid and managed using the latest digital technologies. The good news is that each of these constituent technologies is seeing remarkable growth and investment, and they are slowly being knitted together by successive iterations of regulation, making system solutions the Second Superhero of the Transition.
 

 The need to build a vast amount of new grid capacity – $21.4 trillion worth to get to net zero, according to BloombergNEF – was of course my Second Horseman of the Transition. There are, however, five reasons to think it can be vanquished.
 

 First, there are no physical limits to the amount of transmission that can be built. Over the past 50 years, global power transmission capacity grew by a factor of five; we can certainly grow the grid by another factor of five over coming decades, even if we miss the near-term targets for 2030.
 

 Second, technology. Digitization is already enabling us to get more from less in terms of capacity, HVDC technology is scaling rapidly, and superconductors will at some point do to conventional power cables what fibre-optics did to conventional telephone cables.
 

 Third, price signals. As an example, in the UK, we have a single wholesale power price covering the whole country. When it is windy in the north, the forward price plummets, companies like Octopus tell their users to switch on their appliances and demand soars. Because there is inadequate north-south transmission capacity, however, with one hour to go National Grid has to pay gas and diesel generators in the south to fill the shortfall. Madness.
 

 One solution lies in relentlessly driving through new transmission lines. The alternative, however, is to switch to locational pricing, building transmission only where the economics make sense. Power generators hate the idea – they like being paid top dollar for power wherever it is generated, and whether it is used or curtailed. But the analysis is clear: the more localized your pricing, the less transmission you need to build and the lower the cost of getting to net zero.
 

 The fourth reason why the grid build-out challenge is smaller than you might think is the changing location of power demand – like it or not, deindustrialization is going to move demand to where renewable energy is plentiful, reducing the need for wires.
 

 The fifth and final reason is the electrification of land transport and space heating. Already, just over a decade since the launch of the Tesla S, nearly one new car in five is electric; all major car manufacturers have put electrification at the heart of their futures. Much was made of a supposed slow-down in EV demand last year, but I’m not seeing it: global sales grew from 10.5 to 14 million, an increase of 33% and U.S. sales in fact grew by 48%.
 

 Heat pumps too are flying off the shelves. Sales in Europe grew 2.5 times between 2017 and 2022; in the US for the past two years, more heat pumps were sold than gas furnaces. Only the UK lags, installing just 55,000 in 2023 against France’s 600,000. Using an industrial heat pump, a factory can use a modest amount of power to upgrade its own waste heat back to the temperature needed for its processes. Circularity of industrial heat – how cool is that?
 

 EVs and heat pumps are the natural complementary technologies to wind and solar, in that their use can be time-shifted by a few hours or days to accommodate mismatches in supply and demand. Faced with a grid that it is curtailed, instead of building costly and unpopular transmission lines, or running a hydrogen electrolyzer for a few hours a week and blending the exorbitantly expensive results into the gas grid for little value, let the power price drop locally and watch people rush out to buy EVs and heat pumps.
 

 We have learned time and again over the past 20 years, price signals matter. Get them right, and things move much faster than you might expect.
 

 Superhero 3: Great power competition
 

 In 2018, I wrote a piece entitled Beyond Three Thirds, The Road to Deep Decarbonization. In it, I explained that trends in renewable power, EVs and energy efficiency would be sufficient to see emissions plateau. But driving them toward zero would require solutions for heat, industry, chemicals, aviation, shipping, steel, cement and agriculture – which soon began to be called hard-to-abate sectors.
 

 What is notable, re-reading that piece, is that while I was optimistic about new technologies, I could not say which ones would win. If you want a smile, read the section on hydrogen, which clearly pre-dates the detailed work that went into the Hydrogen Ladder.
 

 Things could not be more different today. For even the most challenging sectors we now have line of sight to decarbonization. In many cases we are seeing more than just pilots: in steel, fertilizers, mid-stream oil and gas, shipping, and even cement, billions of dollars are being invested, with a bit of help from supportive governments and programs like the US Inflation Reduction Act.
 

 There are of course still substantial uncertainties. In shipping, battle lines are drawn between ammonia (toxic and dangerous) and methanol (easy to handle but requires a carbon molecule). Steel has plumped for hydrogen, though direct electrical reduction, biochar or carbon capture might ultimately prove cheaper. Green and blue hydrogen are fighting for the fertilizer sector, though biological and other novel approaches might eventually eat their lunch. For aviation, e-fuels have their fans, but look like staying prohibitively expensive versus bio-based SAF or SAF made with bio-carbon and green hydrogen, so-called power-and-bio-to-liquid (PBTL). And any of these approaches could be wrong-footed if carbon dioxide removal (CDR) can generate enough cheap, permanent offsets.
 

 Overall, there are no longer any so-called hard-to-abate sectors. There are only some sectors in which clean solutions are not projected to undercut their fossil-based alternatives, perhaps ever. They will require a carbon price, but it’s an affordable carbon price: one that we are wealthy enough to pay, should we so decide. For even the most challenging sectors, we are now seeing more than one competing pathway viable at carbon prices in the range of $75 to $250 per ton of CO2 equivalent, which is a far cry from 2018, when it looked like they might need carbon prices of $500 or even $1,000/tCO2.
 

 Combine this line-of-sight to decarbonization with a new era of international rivalry between the US, China, Europe and emerging industrial powerhouses such as India, Brazil, Mexico and Turkey, and the conditions are set for a race to own the net-zero industries of the future – making great power competition and the self-fuelling momentum of the no-longer-hard-to-abate sectors the Third Superhero.
 

 Superhero 4: Disappearing Demand
 

 The fourth Superhero of the Transition is the fact that that achieving net zero will require a lot less in the way of minerals than we think, and they will be cheaper than we fear.
 

 The fivefold increase in demand for critical minerals from the energy sector was, you may recall, my third Horseman of the Apocalypse. However, estimates of critical mineral demand from clean energy technologies have been very substantially over-estimated. Even well-constructed mainstream forecasts are missing the impacts on demand of technological improvements, material substitution and, critically, recycling.
 

 It is a truth universally acknowledged that only 5% of lithium-ion batteries are recycled, with the rest going to landfill. This claim is, however, false. It has been traced back to a report written in 2011 by Friends of the Earth, which divided volumes of collection by volumes of manufacturing at the time. Prior to the arrival of any EV batteries at the end of their life, collection rates for lithium-ion batteries were of course miniscule. However, as recycling expert Hans Eric Melin points out, EV batteries are packed with valuable materials (battery waste currently commands prices of $1,000 to $5,000 per ton). By 2019 Melin estimated that 59% of eligible end-of-life batteries were being recycled; he thinks it is currently 90% and will in due course reach 99%. We are simply not going to send EV batteries to landfills, any more than we do lead-acid batteries.
 

 In addition to the collection rate, what is important is the recovery rate, the proportion of materials recovered for use, and in particular the proportion of critical minerals. And here the news is very good, with reports by incumbent materials companies and challenger startups like Redwood Materials of recovery rates of as much as 95%. This is very significant. Suppose your battery has a life span of 15 years, and together collection and recovery rates exceed 90%. Then as long as battery energy density improves by 10% every 15 years – and remember it doubled in the past decade – your initial battery minerals will continue providing the same storage services forever. This is what circularity looks like, and it is not taken into account in any of the big energy and mineral demand models – in fact most current EV lifetime carbon assessments do not include recycling at all.
 

 At the same time, the transition will naturally cause demand for resources from the fossil fuel industry to fall away, as explained by independent energy analyst Michael Barnard. The 15% of global energy use in oil and gas extraction and refinement? Gone. Some 40% of blue-water shipping that currently moves oil, gas and coal around the world? Sold for salvage. And 15% of shipping used to move iron ore? Largely made redundant by local green steel manufacture. Hydrogen demand from hydrocracking to make petrol and diesel? Gone. Oil and gas pipelines? Recycled. Even cement and steel demand must eventually start to shrink: we have passed peak child and peak urban migration; we will at some point pass peak population.
 

 Finally, the old adage “the cure for high prices is high prices” will apply to transition minerals every bit as much as it does to other commodities, as we are already seeing in the prices of critical minerals, down by 80% from their highs two years ago despite soaring demand.
 

 Superhero 5: The Primary Energy fallacy
 

 The fifth and final Superhero is an absolute zinger: The entire decarbonization challenge is far smaller than is made out by its critics. The reason lies in the nature of Primary Energy Demand, the metric that dominates public debate about the transition.
 

 The history of Primary Energy dates back to the 1970s, when western countries feared they would be starved of the raw energy needed by their economies, and began to cast around the world for energy resources to make sure they controlled a big enough proportion. The agency created to do this was the International Energy Agency, and their key metric was Primary Energy Demand. You’ll still find it called that in IEA energy reports today.
 

 Despite its name, however, Primary Energy Demand is not really a measure of demand. Let’s use an example. Say you light your hallway with a 75-Watt incandescent lightbulb, illuminated 2,000 hours and consuming 150 kWh per year. Power it with electricity from a coal plant with 35% efficiency, add 10% grid loss, and you create Primary Energy Demand of 476 kWh.
 

 You could, however, deliver the same amount of light with a single 10W LED bulb. Allow the same 10% grid loss, and it uses just 22kWh. Run that LED on wind, solar or hydro power and you have reduced your Primary Energy Demand by 95% and eliminated its CO2 emissions – with no reduction in lighting use.
 

 Take a second example, switching from an internal combustion car to an electric car. Say your VW Golf is managing 40 miles per gallon, a pretty normal figure for real-life usage. This translates to 1kWh/mile or, after accounting for losses in extracting, refining and distributing your fuel, 1.2kWh/mile. The equivalent electric VW ID3, after adjusting for grid and charging losses, uses just 0.3 kWh/mile. By switching, you have achieved a 75% reduction in Primary Energy Demand and opened up a route to eliminate 100% of emissions from driving – with no reduction in mobility.
 

 A third example. Heating the average US home requires 57 million British thermal units per year. If you are heating with gas or oil, after adjusting for 15% upstream losses and 90% furnace efficiency, that comes to 21 MWh per year. Switch to a heat pump with a year-round coefficient of performance of 4, allow 10% for grid losses, and your energy use is reduced to 4.6MWh. Powering a heat pump with clean electricity can reduce your Primary Energy Demand by 78% and eliminate CO2 emissions (and methane leaks) from space heating – with no reduction in comfort.
 

 See the pattern? The transition is not about replacing all of Primary Energy Demand with something cleaner, it just needs to deliver energy services, a vastly smaller quantum, in a clean way.
 

 Each year Lawrence Livermore National Lab produces a wonderful Sankey Diagram, showing how the U.S.’s Primary Energy flows through its energy system. Fully two thirds ends up as “rejected energy”, the majority of it waste heat from fossil-fueled power stations and transportation – in other words from burning stuff: the exact same process as produces CO2 emissions. Only one third ends up as the “Energy Services” actually used by American consumers and businesses.
 

 It is worth remembering this next time Bjorn Lomborg, Vaclav Smil or Alex Epstein point out how renewable energy meets just 5% of our energy needs, based on IEA figures for Primary Energy Demand. But it is energy services, not Primary Energy Demand, that fuels human progress: we want everyone in the world to have light, mobility, heating and so on – and that does not mean everyone needs to have incandescent light bulbs powered by coal-fired power stations, petrol or diesel cars or gas-fired heating. Each time anyone uses the IEA’s Primary Energy Demand data as a metric, intentionally or not, they are inflating the importance of fossil fuels.
 

 To be fair, the US Energy Information Administration, BP’s Statistical Review of World Energy (now curated by the Energy Institute) and a few others apply an adjustment to the output of wind, solar and hydro power upwards to put them on a similar footing as thermal resources, the so-called substitution method. That is better than nothing, but still inadequate: the use of a single “fiddle factor” obscures, for instance, whether renewables are displacing efficient or inefficient alternative sources of power; worse than that, it maintains the primacy in people’s minds of increasing energy supply over efficiently meeting demand.
 

 The Japanese have a word – Mottainai – for the reverence that should be paid to efficiency and the sadness caused by waste. This should be our guide as we build the energy system of the future – a system that extracts every last unit of energy (and exergy, which we met in my piece last year on the electrification of heat) from the resources we use.
 

 We should be identifying the energy services needed to power the global economy and figuring out how to deliver them in the cheapest, cleanest and most reliable way. Whether Primary Energy Demand increases or decreases, irrespective of how it is defined, is simply not a matter of any importance.
 

 And finally
 

 So, there you have it, the five Superheroes of the Transition – the five megatrends that will help get the world to net zero: Exponential growth, system solutions, great power competition, disappearing demand and the primary energy fallacy. While the Five Horsemen are knotty problems of the here-and-now, the Five Superheroes are powerful longer-term trends, which gives them the advantage.
 

 There is in fact a sixth Superhero, or rather a superpower that lies within all of us. I believe society has reached a tipping point beyond which it is unthinkable not to deal with climate change, pollution and environmental degradation.
 

 In the same way that there came a point when discharging untreated sewage into the street, or smoking in public buildings, became unacceptable, it is becoming unacceptable to burn fossil fuels. The generation that regarded it as normal – irreplaceable, even a kind of birth-right – is losing its place at the head of the table and being replaced by a generation that is in no doubt about the need to “stop burning stuff”.
 

 That may not make the technical challenges any easier, but it creates a virtuous circle between the inevitability of the transition, the attraction of talent, the tipping of the balance of risk in favor of net-zero solutions, and progress towards net zero.
 

 That leaves only one question – particularly in the light of this past year’s deeply troubling temperature anomalies – will we get there in time?",General,Irrelevant,Irrelevant,
What can we expect from the third decade of cloud computing? [Q&A],https://betanews.com/2024/03/18/what-can-we-expect-from-the-third-decade-of-cloud-computing-qa/,"Cloud has been a cornerstone of the computing industry for many years. As it enters its third decade in 2024, economic pressures, anti-monopoly moves and more mean things will look different for hyperscale providers.
 

 We spoke to Amol Dalvi, VP of Product of Nerdio, to discuss what we can expect to see over the next 10 years.
 

 BN: There have been recent moves towards a more hybrid model of cloud computing, can we expect this trend to continue?
 

 AD: The trend toward a hybrid cloud model has been gaining momentum, and it will likely continue well into 2024. With the hybrid cloud model, organizations gain access to a combination of on-premise, private, or public cloud services. And IT leaders are finding that products like Azure Stack HCI can help unify the deployment and management of applications and workloads across clouds and manage resources. However, it's worth noting that despite the current trend toward hybrid cloud adoption, there are instances/technologies in which a single cloud strategy makes the most sense. For example, Gartner recently shared in the 2023 DaaS Magic Quadrant that the majority of organizations continue to opt for a single cloud platform for DaaS. This preference is driven by the centralized management capabilities, scalability, and enhanced security offered by a singular cloud platform.
 

 When choosing the right cloud environment, IT teams have also been carefully eyeing costs associated with cloud computing. Amid these cost considerations, organizations are recognizing the need to evaluate and optimize their cloud utilization, taking into account evolving business requirements, cost considerations, and other factors such as data compliance, governance and latency. Of course, there is no one-size-fits-all approach when it comes to cloud adoption. In this landscape, the decision to adopt a hybrid vs. single cloud approach becomes more nuanced, with cost playing a role alongside other critical considerations like geographic considerations and specific service offerings from different providers.
 

 BN: How will the growth of edge computing, AI and IoT device usage affect cloud demand?
 

 AD: Edge computing, AI and IoT device usage have driven up demand for cloud services to ensure that companies have the data storage capabilities and flexibility to handle these tools. For example, despite costs associated with generative AI applications like ChatGPT or Microsoft's Copilot, demand for AI tools is only likely to increase as companies evaluate the generative AI tools available from the major cloud providers and the ways that these tools can become embedded in employees' everyday tasks. In fact, a recent study found that four-fifths of organizations plan to increase their investments in AI by over 50 percent by the middle of 2024. If anything, IoT usage and AI development have called for a greater focus on edge computing as a way to reduce latency and enable more real-time analysis of data, provide intelligent insights, etc. All of this is creating a much higher demand for cloud tools that support AI & IoT and allow for greater productivity across an organization.
 

 BN: How are economic considerations shaping the cloud landscape?
 

 AD: According to Gartner, worldwide end-user spending on public cloud services is forecast to grow 20.4 percent and reach $678.8 billion in 2024. Despite this optimistic outlook, many organizations are continuing to stay vigilant about the current economic landscape, recognizing that budgets are likely to be impacted.
 

 As company leaders evaluate ways to reduce costs, many are considering workforce reductions or consolidating their technology stack to reduce inefficiencies. For companies who have made some of these difficult choices, optimizing their cloud usage may ease any additional challenges. For instance, lowering technical debt -- which normally increases due to sunk costs in laptops, hardware, and other resources when layoffs occur. Ultimately, the cloud will continue to provide efficiency, scalability, flexibility, and cost optimization that organizations can harness during economic hardships.
 

 BN: Can we expect more government regulation and intervention to control hyperscale providers?
 

 AD: The short answer? Yes, I believe conversations regarding the extent of government involvement in regulating cloud hyperscale providers will continue in 2024 and beyond. Cloud providers continue to play a critical role in the global technology infrastructure and concerns about data privacy, security, market dominance, and fair competition have prompted conversations about regulatory measures. However, as advancements in the cloud continue, it is crucial that discussions around regulation and governance evolve as well. All stakeholders in the technology landscape need to be equipped with essential knowledge to effectively navigate this evolving landscape.
 

 BN: Why are good partnerships key to getting the best from cloud investments?
 

 AD: Strong partnerships are crucial to maximizing the benefits of cloud investments for several reasons:
 

 Gaining additional expertise and support: By establishing partnerships with cloud service providers or MSPs, organizations will inherently gain valuable expertise and support as these partners are well-versed in the intricacies of each hyperscale cloud platform and its licensing, architecture, etc. In addition to knowledge, partners can offer guidance, best practices, and assistance in optimizing cloud resources -- giving time back to organizations and their IT teams to focus on the critical tasks at hand.
 

 Access to resources and technologies: Collaborative partnerships grant organizations access to a diverse range of resources, tools, and technologies offered by cloud service providers. This accessibility enables organizations to streamline and optimize their cloud operations by scaling down tech stacks that might be both costly and inadequate for their needs.
 

 Cost efficiency: Fostering partnerships can lead to negotiated pricing, discounts, or custom packages based on the organization's requirements. Although outsourcing may seem like an additional organizational expense, it will inherently leave the organization the ability to optimize the cost of cloud services.
 

 Mitigate risks: Partnerships help mitigate risks associated with cloud adoption and ongoing management. With the support of experienced partners, organizations can navigate challenges, ensure compliance, and implement robust security measures, minimizing potential pitfalls.
 

 Scalability and Flexibility: Partners can assist in scaling resources up or down based on fluctuating demands, ensuring that the organization optimally utilizes cloud services without overcommitting or underutilizing resources.
 

 And the list doesn't stop here. Overall, strong partnerships play a pivotal role in realizing the complete benefits of cloud investments. As businesses prepare for the challenges and opportunities of 2024, it is an opportune moment to reassess both business and technology requirements to ensure the right path toward success.
 

 Image credit: everythingposs/depositphotos.com",General,Relevant,Relevant,
"NASA's old, oversubscribed, and overburdened supercomputers are causing mission delays",https://www.techspot.com/news/102302-nasa-old-oversubscribed-overburdened-supercomputers-causing-mission-delays.html,"What just happened? NASA is the world's foremost space research agency and has access to the latest and greatest technology that most organizations can only dream of. However, an audit conducted by the NASA Office of Inspector General has found that the agency's outdated and overburdened supercomputers are creating massive infrastructure bottlenecks, leading to severe mission delays.
 

 In a scathing report (via The Register), the OIG stated that NASA's high-end computing (HEC) technologies need a complete overhaul if it wants to compete with space research programs of other nations and retain its leadership position. Without massive changes, the agency's supercomputing resources will ""likely constrain future mission priorities and goals.""
 

 Describing the agency's HEC resources as ""oversubscribed and overburdened,"" the report claimed that Mission Directorates are requesting more computing time than existing capacity can provide, often leading to schedule delays.
 

 The situation is so dire that various NASA teams are having to use parts of their allocated budget to purchase their own HEC resources to meet deadlines. As an example, the report highlighted that the Space Launch System team invests about $250,000 annually to purchase and manage their own HEC systems instead of waiting for existing HEC resource availability. According to the OIG, almost all NASA centers are using their own HEC systems except for Goddard Space Flight Center and Stennis Space Center.
 

 The audit also highlighted that NASA is not keeping up with modern supercomputing trends, in part due to organizational and funding constraints. For example, NASA's Advanced Supercomputing facility has just 48 GPUs alongside 18,000 CPUs, while the HEC systems at the NASA Center for Climate Simulation is even more CPU-heavy. The inability to modernize the systems is said to be due to multiple factors such as ""supply chain concerns, modern computing language (coding) requirements, and the scarcity of qualified personnel needed to implement the new technologies.""
 

 As of June 2023, NASA had five supercomputers at the NASA Advanced Supercomputing (NAS) facility in Ames, California, and the NASA Center for Climate Simulation (NCCS) in Goddard, Maryland. The list includes Endeavor (154.8 TFLOPS), Aitken (13.12 PFLOPS), Electra (8.32 PFLOPS), Discover (8.1 PFLOPS), and Pleiades (7.09 PFLOPS).
 

 The report is critical of NASA for lacking ""a comprehensive strategy for when to use HEC assets on the premises versus when to utilize cloud computing options."" The haphazard HEC management is also a clear and present cybersecurity threat, and one that needs to be addressed as soon as possible.
 

 To mitigate the challenges, the OIG is recommending that NASA appoint ""executive leadership to determine the appropriate definition, scope, ownership, organizational placement, and structure for NASA's HEC."" In addition, the report says that the agency should establish ""a tiger team to collaborate and strategize on HEC issues,"" including identifying and plugging mission-critical technology gaps.
 

 The agency is also encouraged to develop a concrete strategy to improve prioritization and allocation of HEC assets, mitigate cybersecurity concerns, and address various other issues that are holding it back from attaining its full potential.",General,Relevant,Relevant,
"Navigating The Intersections Of Technology And Human Interaction In AI, User Experience, And SEO via @sejournal, @SEOGoddess",https://www.searchenginejournal.com/navigating-the-intersections-technology-human-interaction-in-ai-user-experience-seo/508417/,"Gone are the days when AI was merely a distant concept.
 

 Today, AI has already been integrated into our daily lives through various applications and services, transforming how we interact with digital platforms.
 

 A few years ago, AI operated silently behind the scenes, facilitating data processing and optimization for large services.
 

 However, starting in 2023, its presence has become ubiquitous, manifesting in the features and functionalities of the apps and tools we use regularly.
 

 How AI Is Reshaping Our Digital Experience
 

 From iOS 16 Live Text Translation to Gmail Auto-complete, AI has become integral to our digital experiences.
 

 What’s particularly fascinating is the bold strides made in the integration of AI into the very tools we use to create and work.
 

 Consider the emergence of AI-powered image creation tools that generate visuals from textual descriptions or transform sketches into intricate 3D models in real time.
 

 Video creation, once labor-intensive, is now more accessible and creative, thanks to AI-driven algorithms that handle background/object detection and stylization.
 

 My background in design has compelled me to explore how these advancements will reshape our interactions with devices and software.
 

 We are witnessing a shift from the traditional keyboard and mouse interaction towards more natural forms of communication with AI-integrated tools.
 

 This transition from manual inputs to intuitive conversations and descriptions empowers users to become orchestrators of technological capabilities.
 

 Does AI Enhance Or Compromise The Authenticity Of User Interactions?
 

 The ongoing discourse surrounding AI’s role in UX design centers on whether it enhances or compromises the authenticity of user interactions.
 

 Advocates view AI as a transformative force, empowering designers to personalize experiences, predict user behavior, and streamline processes.
 

 Yet, skeptics raise concerns about the potential erosion of genuine human interaction, urging caution against the over-reliance on algorithmic intervention.
 

 The rapid pace of AI innovation necessitates a delicate balance between harnessing its potential and preserving authenticity.
 

 While AI offers unprecedented opportunities, its integration poses ethical dilemmas and challenges UX professionals to navigate complex terrain.
 

 The need for responsible AI adoption underscores the importance of prioritizing user-centric design principles, maintaining transparency, and fostering open dialogue.
 

 As we embrace AI as a tool for innovation, collaboration, and empowerment, we must ensure that it complements – not replaces – human expertise.
 

 Ultimately, the future of UX lies in striking a balanced approach: leveraging AI’s capabilities while preserving the authenticity of user interactions. We must forge a path where technology enhances – rather than compromises – the human experience.
 

 Expanding AI Applications And Their Impact On User Experience
 

 AI is reshaping our interactions with cameras, transcending their traditional role as image-capturing devices.
 

 Equipped with AI algorithms, cameras extend beyond mere photography to recognize QR codes, translate texts, and facilitate visual searches. This evolution transforms the camera into a dynamic input tool, effectively bridging the physical and digital realms.
 

 Consider the Dot-go app, which leverages smartphone cameras to initiate automation processes.
 

 Originally designed to aid visually impaired individuals, this innovative application demonstrates the broader potential of AI-powered cameras to enhance daily experiences for everyone.
 

 From identifying bus routes to calculating calorie intake, AI-powered camera applications offer boundless possibilities for seamless integration into everyday life.
 

 As AI progresses, it will further enrich user experiences through natural interactions such as facial recognition and gesture control. This highlights the importance of striking a balance between automation and human touch.
 

 A Firsthand Look At How AI Empowers Developers
 

 GitHub Copilot exemplifies the fusion of AI and developer collaboration, transcending its role as a mere tool to become a meeting point between developers and AI. (Disclaimer: I worked for GitHub.)
 

 GitHub’s machine learning experts dedicated themselves to enhancing Copilot’s contextual understanding, recognizing effective communication as the linchpin of seamless collaboration.
 

 During my time as GitHub’s SEO manager, I witnessed firsthand the remarkable fusion of AI and developer collaboration during the development phase of Copilot.
 

 More than just a tool, Copilot represents a convergence of minds between developers and their AI pair programming counterparts.
 

 Machine learning experts from GitHub tirelessly researched, developed, and tested new capabilities to enhance Copilot’s contextual understanding.
 

 They recognized that effective communication is essential to pair programming, emphasizing the significance of inferring context to facilitate seamless collaboration.
 

 As a marketing team member, I played a pivotal role in ensuring complete visibility from search to all communications surrounding the project. It was a project that genuinely excited me.
 

 The evolution of Copilot from its inception to its widespread availability represented a paradigm shift in AI-driven coding tools. Leveraging OpenAI’s Codex model, GitHub Copilot emerged as the world’s first generative AI coding tool at scale.
 

 The journey wasn’t just about developing a tool; it aimed to empower developers to focus on meaningful work.
 

 Through meticulous experimentation and iteration, GitHub’s team honed Copilot into a resource that accelerates tasks like code completion and fosters creativity and efficiency.
 

 The collaborative efforts behind Copilot underscored the significance of good user experience and the seamless integration of AI technologies into the developer workflow.
 

 As a result, Copilot continues to revolutionize the way developers work, offering tailored suggestions and insights that amplify productivity and innovation in coding endeavors.
 

 Optimizing The User Journey With Human-AI Collaboration
 

 AI is a pivotal catalyst for personalization, intelligent automation, and predictive analytics in UX design.
 

 By analyzing user data and behavior, AI empowers designers to create bespoke experiences that deeply resonate with individual preferences.
 

 This AI-driven approach fosters engagement, efficiency, and data-driven decision-making, leading to significant improvements in SEO rankings.
 

 Websites prioritizing UX elements tend to rank higher on search engine results pages (SERPs) due to reduced bounce rates, increased dwell time, and enhanced user-interaction metrics.
 

 Thus, integrating AI-driven UX design not only optimizes user satisfaction, but also boosts a website’s visibility and authority in the competitive digital landscape.
 

 However, as with any technological advancement, ethical considerations loom large.
 

 Designers must navigate data privacy, bias, and transparency issues to ensure AI algorithms uphold moral standards and minimize negative impacts on users.
 

 Key Takeaway
 

 AI’s transformative impact on user experience design is undeniable.
 

 By embracing AI’s capabilities and collaborating with skilled experts, designers can harness its potential to deliver exceptional experiences that meet or exceed user expectations in the digital era.
 

 As we continue to innovate and adapt, the synergy between human creativity and AI technology will profoundly shape the future of interaction design.
 

 More resources:
 

 Featured Image: APHITHANA/Shutterstock",AI,Relevant,Relevant,
NASA Selects Winners of the Wildfire Climate Tech Challenge,https://www.nasa.gov/directorates/stmd/stmd-prizes-challenges-crowdsourcing-program/center-of-excellence-for-collaborative-innovation-coeci/coeci-news/nasa-selects-winners-of-the-wildfire-climate-tech-challenge/,"NASA selected its Wildfire Climate Tech Challenge winners, awarding three teams $100,000 for their diverse, innovative approaches to address the escalating effects of wildfires and climate change.
 

 The challenge combined the expertise of Minority Serving Institutions – including Historically Black Colleges and Universities, Tribal Colleges and Universities, Hispanic-serving institutions, and others – with NASA resources to enhance Earth science and technological capabilities to support operational fire management agencies. Participants focused on integrated solutions using NASA Earth observational data to address wildfire and wildland fire risks.
 

 After evaluation by a panel of experts, three winners and three runners-up emerged, each demonstrating exceptional creativity, technical expertise, and a high potential for real-world impact.
 

 Winners:
 

 Team Howard U
 

 • Team members: Lauren Taylor, Amy Quarkume, and Joseph Wilkins, with Howard University
 

 • Concept: Fire Smart Health Guardian + Taylor: Addresses critical gaps in wildfire risk communication and air quality monitoring by integrating NASA data, empowering communities with accurate information to make informed decisions with Generative AI in Natural Language Processing technology, mitigating risk, and protecting their health.
 

 Team HorizonForce
 

 • Team members: Jay Desai with the University of North Carolina Pembroke and Elikem Des-Amekudi, North Carolina A&T State University
 

 • Concept: A Next-Generation Solution for Wildfire Detection, Monitoring, and Elimination: System integrating a network of low-cost Internet of Things sensors, NASA MODIS and VIIRS satellite imagery, and high-payload Unmanned Aerial Vehicles to detect, accurately localize, monitor, and autonomously extinguish emerging wildfires before they escalate.
 

 Team FLARE
 

 • Team members: Andrew Saah and Owen Sordillo with the University of San Francisco
 

 • Concept: Fuel Load Analysis and Risk Estimation (FLARE): A software suite leveraging Terrestrial Laser Scanning methods and conventional Earth observation technologies to revolutionize wildfire risk assessments at sub-meter resolution.
 

 Runners-up:
 

 Team FIRESENCE
 

 • Team members: Neftaly Lara, Jose Marquez, and Shuaiang Rong with the University of Illinois, Chicago
 

 • Concept: Computer Vision-Based Situational Awareness: A software suite using low Earth orbit data and other video and image sources to address pre-, active- and post-fire requirements of firefighting agencies, electric power companies, U.S. Forest Service, and other stakeholders.
 

 Team Sireen
 

 • Team members: Vania Arrendondo, Thi Thuy, and Ishel Zain with Florida International University
 

 • Concept: Smart Forests: An Internet of Things solution utilizing sensors, drones, and advanced computing to enable enhanced forest monitoring and protection through comprehensive data collection, capturing a wide range of environmental indicators for immediate alerts and swift responses to threats like fires or illegal logging.
 

 Team Project FireWatch
 

 • Team members: Riannon Reagan, Sofia Silva, and Huston Scharnagl with San Jose State University
 

 • Concept: Wildfire Drone and Fire Trajectory Software: Wildfire drones and fire trajectory software aiming to improve wildfire management technologies and combat wildfires using machine learning and AI to display fire direction and implement smoke/fire detection capabilities.
 

 “These innovative solutions hold tremendous promise in addressing the complex challenges of wildfires and climate change, and we commend the winners for their dedication and ingenuity,” said Michael Seablom, associate director in the Earth Science Division at NASA Headquarters. “The unique perspectives and diverse talent pool of participants made them invaluable partners in this endeavor. ”
 

 In the competition’s opening round, participants submitted a five-page white paper and a short video describing their proposed idea, highlighting the existing NASA resources or technologies used. From these submissions, NASA chose semi-finalists to present their ideas in a live startup pitch event on March 14 at the agency’s headquarters in Washington.
 

 The three winning teams earned a spot in the NASA MSI Incubator program’s second round where they will create commercial opportunities around their ideas. This multi-week program, running from March through May, offers a blend of hybrid workshops and an in-person finale. Participants will gain insights into forming a startup, product-market fit, raising capital, giving an engaging pitch, and more. The program culminates in a Demo Day during Wildfire Week in June.
 

 The three challenge runners-up will participate in the NASA Innovation (I-Corps) Pilot: Wildfire Technology Management Cohort. The NASA I-Corps Pilot supports participation in the National Science Foundation’s I-Corps Program that trains faculty, students in higher education, post-docs, and other researchers to “get out of their comfort zone” and talk to customers. Cornell University will teach this course, where the cohort will explore their technology’s product-market fit and have the opportunity to attend the Institute for Defense and Government Advancement Wildfire Technology Management Conference in April.
 

 “We believe that these winning solutions have the potential to make a significant difference in wildfire management and resilience efforts,” said Ian Mccubbin, Startup and Venture Capital Engagement manager at NASA’s Jet Propulsion Laboratory in Southern California.
 

 The NASA Tournament Lab – part of the Prizes, Challenges, and Crowdsourcing program within the agency’s Space Technology Mission Directorate – managed the challenge. The NASA Tournament Lab facilitates crowdsourcing to tackle agency science and technology challenges, engaging the global community to seek new ideas and approaches that will ultimately benefit all of humanity. Blue Clarity administered the challenge for NASA.
 

 To learn more about NASA prizes and challenges opportunities, visit:
 

 www.nasa.gov/get-involved",General,Relevant,Irrelevant,
OpenAI's video generator Sora might allow nudity. Experts are worried,https://qz.com/openai-sora-ai-video-generator-nudity-deepfake-porn-1851339498,"Seeing a video playback of a cool dream or idea you have might become a reality soon. OpenAI’s text-to-video AI generator, Sora, is going to be publicly released “definitely this year,” Mira Murati, the company’s chief technology officer, told The Wall Street Journal. The news outlet was provided with examples of Sora’s generations of a mermaid with a smartphone and a bull in a china shop.
 

 But when asked about nudity on Sora, Murati said she wasn’t sure if it would be allowed in video generations, adding that artists might use nude generations in creative settings. Murati said OpenAI is “working with artists and creators from different fields to figure out exactly what’s useful,” along with “what level of flexibility” Sora should have.
 

 Advertisement
 

 But despite efforts from the startups and companies working on the models to implement guardrails on the kind of content that can be generated, sensitive material like deepfake nudes and deepfake pornography are churned out regularly by major generative AI tools. And experts say OpenAI and other tech companies working on similar technology, as well as the U.S. government, should be more proactive about regulating tools like Sora before they’re widely released.
 

 Advertisement
 

 Getting on guardrails
 

 In a February poll of U.S. voters by the AI Policy Institute (AIPI), 77% of respondents said that when it comes to AI video generators like Sora, including guardrails and safeguards to prevent misuse is more important than making the models widely available. More than two-thirds of respondents said the developer of an AI model should be held legally responsible for any illegal activity by the model, like generating fake videos for slander or revenge porn.
 

 Advertisement
 

 “That really points to how the public is taking this tech seriously,” said Daniel Colson, the founder and executive director of AIPI. “They think it’s powerful. They’ve seen the way that technology companies deploy these models and algorithms and technologies, and it leads to completely society-transforming results.”
 

 But Colson said the public also “doesn’t trust the tech companies to do that in a responsible manner.”
 

 Advertisement
 

 “OpenAI has a challenging decision to make around this,” he said, “because for better or worse, the reality is that probably 90% of the demand for AI-generated video will be for pornography, and that creates an unpleasant dynamic where, if centralized companies creating these models aren’t providing that service, that creates an extremely strong incentive for the gray market to provide that service.”
 

 Colson said this has already happened with open-source AI image models where there isn’t much content restriction or oversight.
 

 Advertisement
 

 Sora is currently being tested by red teamers, or “domain experts in areas like misinformation, hateful content, and bias,” OpenAI has said as it prepares to make the model available. The company also said it’s working on tools to “detect misleading content” including Sora-generated videos. OpenAI did not respond to a request for comment for this story.
 

 After AI-generated pornographic images of Taylor Swift flooded social media in January, an AIPI poll found that 84% of respondents supported legislation to make non-consensual deepfake porn illegal. Meanwhile, 86% of respondents supported legislation to require companies developing AI models to prevent them from being used to create deepfake porn. More than 90% of respondents said they believed people who use AI models to create deepfake porn should be held accountable under the law, while 87% of respondents said they believe companies developing the models should be held legally liable. There are currently no U.S. laws or regulations around this. (In the European Union, the newly-passed Artificial Intelligence Act, which will assess and regulate AI software for risk, has yet to be officially enacted.)
 

 Advertisement
 

 “The [U.S.] government hasn’t really taken any notable step in the last 25 years — since the dawn of the internet — to substantially regulate these entities, and that’s notable, given the degree to which more and more of American society is truly governed by these non-democratically elected entities,” Colson said.
 

 Video generators like Sora could also be used by cyber criminals to create deepfakes of executives, actors, and politicians in compromising situations to exert influence or to ask for a ransom. In February, the Federal Communications Commission banned AI-generated voices in robocalls after multiple incidents, including a fake call that circulated in January with an AI-generated of President Joe Biden encouraging voters in New Hampshire to stay home instead of voting in the state’s primary election. And during his unsuccessful campaign for the Republican presidential nomination, Florida Gov. Ron DeSantis released an AI-generated video in June of former President Donald Trump hugging former White House medical adviser Dr. Anthony Fauci — without disclosing it wasn’t real.
 

 Advertisement
 

 But mandating guardrails like user verification, content tagging, risk rating, and putting restrictions on how and where AI generated content can be exported could help circumvent cybercrime.
 

 “We need to move from a reactive posture to a proactive posture,” Jason Hogg, an executive-in-residence at Great Hill Partners and a former global chief executive of the cybersecurity firm Aon Cyber, said of U.S. regulation on AI models. (Great Hill Partners is an investor in Quartz’s parent company G/O Media.)
 

 Advertisement
 

 Hogg said there need to be regulations and penalties in place to deal with “a tsunami of cybercrime that is heading towards our shore.”",AI,Relevant,Relevant,
5 Key Enterprise SEO And AI Trends For 2024,https://www.searchenginejournal.com/key-enterprise-seo-trends/504001/,"SEO has undergone many transitions and disruptions in a short time.
 

 Enterprise SEO has been at the center of some fundamental transformations over the past year.
 

 Adapting to the ever-changing needs and demands of consumers, integrating AI into search engines, and the influx of new generative AI SEO and content tools have forced organizations to adapt and evolve their marketing strategies.
 

 In this article, I will delve deeper into five key enterprise SEO trends for 2024 with tips to help you keep pace with change and prepare for future success accordingly.
 

 What Is Enterprise SEO?
 

 Enterprise SEO is typically associated with implementing SEO strategies within large-scale organizations.
 

 It predominantly applies to sizable brands with multiple departments and complex infrastructures. This can include large – and multiple – websites that offer a diverse array of products and services.
 

 One of the key differences between standard SEO and enterprise SEO is the need for the workflow management of stakeholders, strategic planning, and ensuring strategies align with an organization’s broader – and, in many cases, multiple – objectives.
 

 How Enterprise SEO Has Changed
 

 In 2024, enterprise SEO trends will be shaped by technological advancements, changing user behaviors, and the evolving search landscape.
 

 It’s no secret that the way search engines utilize generative AI to create new user experiences is changing how enterprises look at, and understand, what is happening in the search engine results pages (SERPs).
 

 This includes shifting from pure keyword research leveraging data-led insights to understanding conversational intent that triggers search results.
 

 Whether you are searching via traditional results or in Google SGE labs, results now contain more sources and multiple content formats. As a result, enterprises must become more innovative and proactive in their SEO and content marketing approaches.
 

 The great thing to see is that the role of SEO is growing and expanding in this new AI era.
 

 5 Essential Enterprise SEO Trends To Watch In 2024
 

 1. Understanding Market Shift And Ever-Evolving Consumer Preferences
 

 SEO is such a dynamic and intense discipline that, for the majority, it can be a ‘heads down,’ laser-focused, task-by-task approach.
 

 However, especially when we look at enterprise SEO and large-scale projects, it is essential to take a step back and ensure you have a pulse on what is happening at a macro level.
 

 For enterprise SEO experts, it is crucial to stay on top of the latest trends and developments in consumer behavior, especially during economic shifts. These shifts can significantly impact how businesses align their more extensive SEO and content strategies to match business objectives.
 

 For example, the pandemic saw rapid shifts in shopping preferences for products related to staying at home.
 

 In any era-changing economic conditions, the importance of SEO reaches an all-time high due to its cost efficiencies and compounding returns, such as branding and data-driven insights into products and all major digital strategies such as paid search, email, and social.
 

 Market conditions can force organizations to prioritize specific competitor strategies.
 

 Search algorithm updates may prioritize credibility and authoritative sources, which means content should be optimized accordingly. I will share more on this later in this article.
 

 Economic changes can also accelerate the use of new technologies, requiring businesses to be flexible and adaptable, and exercise caution in adoption.
 

 Enterprise SEO pros must liaise with key management stakeholders monthly to ensure their strategies align with key business priorities to avoid going down unproductive pathways.
 

 You must use data analytics effectively to understand target audiences and what is changing.
 

 As enterprise SEO is a multi-stakeholder discipline, insights must be fed into organizational strategies to create more holistic, not just channel-agnostic, individualized experiences.
 

 These can range from lead magnets that take the form of tailored marketing communications to customized product content and campaigns.
 

 2. Using Generative AI For SEO And Content: Managing Risk Vs. Reward
 

 According to Bloomberg Intelligence, by 2032, generative AI will be worth $1.3 trillion. Additionally, Gartner research shows that SEO and content marketing are two of the highest areas of increased investment.
 

 Numbers vary depending on the source, but if you drill down, well over 2,000 generative content AI tools are flooding the market. No doubt you hear about a new one in the news every week!
 

 The challenge for enterprise SEO pros who want to boost content productivity and performance lies in balancing the risk versus reward of using these tools.
 

 Risk: Some of the content generative tools focus on velocity over quality. This is challenging for the consumer and search engines and limits the chance of your brand being discovered in a sea of nonsense.
 

 This is because they are based on single-source, low-quality data sources that are not trained to understand your audience’s needs and wants. They have no understanding of what works in content & SEO.
 

 For brands, this means the content can get buried below irrelevant, low-quality spam-like articles. Over time, I expect Google to solve this.
 

 In addition, as a result, we are seeing more and more government and organization institutions building ethical AI and content creation guidelines and standards related to data use, regulation, and governance.
 

 Always remember the risks.
 

 Generative AI has severe limitations and liabilities , including the tendency to “hallucinate” by fabricating information when it doesn’t have an answer.
 

 , including the tendency to “hallucinate” by fabricating information when it doesn’t have an answer. It can state misinformation so convincingly a reader new to the topic may believe it to be fact.
 

 a reader new to the topic may believe it to be fact. It lacks creativity and produces output that tends to be generic and formulaic.
 

 and produces output that tends to be generic and formulaic. The content produced is only as good as the input (prompts) and oversight (editorial process) –garbage in, garbage out.
 

 Reward: On the flip side, if correctly used, generative AI tools can help improve content productivity and scale content for SEO campaigns.
 

 Help give valuable insights and inspiration : The cornerstone of successful campaign development is the strategic generation of ideas. Marketers can create compelling content by using generative AI to uncover popular search terms, monitor social media trends, and discover unique angles and ideas.
 

 : The cornerstone of successful campaign development is the strategic generation of ideas. Marketers can create compelling content by using generative AI to uncover popular search terms, monitor social media trends, and discover unique angles and ideas. Accelerate content production creation efficiency : Generative AI can also help segment audiences based on demographics, preferences, and behaviors, enabling you to tailor personalization strategies and unique experiences. It can also assist in timely (short-from) email marketing and crafting specific messages for each key target audience.
 

 : Generative AI can also help segment audiences based on demographics, preferences, and behaviors, enabling you to tailor personalization strategies and unique experiences. It can also assist in timely (short-from) email marketing and crafting specific messages for each key target audience. Scale productivity and performance: For enterprise SEO pros who use platforms rather than multiple tools with disparate data sources, AI-generated content can be created in one platform that also helps you streamline workflows. Due to built-in privacy considerations and guardrails, platform-specific generative AI tools are likely safer to use. They can create content based on your existing assets and utilize high-fidelity and secure data based on search and content patterns. These are helpful for efficient content discovery and distribution, allowing you to focus on strategy and creation.
 

 Recommendations from all-in-one platforms also act as a content and SEO best practice assistant.
 

 3. Preparing For Search Generative Experiences: Your Content And Your Brand
 

 The transition to Search Generative Experiences (SGE) marks the most substantial transformation in the history of search engines – and a seismic shift that will impact all industries, affecting every company and marketer globally.
 

 SGE represents a paradigm shift in SEO, moving beyond traditional keyword-based tactics to embrace the power of generative AI.
 

 As AI emerges and becomes almost a “mediator” between a company’s content and its users, one search can produce results that would have previously taken five separate searches.
 

 Take retail shopping as an instance: AI will start to recommend a complete shopping experience that gives consumers an experience that contains many channels and sources and multiple forms of media.
 

 For consumers, this promises deeper and more interactive experiences, leading to increased engagement and time spent on Google.
 

 For brands, it means higher value clicks once a consumer is ready to visit your website.
 

 I have been monitoring this (at BrightEdge) for a long time. I see experiments in critical areas that you should keep an eye on! For example:
 

 Testing of over 22 new content formats in SGE results.
 

 There are many warnings in the healthcare and YMVL industries, as Google is exercising caution.
 

 New visual content formats are used in industries such as e-commerce.
 

 More reviews are being added to results in areas like entertainment.
 

 There is a big focus on places (local) being integrated into results.
 

 To help SEJ readers and the whole community, you can view for free (ungated) the data behind all these findings and a step-by-step guide to understanding this Ultimate Guide to SGE.
 

 Note: This is still in Google Labs and has not been rolled yet. However, from the above, I firmly predict this is a matter of when, where, and how it will proceed.
 

 4. Understanding And Adapting To New Search Behaviours: Data And Conversational Intent
 

 Utilizing data to grasp user behavior and the underlying intent in conversations will be crucial for SEO success in both traditional and AI-driven search results.
 

 Search is becoming conversational, and marketers must focus on user intent, advancing their understanding of their audience from simple keyword optimization to grasping conversational intent and extended phrases.
 

 For users, this translates into more captivating and immersive experiences, leading to increased time spent on Google. This optimizes their search, guiding them swiftly to the most pertinent websites that cater to their unique needs.
 

 For marketers, navigating your search presence becomes more intricate yet more fruitful. Anticipate reduced but higher-quality web traffic. Identifying key searches that activate various types of results is essential.
 

 Clicks will carry greater monetary value due to enhanced conversion rates. This is because consumers are more ready to act after being informed and influenced by prior interactions and data from Google.
 

 Marketers need to guarantee that their content strategy not only answers the specific query but also considers the broader context in which the query is made. This will help ensure targeted and effective engagement with users.
 

 However, the core fundamentals of technical and website SEO remain the same. They will become more critical as marketers shift to optimizing their sites for higher-value traffic and clicks.
 

 Ensure your site is fast and responsive, it is structured, and the content is optimized for human readers. It should be structured to answer their questions in the most engaging and user-friendly way.
 

 Ensure your content assets are primed for conversion with clear CTAs.
 

 Focusing on contextual signals will be vital for content marketers who want to maximize performance.
 

 For example, schema markup, E-E-A-T, and HCU (even though not regarded as ranking factors) are vital, so search engines and users send signals so they can understand the context behind your site and content.
 

 Leverage data to decode user behavior and the intent behind conversations, using this insight as a catalyst for generative AI outcomes.
 

 Develop and refine various content types, such as videos and images, to enhance engagement.
 

 Coordinate marketing efforts across paid media, social platforms, and public relations to create a unified content campaign strategy.
 

 Concentrate on tracking metrics like traffic and converting high-quality down-funnel traffic as consumers spend more time on Google before making informed decisions and visiting your website.
 

 And, as I know, you are now thinking. Yes, SGE could mean slightly less but more qualified traffic.
 

 5. Managing Omnichannel Marketing: Managing SEO And Multiple Marketing Disinclines
 

 SEO has long shifted from being a siloed channel, but enterprises must make changes now as consumers and search engine demands drive the need for even closer collaboration.
 

 Given that the SERPs and AI-generated SGE results encompass a variety of media types and formats – including social media, reviews, and news sources – content marketers will need to get closer than ever to their SEO, digital branding, design, social media, and PR teams.
 

 Consumers are no longer consuming media in silos, and that means marketers cannot operate SEO and digital marketing in silos. More than managing PPC and SEO campaigns with a bit of social media will be required in 2024.
 

 This is especially true as AI-powered results contain multiple formats and sources. Whether you are a big brand or not, whoever provides the best experience will win in 2024 – so expect some curveballs from your competition.
 

 This means the relationships between people, processes, and technology must change.
 

 Make sure you are aligning your teams and managing workflows across:
 

 Design – Images and video.
 

 – Images and video. Branding and PR – Messaging and company reputation.
 

 – Messaging and company reputation. Content – From text to design to social.
 

 – From text to design to social. SEO – PPC and Website teams.
 

 – PPC and Website teams. Customer Service teams – For reviews.
 

 – For reviews. Sales teams for advice on down-funnel CTAs on your site.
 

 For enterprise SEO pros, platforms are the only way you can do this.
 

 Key Takeaways For Enterprise SEO Success In 2024
 

 SEO today is going to be different than SEO tomorrow. SEO tomorrow will be different than the search in March.
 

 Change is the core constant we all share in this industry. Time has shown us that those who keep up with trends and adapt quickly survive and thrive.
 

 As SEO advances alongside AI, keep a core focus on monitoring consumer behavior.
 

 Never forget many of the core principles of SEO still apply, but be ready to help your organization become more agile so your success in enterprise SEO and AI is guaranteed.
 

 In 2024, regardless of the search source, once a consumer clicks, brands that give them the best experience win.
 

 More resources:
 

 Featured Image: Sutthiphong Chandaeng/Shutterstock",AI,Relevant,Relevant,
Feds Probe Ford’s BlueCruise Driver-Assistance System After Fatal Mustang Mach-E Crash,https://jalopnik.com/feds-probe-ford-s-bluecruise-driver-assistance-system-a-1851343883,"Another week, another investigation into a crash involving an advanced driver assistance feature. This time, instead of yet another probe into Tesla’s Autopilot software, it’s Ford’s BlueCruise at the center of the investigation following a deadly Mach-E crash in Texas.
 

 

 

 The Mustang Mach-E Rally Revealed CC Share Subtitles Off
 

 English view video The Mustang Mach-E Rally Revealed
 

 The U.S. National Transportation Safety Board has opened an investigation into a crash in San Antonio, Texas, that involved a Ford Mustang Mach-E equipped with BlueCruise, reports Reuters. The crash occurred on Interstate Highway 10 and saw a Mustang Mach-E crash with a Honda CR-V that was stationary in a traffic lane, explains the site.
 

 Advertisement
 

 San Antonio police report that the Ford had “partial automation” engaged at the time of the crash, which resulted in the death of the driver of the CR-V. As Reuters explains:
 

 The police report said the driver of the Honda CR-V, 56-year-old Jeffrey Allen Johnson of Austin, was taken to a hospital and later pronounced dead. Ford offers BlueCruise, an advanced hands-free driving system that operates on 97% of U.S. and Canadian highways with no intersections or traffic signals. The NTSB said it was investigating the crash “due to its continued interest in advanced driver assistance systems and how vehicle operators interact with these technologies.”
 

 Advertisement
 

 To uncover the role BlueCruise played in the fatal crash, investigators from the NTSB will “examine the wreckage and collect information about the accident site and sequence of events leading to the collision,” reports Reuters. In a statement, a Ford Spokesperson told Jalopnik:
 

 We were recently made aware of this incident and extend our deepest sympathies to those involved. The complete facts of this event are not yet clear. Ford reported this incident to NHTSA as soon as we were made aware, and we are actively researching all available information. Safety is a top priority for all of us at Ford, and we will collaborate fully with any resulting investigation.
 

 Advertisement
 

 As a nationwide policy, automakers are required to inform the National Highway Traffic Safety Administration of any crashes involving their advanced driver-assistance features.",AI,Relevant,Irrelevant,
Euro 2024 kits revealed,https://www.skysports.com/football/news/11095/13094335/euro-2024-kits-revealed-home-and-away-shirts-for-england-wales-scotland-germany-spain-belgium-and-more,"The countdown to Euro 2024 is on with less than 100 days remaining until the tournament kicks off in Germany, and a new array of kits has started to drop.
 

 Twenty-four teams will take to the field in June and July, most sporting box-fresh new kits ahead of the tournament. With time ticking away and the March international break almost upon us, some have already been given a run-out, while others are getting their first look now.
 

 Here are the latest looks ahead of this summer's tournament on the continent...
 

 England Euro 2024 kit
 

 Home
 

 Twitter Twitter , which may be using cookies and other technologies. To show you this content, we need your permission to use cookies. You can use the buttons below to amend your preferences to enable Twitter cookies or to allow those cookies just once. You can change your settings at any time via the This content is provided by, which may be using cookies and other technologies. To show you this content, we need your permission to use cookies. You can use the buttons below to amend your preferences to enablecookies or to allow those cookies just once. You can change your settings at any time via the Privacy Options Unfortunately we have been unable to verify if you have consented to Twitter cookies. To view this content you can use the button below to allow Twitter cookies for this session only. Enable Cookies Allow Cookies Once
 

 Away
 

 Twitter Twitter , which may be using cookies and other technologies. To show you this content, we need your permission to use cookies. You can use the buttons below to amend your preferences to enable Twitter cookies or to allow those cookies just once. You can change your settings at any time via the This content is provided by, which may be using cookies and other technologies. To show you this content, we need your permission to use cookies. You can use the buttons below to amend your preferences to enablecookies or to allow those cookies just once. You can change your settings at any time via the Privacy Options Unfortunately we have been unable to verify if you have consented to Twitter cookies. To view this content you can use the button below to allow Twitter cookies for this session only. Enable Cookies Allow Cookies Once
 

 Perhaps the most eye-catching part of England's new kits is a purple away shirt, which Nike says mixes the red and blue of other away kits from previous years. Purple trim will also feature on the classic white home shirt, which will first be worn by Gareth Southgate's Three Lions later this month.
 

 Home
 

 Away
 

 Makers Adidas say they've gone for a look celebrating Belgium's history of art and design, including cartoonist Herge, whose Tintin character they hope will inspire the nation to glory this summer.
 

 Home
 

 Away
 

 Germany's away kit has been inspired by the metaverse for the upcoming Euros campaign, which Adidas say looks to connect with the next generation of the country's fans. Now they just have to hope they won't be limited to playing football online before the summer's out.
 

 Home
 

 Away
 

 The letter I runs through the Italy away shirt, as would make sense, with nods to the green, white and red of the country's flag running down both sides in the shape of the letter.
 

 ""L’ITALIA CHIAMO"" is emblazoned on the back of the collar, the name of the Italian national anthem.
 

 Scotland Euro 2024 kit
 

 Home
 

 The Tartan Army will now be wearing the patterned design on their top and bottom halves with Scotland's new home kit drawing inspiration from the famous layout.
 

 Away
 

 Home
 

 Both Spain kits include some recreation of a carnation, the country's national flower. Lovely - if not the intimidating sight for opponents.
 

 Away
 

 Hungary Euro 2024 kit
 

 Home
 

 Away
 

 Euro 2024 fixtures, dates and groups
 

 The Euro 2024 groups have been drawn, with England, Scotland and Wales - if they come through the play-offs - discovering their fates.
 

 The tournament kicks off on Friday June 14 when hosts Germany face Scotland in Munich.
 

 See the full Euro 2024 schedule here.",General,Relevant,Irrelevant,
Qualcomm introduces Snapdragon 8s Gen 3 with on-device generative AI capabilities,https://indianexpress.com/article/technology/mobile-tabs/qualcomm-snapdragon-8s-gen-3-launch-features-performance-9220301/,"Qualcomm on Monday announced its latest and the first “8s” series flagship mobile platform — the Snapdragon 8s Gen 3, intending to enable on-device generative AI capabilities on more Android smartphones. Major Android OEMs like Honor, iQOO, realme, Redmi, and Xiaomi are confirmed to launch Snapdragon 8s Gen 3-powered smartphones in the coming weeks.
 

 The key highlights of the Snapdragon 8s Gen 3 include the support of major large language models such as Baichuan-7B, Llama 2, and Google’s Gemini Nano, and the processor is capable of handling on-device AI models with up to 10 billion parameters.
 

 “With capabilities including on-device generative AI and advanced photography features, Snapdragon 8s Gen 3 is designed to enhance user experiences, fostering creativity and productivity in their daily lives,” said Chris Patrick, senior vice president and general manager of mobile handsets, Qualcomm Technologies, Inc.
 

 Advertisement
 

 The on-device AI engine can handle tasks like generative-AI-powered virtual assistant, image generation, and it also has multi-modal gen-AI model support. Smartphones powered by the Snapdragon 8s Gen 3 processor can also offer experiences like on-device photo expansion, and the AI also powers the camera capabilities, powered by the 18-bit triple cognitive ISP.
 

 Qualcomm Snapdragon 8s Gen 3 technical specifications
 

 Snapdragon 8s Gen 3 highlight features (Image credit: Qualcomm) Snapdragon 8s Gen 3 highlight features (Image credit: Qualcomm)
 

 The Qualcomm Snapdragon 8s Gen 3 is an octa-core processor with one prime core clocked at 3GHz, four performance cores with a 2.8GHz clock speed, and three efficiency cores with up to 2GHz clock speed. The processor is fabbed using TSMC’s 4nm process and it also comes with the latest Adreno GPU.
 

 The key differences between the Snapdragon 8 Gen 3 and the Snapdragon 8s Gen 3 can be limited to the CPU clock speed, networking capabilities, graphics, and AI capabilities. Qualcomm also confirmed that the graphics performance of the Snapdragon 8s Gen 3 sits between the Snapdragon 8 Gen 2 and the Snapdragon 8 Gen 3. While the Snapdragon 8s Gen 3 supports real-time hardware-accelerated ray tracing, it does not support Global illumination like the Snapdragon 8 Gen 3.
 

 The Snapdragon 8s Gen 3 comes with the Snapdragon X70 5G Modem-RF System with up to 5Gbps downlink speed. The chip does support Wi-Fi 7 and Bluetooth 5.4. The processor can handle a display with up to 4K resolution at 60fps or a 2K resolution display with up to 144Hz.
 

 Advertisement
 

 It also supports up to 200 MP cameras; however, there is no 8K video recording capability, and it offers up to 4K 60fps HDR video recording. There is fast UFS 4.0 support along with up to 24 GB of LP-DDR5x RAM with up to 4200 MHz.",AI,Relevant,Relevant,
Harnessing the power of privacy-enhancing tech for safer AI adoption,https://www.helpnetsecurity.com/2024/03/18/privacy-enhancing-technologies-pets-video/,"A consensus on regulatory AI frameworks seems distant. Yet, the imperative for secure and responsible AI deployment cannot be overstated. How can leaders proactively address AI adoption challenges while waiting for regulatory clarity?
 

 In this Help Net Security video, Dr. Ellison Anne Williams, CEO of Enveil, discusses global AI adoption and the imperative role of Privacy Enhancing Technologies (PETs).",Trust Technologies,Relevant,Relevant,
Bang & Olufsen’s wireless hub turns even their 30-year-old speakers into smart Bluetooth devices,https://www.yankodesign.com/2024/03/17/bang-olufsens-wireless-hub-turns-even-their-30-year-old-speakers-into-smart-bluetooth-devices/,"When companies mention the term “backward compatibility”, it seldom means revamping their products from 30 years ago… but Bang & Olufsen’s managed to pull off the unthinkable. You see, people who own B&O sound-systems do so because they’re passionate about audio quality – and if there’s one thing all audiophiles will agree to, it’s that analog sound systems from the years gone by are still the gold-standard in sound quality. The only problem is that they aren’t designed to be wireless. Not that any audiophile would dream about listening to Spotify on their state-of-the-art sound system, but there’s admittedly a certain convenience to being able to play any song directly from your phone on wireless speakers. Announced just this month, Bang & Olufsen’s latest device lets you do just that. The Beoconnect Core, priced at £999 ($1150 USD), is an intermediary wireless hub that turns all of B&O’s older speakers wireless, connecting the rich, auditory legacy of Bang & Olufsen with the convenience of today’s streaming culture.
 

 Designer: Bang & Olufsen
 

 Not to be confused with the BeoSound Core from 5 years ago, the Beoconnect Core is B&O’s latest accessory designed to be infinitely backward compatible with the company’s entire speaker catalog. The Beoconnect Core transforms legacy speakers, some dating back more than 30 years, into modern wireless systems capable of streaming music from any app, connecting to turntables, or even enhancing TV audio for a cinematic experience. This device is a celebration of the brand’s heritage, ensuring that the beloved sound systems can continue to create memorable moments in the digital age.
 

 “Our aim is to build product icons that can last a lifetime, and Beoconnect Core is an important addition to our product offering, that enables us to deliver on this longevity promise. Beoconnect Core connects our past with our future and comes with our replaceable Mozart streaming module that can easily be upgraded to the newest technology”, says Michael Henriksson, Vice President of Product Marketing at Bang & Olufsen. “This means that the products that our customers love can be used for years to come and continue to provide memorable moments”.
 

 The Beoconnect Core’s understated design complements any room’s aesthetic. Its gently curved, pearl-blasted aluminum chassis is as stylish as it is functional, efficiently dissipating heat. The non-conductive cover ensures clear and uninterrupted antenna reception. For a truly integrated experience, the Core can be seamlessly docked into a BeoSound Shape tile using a custom-designed bracket. The Core’s design prioritizes easy upgradeability too. Its functionality is future-proofed by the replaceable Mozart streaming module, ensuring your system stays compatible with the latest streaming technologies. This commitment to longevity extends to the Cradle-to-Cradle design principles used in the Core’s construction, minimizing environmental impact and maximizing serviceability.
 

 As far as compatibility goes, the Beoconnect Core offers a variety of options to integrate your B&O speakers seamlessly into your existing setup. Powerlink and USB connections ensure optimal performance with Beolab 50 and Beolab 90 speakers, while a line-in port allows for the connection of turntables and other audio sources. But the Core’s capabilities extend beyond pure audio. It features an HDMI eARC connection, enabling you to connect your B&O speakers to any TV and experience the immersive power of Bang & Olufsen sound with your favorite movies and shows. So if you’ve got yourself some B&O speakers from more than a decade ago (when wireless connectivity wasn’t really much of a priority for high-end audio companies), the $1150 Core is a worthwhile investment in future-proofing your sound system to be compatible with latest streaming apps while still retaining its ability to default back to the glorious analog playback whenever you want.",Communications Technologies,Relevant,Irrelevant,
Wireless charger concepts imagine a world free from power cables,https://www.yankodesign.com/2024/03/18/wireless-charger-concepts-imagine-a-world-free-from-power-cables/,"Although wireless charging has been around for years, it was only until Apple finally joined the fray that the technology really became popular. Of course, it was Apple’s MagSafe spin on wireless charging that really caught on, but it still sparked interest in a future where wires and cables are a thing of the past. We’re still a long way from that future considering how wireless charging works today, but that’s not to say that there is no progress to improve the situation. These wireless charging product designs, for example, are based on such ongoing development and prepare us for a world where desks can be completely devoid of cables, especially those for charging your multitude of devices.
 

 Designer: Sprout Studios
 

 As convenient as wireless charging might be, especially magnetic wireless charging, the requirement to have the device and the charger touching is still quite restricting. Not only that, you still have to make sure that the charging coils are aligned properly, which is what made it necessary for Apple to implement MagSafe in this way. But what if you could get rid of that restriction? Then every surface or anything on your desk can become a wireless charger.
 

 That’s exactly what these designs are proposing, based on technology being developed by startup DeepCharge. Even a laptop mat, for example, can become a wireless charger that can accommodate phones, earbuds, and other devices as well. This Laptop Pad also has extra features like an antimicrobial frantic top and LED lighting to indicate charging status. You don’t have to ensure that devices are in the right area. Simply place them on the mat and watch the LED indicator light up. Another design involves a charging pad that also acts as a landing pad for drones, though that requires attaching some feet to the quadcopter.
 

 A more ambitious design, however, is based on “transmutation” and “energy hopping” technologies that are still being developed. In a nutshell, it could turn any surface, like a desk or a shelf, into a wireless charging area. Then you have small wireless charging stations that can transfer power from a central hub and distribute it even in areas out of reach of your desk. Pretty much like how mesh routers work today, except spreading electrical power instead of data.
 

 Although the concepts in this collection still look like your conventional technical products, the technology it relies on opens the door to even more flexible designs. Anything on your desk or shelf, be it an accessory or even a piece of decoration, can become one of those satellite charging hubs. With wireless computer peripherals and data connections, such a design could lead to cleaner and tidier workspaces, unless of course, you start cluttering your table with even more devices to charge.",General,Relevant,Relevant,
The Role of Quantum Computing in Data Science,https://www.dataversity.net/the-role-of-quantum-computing-in-data-science/,"Read more about author Nahla Davies.
 

 Quantum computing is on the cusp of turning the data science world upside down, offering a level of processing power we’ve only dreamed of until now.
 

 This new frontier has an incredible potential to reshape the way we approach data analysis, predictive modeling, and solving the kind of complex problems that have always been a tough nut to crack.
 

 Drawing on the latest trends and developments in quantum computing, this article aims to shed light on the seismic shifts anticipated within the current data science landscape, propelled by quantum innovation.
 

 We’ll be looking at what this shift means for the field, including both the big opportunities and the challenges data scientists will face as they step into the quantum age – plus, we’re going to try to wrap our heads around just how big a deal this change really is.
 

 The Basics of Quantum Computing
 

 At the heart of quantum computing lies the principle of quantum mechanics, which allows quantum bits (qubits) to exist in multiple states simultaneously, unlike traditional bits that are either 0 or 1.
 

 This capability, known as superposition, along with entanglement – where the state of one qubit can depend on the state of another, no matter the distance between them – enables quantum computers to process vast amounts of data at unprecedented speeds.
 

 These fundamental principles set the stage for quantum computing’s potential to revolutionize data science by performing complex calculations that are impractical for classical computers.
 

 Adding to this, the concept of quantum supremacy, where a quantum computer can perform a calculation that is practically impossible for a classical computer, further illustrates the transformative potential of quantum computing.
 

 Quantum Advancements in Data Analysis
 

 Among the many advancements quantum computing promises to bring, data analysis stands to benefit immensely from quantum computing. Traditional data processing can be time-consuming and computationally intensive, especially when dealing with large datasets or complex algorithms like those used in machine learning.
 

 Quantum algorithms, however, can analyze data in unique ways that vastly outpace current methods. For example, quantum algorithms for database searching can theoretically find an item within a database quadratically faster than classical algorithms. This speed could dramatically reduce the time needed for data preprocessing, analysis, and insight generation, making real-time data analysis more feasible across various industries, from finance to healthcare.
 

 Furthermore, the introduction of quantum computing into data analysis could revolutionize the field of artificial intelligence. The computational speed and efficiency of quantum processors allow for the training of more complex AI models in a fraction of the time required by conventional computers.
 

 Predictive Modeling and Its Impact on Quantum Computing
 

 Predictive modeling is another area where quantum computing is poised to make a significant impact. The ability of quantum computers to handle complex, multidimensional datasets with high degrees of interconnectivity could lead to more accurate and sophisticated predictive models.
 

 Quantum-enhanced machine learning algorithms can process information in a fundamentally different way, allowing for the development of models that could, for example, more accurately predict stock market trends, weather patterns, or disease outbreaks by analyzing patterns and correlations beyond the reach of classical computing.
 

 This quantum advantage extends to the realm of optimization problems in predictive modeling, where finding the best solution among many possible options is often computationally prohibitive.
 

 Quantum algorithms, particularly quantum annealing, offer a path to solving such optimization problems more efficiently, enabling predictive models to consider a broader range of variables and scenarios. This capability could significantly enhance decision-making processes in fields such as logistics, finance, and public health by providing more nuanced and dynamic predictive insights.
 

 Tackling Complex Problems
 

 Quantum computing offers new hope for solving some of the most challenging problems in data science. Problems that are currently considered NP-hard or non-deterministic polynomial-time hard, which are not feasibly solvable with today’s computers, could potentially be tackled with quantum algorithms.
 

 Quantum computing could, for instance, revolutionize the field of optimization, which is crucial in logistics, manufacturing, and energy management, by finding the optimal solution to problems with a vast number of possible combinations and variables far more efficiently than current methods allow.
 

 In addition to solving NP-hard problems, quantum computing opens up new avenues for research in fields that require the simulation of complex quantum systems, such as materials science and pharmaceuticals.
 

 Even financial institutions in Japan are banking on quantum computing to solve many of the issues plaguing our networks and devices, such as cybersecurity vulnerabilities, data analysis limitations, and the overall efficiency of financial transactions. These problems, often too complex for classical computing technologies to handle efficiently, are ripe targets for the transformative power of quantum computing.
 

 The intrinsic nature of quantum computers makes them ideally suited for modeling quantum phenomena, offering the potential to accelerate the discovery of new materials and drugs. This represents a significant leap forward, as it could drastically reduce the time and cost associated with research and development in these key areas and ultimately lead to faster scientific breakthroughs and innovation.
 

 Challenges in the Quantum Era
 

 Despite its potential, the transition to quantum computing presents several significant challenges to overcome.
 

 Quantum computers are highly sensitive to their environment, with qubit states easily disturbed by external influences – a problem known as quantum decoherence. This sensitivity requires that quantum computers be kept in highly controlled conditions, which can be expensive and technologically demanding.
 

 Moreover, concerns about the future cost implications of quantum computing on software and services are emerging. Ultimately, the prices will be sky-high, and we might be forced to search for AWS alternatives, especially if they raise their prices due to the introduction of quantum features, as it’s the case with Microsoft banking everything on AI.
 

 This raises the question of how quantum computing will alter the prices and features of both consumer and enterprise software and services, further highlighting the need for a careful balance between innovation and accessibility.
 

 There’s also a steep learning curve for data scientists to adapt to quantum computing. Developing quantum algorithms requires a deep understanding of quantum mechanics and computing principles, which are not yet part of standard data science curricula.
 

 A Sea of Opportunities
 

 On the flip side, the challenges associated with quantum computing are matched by the vast opportunities it presents. The quest to overcome these hurdles is driving innovation in quantum error correction and quantum computer design, making the technology more robust and accessible. We might even see sensitive niches, such as medicine, experience their own quantum transformation.
 

 As the field matures, the integration of quantum computing into mainstream technology and business practices is expected to accelerate even further, offering unprecedented computational capabilities.
 

 We might even see sensitive niches such as medicine experience quantum transformation. While today’s iterations of HIPAA hosting are certainly potent, with quantum computing, cybersecurity in the field of medicine will need to evolve to address the unique challenges and opportunities presented by quantum technologies. The encryption methods currently safeguarding patient data and ensuring compliance with HIPAA regulations may soon be obsolete against the capabilities of quantum computing.
 

 The Future of Quantum Computing in Data Science
 

 The leap from classical to quantum computing isn’t merely a step – but a giant leap for the field of data science, promising to revolutionize how we process information, make predictions, and solve problems that have long eluded the grasp of current technologies.
 

 The potential for quantum computing to transform sectors like healthcare, finance, and climate science is immense, offering tools that are faster, more accurate, and capable of handling complexities far beyond today’s capabilities.
 

 However, this transition also poses significant challenges, necessitating a paradigm shift in how data scientists approach problems, develop algorithms, and interpret data. The journey towards quantum computing will require a concerted effort in education, research, and development to equip the next generation of data scientists with the skills and knowledge to navigate the quantum landscape.
 

 Despite these challenges, the future of data science in the quantum era is bright. As we continue to unlock the capabilities of quantum computing, we’re not just enhancing our computational power; we’re expanding the horizons of what is possible in data science.",Quantum Computing,Relevant,Relevant,
Dr. J. Nathan Matias on leading technology research for better digital rights,https://blog.mozilla.org/en/internet-culture/dr-j-nathan-matias-digital-rights-science-cornell-university/,"At Mozilla, we know we can’t create a better future alone, that is why each year we will be highlighting the work of 25 digital leaders using technology to amplify voices, effect change, and build new technologies globally through our Rise 25 Awards. These storytellers, innovators, activists, advocates. builders and artists are helping make the internet more diverse, ethical, responsible and inclusive.
 

 This week, we chatted with winner Dr. J. Nathan Matias, a professor at Cornell University leading technology research to create change and impact digital rights. He leads the school’s Citizen and Technology Lab (CAT) and is the co-founder of the Coalition for Independent Technology Research, a nonprofit defending the right to ethically study the impact of tech on society. We talk with Matias about his start in citizen science, his work advocating for researchers’ rights and more.
 

 As a professor at Cornell, how would you gauge where students and Gen Z are at in terms of knowing the dangers of the internet?
 

 As a researcher, I am very aware that my students are one narrow slice of Americans. I teach communication and technology. I teach this 500 student class and I think the students I teach hear about people’s concerns, about technology, through media, through what they see online. And they’re really curious about what if that is true and what we can do about it. That’s one of the great joys of being a professor, that I can introduce students to what we know, thanks to research and to all the advocacy and journalism, and also to what we don’t know and encourage students to help create the answers for themselves, their communities and future generations.
 

 To kind of go a little bit even further, as a professor, what are the things that you try to instill with them, or what are core concepts that you think are really important for them to know and try to hammer down to them about the internet and the social impacts of all of these platforms?
 

 If I’m known for one thing, it’s the idea that knowledge and power about digital technologies shouldn’t be constrained to just within the walls of the universities and tech companies. Throughout my classes and throughout my work, I actively collaborate with and engage with the general public to understand what people’s fears are to collect evidence and to inform accountability. And so, my students had the opportunity to see how that works and participate in it themselves. And I think that’s especially important, because yeah, people come to a university to learn and grow and learn from what scholars have said before, but also, if we come out of our degrees without an appreciation for the deeply held knowledge that people have outside of universities, I think that’s a missed opportunity.
 

 Beyond the data you collect in your field, what other types of data collection out there creates change and inspires you to continue the work that you do?
 

 I’m often inspired by people who do environmental citizen science because many of them live in context. We all live in contexts where our lives and our health and our futures are shaped by systems and infrastructures that are invisible, and that we might not appear to have much power over, right? It could be air or water, or any number of other environmental issues. And it’s similar for our digital environments. I’m often inspired by people who do work for data collection and advocacy and science on the environment when thinking about what we could do for our digital worlds. Last summer, I spent a week with a friend traveling throughout the California Central Valley, talking to educators, activists, organizers and farmworkers and communities working to understand and use data to improve their physical environment. We spent a day with Cesar Aguirre at the Central California Justice Network. You have neighborhoods in central California that are surrounded by oil wells and people are affected by the pollution that comes out of those wells — some of them have long been abandoned and are just leaking. And it’s hard to convince people sometimes that you’re experiencing a problem and to document the problem in a way that can get things to change. Cesar talked about ways that people used air sensors and told their stories and created media and worked in their local council and at a state level to document the health impacts of these oil wells and actually get laws changed at the state level to improve safety across the state. Whenever I encounter a story like that, whether it’s people in Central California or folks documenting oil spills in Louisiana or people just around the corner from Cornell — indigenous groups advocating for safe water and water rights in Onondaga Lake — I’m inspired by the work that people have to do and do to make their concerns and experiences legible to powerful institutions to create change. Sometimes it’s through the courts, sometimes it’s through basic science that finds new solutions. Sometimes it’s mutual aid, and often at the heart of these efforts, is some creative work to collect and share data that makes a difference.
 

 Dr.J Nathan Matias at Mozilla’s Rise25 award ceremony in October 2023.
 

 When it pertains to citizen science and the work that you do, what do you think is the biggest challenge you and other researchers face? And by that I mean, is it kind of the inaction of tech companies and a lot of these institutions? Or is it maybe just the very cold online climate of the world today?
 

 It’s always hard to point to one. I think the largest one is just that we have a lot more work to do to help people realize that they can participate in documenting problems and imagining solutions. We’re so used to the idea that tech companies will take care of things for us, that when things go wrong, we might complain, but we don’t necessarily know how to organize or what to do next. And I think there’s a lot that we as people who are involved in these issues and more involved in them can do to make people aware and create pathways — and I know Mozilla has done a lot of work around awareness raising. Beyond that, we’ve kind of reached a point where I wish companies were indifferent, but the reality is that they’re actively working to hinder independent research and accountability. If you talk to anyone who’s behind the Coalition for Independent Tech Research, I think we would all say we kind of wish it we didn’t have to create it, because spending years building a network to support and defend researchers when they come under attack by governments or tech companies for accountability and transparency work for actually trying to solve problems, like, that’s not how you prefer to spend your time. But, I think that on the whole, the more people realize that we can do something, and that our perspective and experience matters, and that it can be part of the solution, the better off we are with our ability to document issues and imagine a better future. And as a result, when it involves organizing in the face of opposition, the more people we’ll have on that journey
 

 Just looking at this year in general with so much going on, what do you think is the biggest challenge that we face this year and in the world? How do we combat it?
 

 Here’s the one I’ve been thinking about. Wherever you live, we don’t live in a world where a person who has experienced a very real harm from a digital technology — whether it’s social media or some kind of AI system — can record that information and seek some kind of redress, or even know who to turn to, to address or fix the problem or harm. And we see this problem in so many levels, right? If someone’s worried about discrimination from an algorithm in hiring, who do you turn to? If you’re worried about the performance of your self-driving car, or you have a concern about mental health and social media this year? We haven’t had those cases in court yet. We’re seeing some efforts by governments to create standards and we’re seeing new laws proposed. But it’s still not possible, right? If you get a jar of food from the supermarket that has harmful bacteria, we kind of know what to do. There’s a way you can report it, and that problem can be solved for lots of people. But that doesn’t yet exist in these spaces. My hope for 2024 is that on whatever issue people are worried about or focused on, we’ll be able to make some progress towards knowing how to create those pathways. Whether it’s going to be work so that courts know how to make sense of evidence about digital technologies —and I think they’re going to be some big debates there — whether it’s going to involve these standards conversations that are happening in Europe and the U.S., around how to report AI incidents and how to determine whether an AI system is safe or not, or safe for certain purposes and any number of other issues. Will that happen and be solved this year? No, it’s a longer term effort. But how could we possibly say that we have a tech ecosystem that respects people’s rights and treats them well and is safe if we don’t even have basic ways for people to be heard when things go wrong, whether it’s by courts or companies, or elsewhere. And so I think that’s the big question that I’m thinking about both in our citizen science work and our broader policy work at Cat Lab.
 

 There’s also a bigger problem that so many of these apps and platforms are very much dependent upon us having to doing something compared to them.
 

 Absolutely. I think a lot of people have lost trust in companies to do things about those reports. Because companies have a history of ignoring them. In fact, my very first community participatory science project in this space, which started back in 2014, we pulled information from hundreds of women who faced online harassment. And we looked at the kinds of things they experienced. And then whether Twitter back then was responding to people’s reports. It revealed a bunch of systemic problems and how the company has handled it. I think we’ve reached the point where there’s some value in that reporting, and sometimes for good and sometimes those things are exploited for censorship purposes as well — people report things they disagree with to try to get it taken down. But even more deeply, those reports don’t get at the deeper systemic issues. They don’t address how to prevent problems in the first place, or how to create or how to change the underlying logics of those platforms, or how to incentivize companies differently, so that they don’t create the conditions for those problems in the first place. I think we’re all looking for what are the right entities? Some currently exist, some we’re going to have to create that will be able to take on what people experience and actually create change that matters.
 

 We started Rise25 to celebrate Mozilla’s 25th anniversary, what do you hope people are celebrating in the next 25 years?
 

 I love that question because my first true encounter with Mozilla would have been in 2012 at the Mozilla festival, and I was so inspired to be surrounded by a room of people who cared about making the Internet and our digital worlds better for people. And it was such a powerful statement that Mozilla convened people. Other tech institutions have these big events where the CEO stands on a stage and tells everyone why what they’re doing is revolutionary. And Mozilla did something radically different, which was to create a community and a space for people to envision the future together. I don’t know what the tech innovations or questions are going to be 25 years from now — there will probably be some enduring ones about access and equity and inclusion and safety for whatever the technologies are. My hope is that 25 years from now, Mozilla will continue to be an organization and a movement that listens and amplifies and supports a broad and diverse community to envision that together. It’s one of the things that makes Mozilla so special, and I think is one of the things that makes it so powerful.
 

 What is one action you think that everybody can take to make the world and their lives online better?
 

 I think the action to believe yourself when you notice something unusual, or have a question. And then to find other people who can corroborate and build a collective picture. Whether it’s by participating in the study at Cat Lab or something else. I have a respiratory disability, and it’s so easy to doubt your own experience and so hard to convince other people sometimes that what you’re experiencing is real. And so I think the biggest step we can do is to believe ourselves and to like, believe others when they talk about things they’ve experienced and are worried about but use that experience as the beginning of something larger, because it can be so powerful, and make such a huge difference when people believe in each other and take each other seriously.
 

 What gives you hope about the future of our world?
 

 So many things. I think every time I meet someone who is making things work under whatever circumstances they have — unsurprising as someone who does citizen and community science. I think about our conversations with Jasmine Walker, who is a community organizer who organizes these large spaces for Black communities online and has been doing it for ages and across many versions of technology and eras of time. And just to see the care and commitment that people have to their communities and families as it relates to technology — it could be our collaborators who are investigating hiring algorithms or communities we’ve talked to. We did a study that involved understanding the impact of smartphone design on people’s time use, and we met a bunch of people who are colorblind and advocates for accessibility. In each of those cases, there are people who care deeply about those around them and so much that they’re willing to do science to make a difference. I’m always inspired when we talk, and we find ways to support the work that they’re doing by creating evidence together that could make a difference. As scientists and researchers, we are sometimes along for the ride for just part of the journey. And so I’m always inspired when I see the commitment and dedication people have for a better world.",General,Relevant,Relevant,
Mastercard Launches Open Banking Program,https://smallbiztrends.com/2024/03/mastercard-launches-open-banking-program.html,"Mastercard unveiled Open Banking for Account Opening program, marking a significant leap forward in the digital banking sector. This initiative is set to redefine the experience of opening digital accounts for U.S. consumers and small businesses, particularly for those involved with debit and prepaid products. By incorporating a suite of open banking products as a core benefit, Mastercard aims to address common challenges in the digital account opening process, including verification hurdles, high abandonment rates, non-sufficient fund (NSF) returns, and the tedious manual entry of payment details.
 

 The introduction of the Open Banking for Account Opening program is timely, aligning with the surging mobile banking adoption rates among Gen Z users, which Insider Intelligence predicts will grow from 20.7 million in 2020 to 47.8 million by 2026. This 12.4% year-over-year increase underscores the urgent need for more streamlined and user-friendly digital banking solutions.
 

 Mastercard’s commitment to enhancing the digital banking landscape is evident in its offer to provide participating U.S. issuers with complimentary access to key verification tools. These tools, including Account Owner Verification, Account Detail Verification, and Account Balance Check solutions, are specifically designed to facilitate the digital opening of Mastercard-branded consumer and small business debit and general-purpose reloadable consumer prepaid products.
 

 Leveraging the secure exchange of consumer-permissioned data, Mastercard Open Banking aims to deliver a seamless and secure digital account opening experience. By employing industry standards and cutting-edge machine learning technologies, the program empowers issuers to:
 

 Confidently verify account ownership.
 

 Dramatically reduce account abandonment and inactivity through swift account funding and an enhanced user experience.
 

 Minimize NSF returns with real-time balance verification.
 

 Silvana Hernandez, Executive Vice President of Product and Engineering for North America at Mastercard, highlighted the changing landscape of consumer banking behaviors, noting a significant shift towards online account openings driven by the demand for convenience and efficiency. “The Open Banking for Account Opening program provides another entry point to the digital economy through valuable and secure experiences that lean into the power of consumer-permissioned data,” Hernandez stated.
 

 Mastercard’s Open Banking initiative is not just about modernizing the account opening process; it’s about enriching the entire banking ecosystem. By making it safer, simpler, and more accessible for all participants, Mastercard is setting a new standard for digital banking services.
 

 Expected to be generally available in the first half of 2024, the Open Banking for Account Opening program represents a critical step towards creating a more inclusive and efficient digital economy. For small business owners and entrepreneurs, this initiative promises to streamline financial operations, making it easier to access essential banking services and manage finances effectively.",Communications Technologies,Relevant,Relevant,
"Blinken says fighting disinformation #39;vital US national security interest#39;, says technology must sustain democratic values",https://www.moneycontrol.com/news/technology/blinken-says-fighting-disinformation-vital-us-national-security-interest-says-technology-must-sustain-democratic-values-12481391.html,"A file photo of US Secretary of State Antony Blinken in Washington, DC. (Photo: Carolyn Kaster via AFP/Getty Images)
 

 US Secretary of State Antony Blinken underscored the need to make sure that technologies sustain democratic values, telling a democracy summit on Monday that authoritarian regimes deploy them to undermine democracy and human rights. Blinken spoke at the ministerial conference of the third Summit for Democracy, a US-led initiative held in Seoul, South Korea, this year.
 

 Fighting disinformation including AI-enabled content is a ""vital"" national security interest and diplomatic priority for the US, Blinken said, adding, ""Revitalising democracy will also require us to shape the technological future, that's inclusive, that's rights respecting, directed at driving progress in people's lives.""
 

 Story continues below Advertisement Remove Ad
 

 Saying that digital technologies, including both social media and Artificial Intelligence, were ""dramatically accelerating the speed and spread of disinformation,"" Blinken outlined US efforts to push back against the issue.
 

 ""As authoritarian and repressive regimes deploy technologies to undermine democracy and human rights, we need to ensure that technology sustains and supports democratic values and norms,"" he said, ""Building a more resilient information environment is a vital US national security interest and an urgent priority for our diplomacy.""
 

 The US State Department's 'Democratic Roadmap' of recommendations would include ""encouraging social media platforms to label AI-generated content, so users know when an image is real or when it is not,"" he said.
 

 Blinken also outlined a raft of efforts to support the media industry, including a crackdown on ""the misuse of commercial spyware to surveil and harass journalists, human rights defenders, and others –- including leveraging sanctions, export controls, and visa restrictions to hold governments and firms accountable"".
 

 Propaganda-spewing websites have typically relied on armies of writers, but Generative AI tools now offer a significantly cheaper and faster way to fabricate content. Hundreds of AI-powered sites mimicking news outlets have cropped up in recent months, fueling an explosion of false narratives -- about everything from war to politicians –- that researchers say is stoking alarm in a year of high-stake elections around the world.
 

 Experts say that auto-generated misinformation could have a major impact on the US 2024 election, with many other countries, including South Korea which has parliamentary elections in April, also concerned about the issue.
 

 Story continues below Advertisement Remove Ad
 

 US President Joe Biden first proposed the idea of a democracy summit during his 2020 campaign and has called for the US and like-minded allies to show the world that democracies serve societies better than autocracies.
 

 Also Monday, Blinken met South Korean Foreign Minister Cho Tae-yul and President Yoon Suk Yeol for talks on North Korea and the US-South Korea alliance, according to the South Korean government.
 

 North Korea fired at least one suspected ballistic missile in a defiant show of force that coincided with US Secretary of State Antony Blinken's Seoul visit.
 

 This would be the second ballistic missile Kim Jong Un’s regime has fired this year after shooting off an intermediate-range rocket in mid-January designed to hit US bases in Asia. The state’s official media said that projectile was a “hypersonic"" missile, indicating it deployed a reentry vehicle for carrying a nuclear warhead that can change its flight path at high speeds.
 

 (With inputs from from AP, AFP and Bloomberg)",General,Relevant,Relevant,
Digital Transformation with AI: The Benefits and Challenges,https://www.sitepoint.com/digital-transformation-ai-benefits-challenges/,"In this article, we’ll explore the benefits, challenges, and steps of implementing AI for your digital transformation. We’ll also provide you with some practical tips and examples to help you get started or continue your AI journey. This article will help you understand how AI can accelerate your digital transformation and how to make it happen.
 

 Digital transformation uses technologies to create new or modify existing business processes, products, services, and customer experiences. It’s not just about adopting new tools or platforms but changing how you think, operate, and deliver value to your customers and stakeholders.
 

 Digital transformation is essential for businesses to survive and thrive in the competitive and dynamic market. It can help you improve your efficiency, productivity, innovation, agility, and customer satisfaction. It can also help you reduce your costs, risks, and environmental impact.
 

 However, digital transformation takes work. It requires a clear vision, a strong strategy, committed leadership, a skilled workforce, a supportive culture, and a continuous learning mindset. It also involves a lot of data, insights, and intelligence to make informed and effective decisions.
 

 This is where artificial intelligence (AI) comes in. AI is the ability of machines or systems to perform tasks that usually require human intelligence, such as reasoning, learning, decision-making, and problem-solving. AI can enable and enhance your digital transformation by providing you with the capabilities, tools, and solutions to:
 

 Improve your customer experience and engagement by personalizing your offerings, providing faster and better service, and creating more interactive and immersive channels.
 

 Optimize your business processes and operations by automating your workflows, increasing accuracy and quality, and enhancing performance and scalability.
 

 Foster your innovation and growth by discovering new opportunities, creating new products and services, and generating new value propositions and business models.
 

 The Benefits of AI for Digital Transformation
 

 AI can bring many advantages and opportunities for your digital transformation. Here are some of the main benefits of AI for each of the three critical aspects of digital transformation: customer experience, business processes, and innovation.
 

 How AI can improve customer experience and engagement
 

 Customer experience is your customers’ perception and emotion when they interact with your brand, products, services, and channels. Customer engagement is the degree and frequency of customer involvement and loyalty to your brand, products, services, and channels. Both customer experience and engagement are crucial for customer satisfaction, retention, and advocacy, ultimately affecting your revenue and profitability.
 

 AI can help you improve your customer experience and engagement in the ways listed below.
 

 Personalizing your offerings . AI can help you tailor your products, services, and content to the preferences, needs, and behaviors of each customer. For example, AI can help you recommend the best products, offers, or content for each customer based on their purchase history, browsing behavior, or feedback. AI can also help you create personalized marketing campaigns, messages, and promotions that resonate with each customer segment or persona.
 

 Providing faster and better service . AI can help you provide more efficient and effective service to your customers by automating your customer support, feedback, and resolution processes. For example, AI can help you create chatbots, voice assistants, or virtual agents that can answer your customers’ queries, requests, or complaints 24/7, without human intervention. AI can also help you analyze customer feedback, sentiment, and satisfaction, providing actionable insights and suggestions to improve service quality and delivery.
 

 Creating more interactive and immersive channels. AI can help you make more engaging and memorable customer experiences by leveraging new and emerging technologies, such as augmented reality, virtual reality, or mixed reality. For example, AI can help you create virtual or augmented reality applications that simulate your products, services, or environments, allowing your customers to try, test, or explore them before buying. AI can also help you create mixed-reality applications that blend your physical and digital channels and provide customers with seamless and consistent experiences.
 

 How AI can optimize business processes and operations
 

 Business processes are the set of activities and tasks that you perform to deliver your products, services, or value to your customers and stakeholders. Business operations are the day-to-day management and execution of your business processes. Both business processes and operations are essential for your efficiency, productivity, quality, and performance, ultimately affecting your costs, risks, and profitability.
 

 AI can help you optimize your business processes and operations in the following ways.
 

 Automating your workflows . AI can help you automate your repetitive, manual, or mundane tasks and workflows and free up your time and resources for more strategic and creative work. For example, AI can help you automate your data entry, processing, analysis, and reporting tasks, reducing errors and delays. AI can also help you automate your document generation, verification, or document management tasks, improving compliance and security.
 

 Increasing your accuracy and quality . AI can help you improve the accuracy and quality of your outputs, outcomes, and decisions by providing you with more reliable and relevant data, insights, and intelligence. For example, AI can help you improve the accuracy and quality of your forecasts, predictions, or recommendations by using advanced algorithms, models, or methods, such as machine learning, deep learning, or natural language processing. AI can also help you improve your detection, diagnosis, or prevention accuracy and quality by using sophisticated techniques, such as computer vision, speech recognition, or sentiment analysis.
 

 Enhancing your performance and scalability. AI can help you improve your performance and scalability by enabling you to handle more complex, dynamic, or large-scale problems and scenarios and provide you with more flexible, adaptive, and scalable solutions. For example, AI can help you enhance your performance and scalability by using cloud, edge, or distributed computing, providing you with more computing power, storage, and network capabilities. AI can also help you enhance your performance and scalability using the Internet of Things, blockchain, or smart contracts, providing more connectivity, transparency, and automation.
 

 How AI can foster innovation and growth
 

 Innovation is creating new or improved products, services, processes, or business models to generate new value for your customers and stakeholders. Growth increases your revenue, profitability, market share, or competitive advantage. Both innovation and development are vital for your survival and success in the competitive and dynamic market.
 

 AI can help you foster your innovation and growth in the ways listed below.
 

 Discovering new opportunities . AI can help you find new opportunities for your products, services, processes, or business models by providing new data, insights, and intelligence. For example, AI can help you discover new opportunities by using data mining, web scraping, or social media analysis, providing you with new sources, types, or data formats. AI can also help you discover new opportunities by using pattern recognition, anomaly detection, or trend analysis, providing new patterns, anomalies, or trends in your data.
 

 Creating new products and services . AI can help you develop new products and services that can solve your customers’ problems, meet their needs, or exceed their expectations by providing you with new capabilities, tools, and solutions. For example, AI can help you create new products and services using generative design, adversarial networks, or neural style transfer, which can provide unique designs, images, or styles. AI can also help you create new products and services by using natural language generation, text summarization, or text translation, which can provide new texts, summaries, or translations.
 

 Generating new value propositions and business models. AI can help you develop new value propositions and business models that can differentiate you from your competitors, create new markets, or disrupt existing ones by providing new strategies, methods, or approaches. For example, AI can help you generate new value propositions and business models by using recommender systems, personalization, or segmentation, which can provide you with new ways to target, reach, or serve your customers. AI can also help you generate new value propositions and business models by using innovative pricing, dynamic pricing, or subscription pricing, which can provide you with new ways to price, charge, or monetize your products or services.
 

 The Challenges of AI for Digital Transformation
 

 AI can also bring many challenges and risks for your digital transformation. Here are some of the main challenges of AI for each of the three critical aspects of digital transformation: technical, organizational, and ethical.
 

 The technical and organizational barriers to AI adoption
 

 Lack of data . Data is the fuel for AI, and with enough, relevant, and quality data, AI can function properly and effectively. Data can be scarce, fragmented, inconsistent, incomplete, or inaccurate, limiting or hindering your AI capabilities and outcomes. Data can also be sensitive, confidential, or regulated, posing legal, ethical, or security challenges for AI use and sharing.
 

 Lack of skills . AI skills are the engine for AI, and with enough qualified and diverse skills, AI can be developed, deployed, and maintained. AI skills can be scarce, expensive, or competitive, creating talent gaps or shortages for your AI projects and teams. AI skills can also be specialized, complex, or evolving, requiring constant learning and updating for your AI professionals and users.
 

 Lack of infrastructure . Infrastructure is the foundation for AI, and with enough robust and secure infrastructure, AI can be supported and scaled. Infrastructure can be inadequate, outdated, incompatible, or vulnerable, limiting or compromising your AI performance and reliability. Infrastructure can also be costly, complex, or regulated, posing financial, technical, or legal challenges for your AI deployment and maintenance.
 

 Lack of culture. Culture is the enabler for AI, and with enough positive and supportive culture, AI can be adopted and embraced. Culture can be resistant, fearful, or skeptical, creating barriers or conflicts for your AI change and transformation. Culture can also be siloed, rigid, or hierarchical, which can hinder your AI collaboration and innovation. Culture can also be unaware, unprepared, or unskilled, which can cause your AI gap and mismatch.
 

 The ethical and social implications of AI use
 

 AI use is not just a technical or organizational issue but also an ethical and social one. It involves a lot of values, principles, and norms that guide your AI design, development, and deployment. It also consists of many impacts, consequences, and responsibilities resulting from your AI use and influence.
 

 Some of the ethical and social implications of AI use are listed below.
 

 Bias and discrimination . AI can be biased or discriminatory, either intentionally or unintentionally, due to the data, algorithms, or systems that are used to train, test, or run it. Bias and discrimination can affect the fairness, accuracy, and quality of your AI outputs, outcomes, and decisions and harm or disadvantage your customers, employees, or stakeholders. Bias and discrimination can also violate your ethical, legal, or social standards and expectations and damage your reputation, trust, or credibility.
 

 Privacy and security . AI can pose privacy and security risks, deliberately or accidentally, due to the data, algorithms, or systems used to collect, store, or process it. Privacy and security risks can affect the confidentiality, integrity, and availability of your AI data, insights, and intelligence and can expose or compromise your customers, employees, or stakeholders. Privacy and security risks can also violate your ethical, legal, or social standards and expectations and cause liability, penalty, or loss.
 

 Transparency and explainability . AI can be opaque or unexplainable, either inherently or deliberately, due to the data, algorithms, or systems that are used to generate, interpret, or communicate it. Opacity and unexplainably can affect the understandability, verifiability, and accountability of your AI outputs, outcomes, and decisions and confuse or mislead your customers, employees, or stakeholders. Opacity and unexplainability can also violate your ethical, legal, or social standards and expectations and can undermine your confidence, trust, or credibility.
 

 Human dignity and autonomy. AI can affect human dignity and autonomy, either positively or negatively, due to the data, algorithms, or systems used to augment, replace, or influence it. Human dignity and independence can affect the respect, value, and empowerment of your customers, employees, or stakeholders, enhancing or diminishing their well-being, rights, or freedoms. Human dignity and autonomy can reflect your ethical, legal, or social standards and expectations, improving or reducing your reputation, trust, or credibility.
 

 The Steps to Implement AI for Digital Transformation
 

 AI implementation is not a one-time or one-size-fits-all process, but a continuous and customized one. It requires a lot of planning, execution, and evaluation to ensure that your AI solutions are aligned with your digital transformation goals, needs, and capabilities. It also requires a lot of learning, improvement, and adaptation to ensure that your AI solutions are relevant, effective, and sustainable. Below are some of the main steps to implement AI for your digital transformation.
 

 How to assess your current digital maturity and AI readiness
 

 Before starting your AI journey, you must assess your current digital maturity and AI readiness. This will help you understand where you are, where you want to go, and what to do to get there. You can use various frameworks, models, or tools to assess your digital maturity and AI readiness, such as the Digital Maturity Model, the AI Maturity Model, or the AI Readiness Assessment Tool.
 

 Some of the critical dimensions and indicators that you can use to assess your digital maturity and AI readiness are:
 

 Strategy . Your vision, mission, goals, and objectives for your digital transformation and AI adoption and how they are aligned with your business strategy and customer value proposition.
 

 Leadership . Your commitment, support, and involvement of top management and key stakeholders for your digital transformation and AI adoption and how they are communicated and demonstrated across your organization.
 

 Culture . Your values, beliefs, and behaviors that foster your digital transformation and AI adoption and how they’re embedded and reinforced across your organization.
 

 Skills . Your knowledge, competencies, and capabilities that enable your digital transformation and AI adoption and how they are acquired, developed, and retained across your organization.
 

 Data . Your sources, types, and formats of data that fuel your digital transformation and AI adoption and how they are collected, stored, processed, and analyzed across your organization.
 

 Technology . Your tools, platforms, and systems that support your digital transformation and AI adoption and how they are integrated, deployed, and managed across your organization.
 

 Processes . Your activities, tasks, and workflows that deliver your digital transformation and AI adoption and how they are designed, implemented, and optimized across your organization.
 

 Innovation. Your outcomes, results, and impacts that demonstrate your digital transformation and AI adoption and how they’re measured, evaluated, and improved across your organization.
 

 Based on your assessment, you can identify your strengths, weaknesses, opportunities, and threats for your digital transformation and AI adoption and prioritize your actions and initiatives accordingly.
 

 How to define your AI vision and strategy
 

 After you’ve assessed your current digital maturity and AI readiness, you need to define your AI vision and strategy. This will help you articulate what you want to achieve, why you want to achieve it, and how you want to achieve it with AI.
 

 You can use various frameworks, models, or tools to define your AI vision and strategy, such as the AI Canvas, the AI Strategy Framework, or the AI Strategy Template.
 

 Some of the key elements and questions that you can use to define your AI vision and strategy are listed below.
 

 Vision . Your desired future state and direction for your digital transformation and AI adoption and how it aligns with your business strategy and customer value proposition. For example, you can define your AI vision as: “To become a leader in AI-powered innovation and customer experience in our industry.”
 

 Value proposition . Your unique and compelling value proposition for your digital transformation and AI adoption and how it differentiates you from your competitors and creates value for your customers and stakeholders. For example, you can define your AI value proposition as: “To provide personalized, efficient, and innovative products and services to our customers, and to optimize our processes and operations with AI.”
 

 Use cases . Your specific and prioritized use cases for your digital transformation and AI adoption and how they address your problems, needs, or opportunities. For example, you can define your AI use cases as: “To use AI to recommend the best products, offers, or content for each customer, to automate our customer support, feedback, and resolution processes, and to create virtual or augmented reality applications to simulate our products, services, or environments.”
 

 Solutions . Your feasible and viable solutions for your digital transformation and AI adoption and how they leverage your data, technology, and skills. For example, you can define your AI solutions as: “To use machine learning, natural language processing, and computer vision to train, test, and run our AI models, to use chatbots, voice assistants, or virtual agents to interact with our customers, and to use augmented reality, virtual reality, or mixed reality to create our applications.”
 

 Roadmap. Your realistic and actionable roadmap for your digital transformation and AI adoption, and how it outlines your milestones, deliverables, and resources. For example, you can define your AI roadmap as: “To start with a pilot project to test and validate our AI solution for one of our use cases, to scale up and deploy our AI solution for all of our use cases, and to monitor and improve our AI solution for continuous learning and adaptation.”
 

 Based on your definition, you can communicate and align your AI vision and strategy with top management and key stakeholders and secure their buy-in and support.
 

 How to select and prioritize your AI use cases and projects
 

 Once you’ve defined your AI vision and strategy, you must select and prioritize your AI use cases and projects. This will help you focus on the most relevant and valuable use cases and projects for your digital transformation and AI adoption. You can use various frameworks, models, or tools to select and prioritize your AI use cases and projects, such as the AI Use Case Prioritization Matrix, the AI Project Prioritization Framework, or the AI Project Prioritization Tool.
 

 Some of the critical criteria and factors that you can use to select and prioritize your AI use cases and projects are:
 

 Business value . The potential business value your AI use case or project can generate for your organization, such as revenue, profitability, market share, or competitive advantage.
 

 Customer value . The potential customer value that your AI use case or project can create for your customers, such as satisfaction, retention, advocacy, or loyalty.
 

 Technical feasibility . The technical feasibility of your AI use case or project, such as the availability, quality, and accessibility of your data, technology, and skills.
 

 Organizational readiness . The organizational readiness of your AI use case or project, such as the alignment, support, and involvement of your top management and key stakeholders for your AI use case or project.
 

 Implementation complexity . The implementation complexity of your AI use case or project, such as the time, cost, and effort required to develop, deploy, and maintain your AI solution.
 

 Risk and uncertainty. The risk and uncertainty of your AI use case or project, such as the technical, organizational, ethical, or social challenges or risks that you may face or encounter during or after your AI implementation.
 

 You can allocate resources, assign roles and responsibilities, and define your scope and deliverables for your AI use cases and projects based on your selection and prioritization.
 

 How to build and deploy your AI solutions
 

 After you’ve selected and prioritized your AI use cases and projects, you need to build and deploy your AI solutions. This will help you turn your ideas and plans into reality and deliver your AI value proposition to your customers and stakeholders.
 

 You can use various frameworks, models, or tools to build and deploy your AI solutions, such as the AI Development Lifecycle, the AI Deployment Framework, or the AI Deployment Tool.
 

 Some of the key steps and activities that you can use to build and deploy your AI solutions are listed below.
 

 Data preparation . Collecting, cleaning, transforming, and labeling your data for your AI solution and ensuring its quality, relevance, and security. For example, you can use data mining, web scraping, or social media analysis to collect your data from various sources, types, or formats. You can also use data cleansing, integration, or augmentation to clean, transform, or label your data for your AI solution. You can also use data quality, data validation, or data encryption to ensure the quality, relevance, and security of your data for your AI solution.
 

 Model development . The process of designing, building, and testing your AI model for your AI solution and ensuring its accuracy, performance, and reliability. For example, you can use machine learning, deep learning, or natural language processing to design, build, and test your AI model for your AI solution. You can also use cross-validation, hyperparameter tuning, or model selection to optimize your AI model for your AI solution. You can also use accuracy, precision, or recall measuring your AI model’s accuracy, performance, and reliability for your AI solution.
 

 Model deployment . The process of deploying, integrating, and managing your AI model for your AI solution and ensuring its scalability, availability, and maintainability. For example, you can use cloud, edge, or distributed computing to deploy, integrate, and manage your AI model for your AI solution. You can also use load balancing, fault tolerance, or backup and recovery to ensure the scalability, availability, and maintainability of your AI model for your AI solution.
 

 Solution delivery. Delivering, launching, and marketing your AI solution to your customers and stakeholders and ensuring its usability, accessibility, and desirability. For example, you can use chatbots, voice assistants, or virtual agents to deliver, launch, and market your AI solution to your customers and stakeholders. You can also use user interface, user experience, or user feedback to ensure the usability, accessibility, and desirability of your AI solution to your customers and stakeholders.
 

 You can monitor and evaluate your AI solution and its impact and outcome based on your build and deployment.
 

 How to measure and improve your AI outcomes and impact
 

 After you’ve built and deployed your AI solutions, you must measure and improve your AI outcomes and impact. This will help you assess and demonstrate the value and effectiveness of your AI solutions for your digital transformation and AI adoption. It will also help you identify and address any gaps, issues, or opportunities for your AI solutions and their improvement and adaptation.
 

 You can use various frameworks, models, or tools to measure and improve your AI outcomes and impact, such as the AI Outcome Measurement Framework, the AI Impact Assessment Framework, or the AI Impact Assessment Tool.
 

 Some of the critical dimensions and indicators that you can use to measure and improve your AI outcomes and impact are listed below.
 

 Business outcomes . The business outcomes that your AI solution can generate for your organization, such as revenue, profitability, market share, or competitive advantage. For example, you can measure your business outcomes using key performance indicators, return on investment, or net promoter score. Optimization, experimentation, or benchmarking can also improve your business outcomes.
 

 Customer outcomes . The customer outcomes that your AI solution can create for your customers, such as satisfaction, retention, advocacy, or loyalty. For example, you can measure customer outcomes using customer satisfaction scores, retention rates, or lifetime value. You can also improve your customer outcomes by using personalization, segmentation, or recommendation.
 

 Technical outcomes . The technical outcomes that your AI solution can achieve, such as accuracy, performance, and reliability. For example, you can measure your technical outcomes using accuracy, precision, or recall. You can also improve your technical outcomes using cross-validation, hyperparameter tuning, or model selection.
 

 Organizational outcomes . The organizational outcomes that your AI solution can enable, such as efficiency, productivity, quality, and performance. For example, you can measure your organizational outcomes using process efficiency, effectiveness, or quality. You can also improve your organizational outcomes using automation, optimization, or standardization.
 

 Innovation outcomes . The innovation outcomes that your AI solution can foster, such as new products, services, processes, or business models. For example, you can measure your innovation outcomes by using innovation rate, impact, or diffusion. You can also improve your innovation outcomes using ideation, prototyping, or testing.
 

 Ethical outcomes . The ethical outcomes that your AI solution can respect, such as fairness, transparency, and accountability. For example, you can measure your ethical outcomes using fairness, transparency, or accountability metrics. You can also improve your ethical outcomes by using bias mitigation, explainability enhancement, or suitability enhancement.
 

 Social outcomes. The social outcomes that your AI solution can contribute, such as well-being, rights, or freedoms. For example, you can measure your social outcomes using wellbeing, human rights, or freedom indicators. You can also improve your social outcomes using impact assessment, stakeholder engagement, or social responsibility.
 

 You can learn and adapt your AI solution and its impact and outcome based on your measurement and improvement.
 

 Conclusion
 

 AI is a pivotal and influential technology that can enable and enhance your digital transformation. AI can help you improve customer experience and engagement, optimize business processes and operations, and foster innovation and growth.
 

 However, AI comes with many challenges and risks, such as technical and organizational barriers, ethical and social implications, and implementation complexity.
 

 Therefore, you need to follow a systematic and strategic approach to implement AI for your digital transformation and ensure that your AI solutions are aligned with your goals, needs, and capabilities and are relevant, effective, and sustainable.
 

 This article has explored the benefits, challenges, and steps of implementing AI for your digital transformation. We’ve also provided you with some practical tips and examples to help you get started or continue your AI journey.",General,Irrelevant,Relevant,
Filipino police free hundreds of slaves toiling in romance scam operation,https://www.theregister.com/2024/03/18/phillipines_cyberslavery_gang_busted/,"Filipino police rescued 875 ""workers"" – including 504 foreigners – in a raid late last week on a firm that posed as an online gaming company but in reality operated a forced labor camp that housed romance scam operators.
 

 A video of the raid on the Tarlac Pogo firm posted last Thursday shows the nation's Criminal Investigation and Detection Group (CIDG) entering what appears to be an office housing rows of workers in front of computers.
 

 The rescued ""workers"" hailed from Vietnam, China, the Philippines, Rwanda, Taiwan, Indonesia, and Kyrgyzstan. The victims were allegedly lured into slavery on the promise of a job offer. Instead, they allegedly had their passports confiscated and were forced to adopt fake identities and pretend to be suitors of their victims to extract money.
 

 The schemes that lured the workers involved promises of cryptocurrency wins, investments in businesses, and more.
 

 Those who failed to meet quotas were physically harmed, deprived of sleep or locked in their rooms, executive director of Presidential Anti-Organized Crime Commission (PAOCC), Gilberto Cruz, told local media.
 

 Officials were reportedly tipped off by a Vietnamese worker who arrived at the center in January. He arrived after being promised a job as a chef. Police said he bore signs of torture in the form of electrocution marks.
 

 During the raid, the authorities seized live ammunition and guns from the ten-hectare compound, located approximately 60 miles north of Manila. Also found were mobile phones, sim cards and scripts. Thirty-four vehicles within the compound had mismatched serial numbers and license plates, according to Cruz.
 

 Since the raid, nine people have been charged in connection with the scam center. Only one of the individuals was Filipino, according to local media. Five were Chinese, two Vietnamese and one Malaysian. The individuals face anti-trafficking violations, among others, following an inquest.
 

 The ""gaming company"" that ran the operation – which went by Zun Yuan Technology Incorporated – maintains a meager website that may not initially set off alarm bells and appears more targeted toward recruiting staff than clients. The faux company details that it was established in 2023 as an upcoming ""prominent player/game provider in the online gaming industry"" providing ""a comprehensive range of services tailored to meet the unique needs of online casino operators worldwide.""
 

 Zun Yuan Technologies Inc website – Click to enlarge
 

 It then goes on to identify the company's purported facilities: a large cafeteria, multiple large generators for uninterrupted business operations, an onsite convenience store and a professional-grade billiards room.
 

 Those interested in getting in touch can do so only through Telegram or an email address.
 

 Scam compounds staffed with trafficked and enslaved manpower have become common in Southeast Asia. Last October, authorities in the Philippines raided what claimed to be an internet gaming license hub, called Smart Web Technology Corporation, in Pasay City – one of the cities that make up Metro Manila. Smart Web was allegedly dealing in sex trafficking, as well as crypto investment and love scams.
 

 Forced labor cyber crime syndicates have also been found in Cambodia, Laos, and Myanmar.
 

 According to a report [PDF] from the United Nations Office on Drugs and Crime (UNODC), ""the development of scalable and digitized solutions has supercharged the criminal business environment across Southeast Asia.""
 

 The report noted that the proliferation of similar forced-labor operations has intensified calls to ban online offshore gambling operators in the Philippines, resulting in new regulations of such entities.
 

 Unfortunately, such measures to address cyber fraud operations have only pushed them from Cambodia, the Philippines, Malaysia, Thailand and Vietnam into places like Lao PDR and parts of Myanmar. ®",General,Relevant,Irrelevant,
Dundee vs Rangers called off after heavy rainfall,https://www.skysports.com/football/news/11781/13093868/dundee-vs-rangers-postponed-scottish-premiership-clash-called-off-due-to-heavy-rain-around-dens-park,"The decision to postpone Sunday's Scottish Premiership match between Dundee and Rangers will be investigated by the league's governing body.
 

 Rangers hit out at the manner of the late decision to call off the game, saying they were left ""angered"" by a lack of communication.
 

 Philippe Clement's side had been due to play at midday - needing a win to return to top spot in the league - but following two pitch inspections, referee Don Robertson said a waterlogged pitch meant the game could not go ahead.
 

 The latest call-off marks Dundee's fourth home postponement in the Scottish Premiership this season.
 

 In a statement, the SPFL said they will now be ""investigating the circumstances surrounding this postponement"" and added ""this was particularly disappointing given the fact it was a live Sky Sports match and the proximity of the match to the split"".
 

 'Player safety primary consideration'
 

 Please use Chrome browser for a more accessible video player Don Robertson, the match official for Dundee vs Rangers, explains why the match was called off
 

 Match official Robertson told Sky Sports the main concern involved an area in front of one of the dugouts, which had been treated with sand but was still too waterlogged to be deemed safe.
 

 ""I was aware Dundee and the ground staff were working very hard on that specific area of the pitch as well as others causing them concern,"" he said.
 

 ""But unfortunately, what they've been able to do hasn't been enough to make the area safe for the players and that's the primary consideration in these matters. I know they've got a lot of sand, tried to remove some of the water, but it wasn't safe at 10.15am so unfortunately it's been postponed.
 

 ""We're guided by the home club in this situation. They will have first sight of the pitch, they arrived this morning and saw areas of concern and contacted the league and the Scottish FA.
 

 ""A local official came to do a primary pitch inspection, but it was agreed between the clubs and the SPFL that they would wait until 10.15am to conduct the final inspection of the pitch.""
 

 The postponement means Celtic will end the weekend top of the table, following their 3-1 win over St Johnstone on Saturday.
 

 In a strongly-worded statement on their website, Rangers claimed they had not been informed of any potential issues with the playing surface at Dens Park until Sunday morning, and questioned why they had not been raised sooner.
 

 ""Rangers, on behalf of our supporters, are extremely disappointed and angered with the late call-off of today's match,"" they wrote.
 

 ""The first team have prepared as normal for the match, and it was not until this morning that any concerns over the playing surface were raised.
 

 ""It is not understood why the home club did not raise those concerns in a more timely manner, given the reoccurring issues they have had with their playing surface at earlier points in the season.
 

 ""The Rangers team and thousands of our supporters had already arrived at the stadium by the time a decision was reached.
 

 ""This is the only match in the entire UK senior leagues to be postponed this weekend, and given it was to be shown on Sky Sports nationwide, reflects poorly on our game.""
 

 Clement: It's a crazy situation
 

 Please use Chrome browser for a more accessible video player Rangers boss Philippe Clement takes a dig at Dundee's pitch after being disappointed that their Scottish Premiership clash was postponed due to the condition of the surface
 

 Rangers manager Philippe Clement told Sky Sports:
 

 ""I'm very, very, very disappointed in many ways. We didn't know anything that there was a problem, nobody contacted us, not yesterday evening, not overnight or this morning. Our kit man was here early and he told us there was the problem.
 

 Datawrapper Datawrapper , which may be using cookies and other technologies. To show you this content, we need your permission to use cookies. You can use the buttons below to amend your preferences to enable Datawrapper cookies or to allow those cookies just once. You can change your settings at any time via the This content is provided by, which may be using cookies and other technologies. To show you this content, we need your permission to use cookies. You can use the buttons below to amend your preferences to enablecookies or to allow those cookies just once. You can change your settings at any time via the Privacy Options Unfortunately we have been unable to verify if you have consented to Datawrapper cookies. To view this content you can use the button below to allow Datawrapper cookies for this session only. Enable Cookies Allow Cookies Once
 

 ""That's a really strange thing for me. Secondly, I think it will be the only game in all the leagues in Scotland postponed [today]. That's a crazy situation. If you are playing in the Scottish Premiership, you should be playing with the highest standards and the best pitches also.
 

 ""The television pays a lot of money to broadcast it, fans pay a lot of money to attend, and now the game is postponed - it's a really strange situation.""
 

 Dundee owner Nelms: We did everything we could
 

 Please use Chrome browser for a more accessible video player Dundee manager Tony Docherty is disappointed his side's home match with Rangers has been postponed, but understands that officials have a job to do
 

 Dundee owner John Nelms told Sky Sports:
 

 ""We're supposed to be one of the most robust leagues in the world, the ball is rolling, we've had guys out here since 5am. Mother Nature's done what she's done, we've done everything we could to get this pitch in the right place.
 

 ""There are two small spots where the ball isn't bouncing, as we speak. The rest of the pitch is fine, they said they don't think we'll be able to get it playable before 12pm, so that's where we're at.""
 

 In pictures: Why Rangers' trip to Dundee was called off
 

 Dundee return to Scottish Premiership action after the international break at home to St Johnstone on March 30, while Rangers face Hibs at Ibrox.
 

 Both games kick off at 3pm.",General,Relevant,Irrelevant,
AMD Radeon RX 7600 XT: Is the 16GB graphics card worth the money?,https://www.pcworld.com/article/2262427/amd-radeon-rx-7600-xt-is-the-16-gb-graphics-card-worth-the-money.html,"The AMD Radeon RX 7600 XT is undoubtedly an extremely interesting graphics card that stands out from the crowd with its impressive 16GB of graphics memory. Its release in January 2024 was intended to close the gap between the existing RX 7600 and RX 7700 XT models.
 

 What are the RX 7600 XT’s technical specifications?
 

 The RX 7600 XT not only offers an impressive 16GB of graphics memory, but also an FP32 computing power of around 11.3 TFLOPS. These figures promise a smooth gaming experience, especially in Full HD resolution. The GPU has various clock frequencies, including a base clock of 1,720MHz, a gaming clock of 2,470MHz and a boost clock of 2,755MHz.
 

 Compared to its little sister, the RX 7600, the RX 7600 XT not only shows a slight increase in performance, but also offers twice as much graphics memory. This is particularly advantageous for users who work with resource-intensive applications or high-resolution textures. Although the GPU is mainly designed for Full HD gaming, it can also achieve satisfactory results in 1440p resolution as long as you can limit yourself to games such as Baldur’s Gate 3.
 

 You may be interested in this article: Best graphics cards
 

 How does the RX 7600 XT with 16GB perform?
 

 The market for graphics cards in the $300 to $400 price range is highly competitive, and the RX 7600 XT has to go against rivals such as the RTX 4060 Ti (8GB), Intel Arc A770 (16GB), and the RX 6750 XT. This shows that the RX 7600 XT offers a solid price-performance ratio, albeit not the best.
 

 Nevertheless, it is important to emphasize that despite the large memory, the RX 7600 XT is not necessarily the most powerful card in this price range. Both the RTX 4060 Ti and the RX 6750 XT offer slightly more performance, especially in more demanding games. So if you’re looking for a graphics card for QHD gaming, the RX 7600 XT might not fulfil all expectations.
 

 One interesting aspect of the RX 7600 XT is its connection of eight PCIe 4.0 lanes. Unfortunately, this comes with some limitations, such as the fact that the card is not designed for older systems with PCIe 3.0. An “upgrade” with this graphics card would result in read and write speeds being halved. This should be taken into account when deciding on the RX 7600 XT, especially if you plan to use it in an older system.
 

 Another highlight of the RX 7600 XT is the support of AMD’s FidelityFX Super Resolution (FSR 3). This upscaling technology is designed to improve image quality without significantly compromising performance. FSR makes it possible to enjoy games in higher resolutions without compromising on performance. This makes the RX 7600 XT particularly attractive for users who value a future-proof graphics card, as the 7000 generation benefits best from upscaling technology according to AMD.
 

 The large graphics memory of 16GB offers several advantages, which become apparent in a direct comparison with the RX 7600. For example, the Radeon RX 7600 XT can achieve a 40 percent increase in ray tracing performance compared to the RX 7600, because the smaller 8GB memory fills up very quickly with ray tracing activated. Nevertheless, a graphics card in this price range is not recommended for the use of ray tracing and the performance of the RX 7600 XT is still behind that of an Intel Arc A770, despite a better efficiency of around 30 percent.
 

 Conclusion
 

 The extra charge for the 16GB graphics memory does not make the price-performance ratio of the card look particularly good. Even an RTX 4060 Ti is more attractive than the RX 7600 XT due to the additional performance. The larger memory makes it possible to process more complex scenes and higher resolutions smoothly, which is reflected in better future-proofing. In addition, a larger graphics memory can also improve performance when using technologies such as ray tracing, but this is not a selling point.
 

 The big problem with the RX 7600 XT is the competition, which simply offers better performance. In addition, there are cards like the RX 6750 XT (6700 XT), which also offer very good future-proofing with their 12GB of graphics memory, cost no more, and are even designed for higher resolutions.
 

 If you’re looking for a good graphics card for gaming in Full HD, then it is best to go for the price-performance hit, the RX 6600 (8GB). It costs just under $200 and will be able to display everything in a smooth 60fps. If you want to gain your first experience with ray tracing, then the RTX 4060 Ti (16GB) offers 64 percent better performance compared to the RX 7600 XT, with 95 percent better efficiency — but it costs quite a bit more, too.
 

 This article was translated from German to English and originally appeared on pcwelt.de.",General,Relevant,Irrelevant,
China filed 25% more patents than the U.S. in 2023 — heavily sanctioned Huawei led all companies worldwide despite bans,https://www.tomshardware.com/tech-industry/china-filed-25-more-patents-than-the-us-in-2023-banned-huawei-led-all-companies-worldwide-despite-heavy-us-sanctions,"Huawei, Samsung, and Qualcomm were the top international patent filers in 2023, with China-based companies well ahead of their high-tech rivals from South Korea and the US, according to recently released data from the World Intellectual Property Organization (WIPO). Despite heavy US sanctions severely impacting its ability to function in global markets, Huawei easily led the rest of the companies worldwide with the top number of patents filed.
 

 China-based entities led all other countries in terms of the total number of patents filed. The total number of international patent applications filed globally was 272,600 in 2023, down 1.8% from 2023, but China remained on top with 69,610 applications, easily outstripping the United States, which had 58,823.
 

 The WIPO determines the number of patent applications filed by an entity through its Patent Cooperation Treaty (PCT) system. PCT patents are filed by entities wishing to protect their inventions in multiple countries with a single international patent application. Some companies do not file for a PCT patent application with all of their inventions, so while the WIPO rankings are important, they may not reflect all the patent applications filed in all countries.
 

 Companies
 

 Regarding corporate filings, Chinese telecommunications giant Huawei Technologies maintained its position as the top filer with 6,494 published PCT applications. South Korea's Samsung Electronics and the U.S.-based Qualcomm followed with 3,924 and 3,410 applications, respectively. Mitsubishi Electric of Japan and BOE Technology of China also featured in the top five, with 2,152 and 1,988 applications, respectively.
 

 Image 1 of 2 (Image credit: WIPO) (Image credit: WIPO)
 

 In fact, the entire Top 50 of PCT patent filers is dominated by high-tech companies that develop hardware, telecom technologies, and software. Meanwhile, Big Tech giants like Apple, Google, Microsoft, and Meta are not in the Top 15. Last year, companies like Oppo and Vivo were bigger inventors than Apple and Microsoft, whereas AMD and Nvidia were absent from the list.
 

 Countries
 

 Regarding countries, China continued to lead the world in PCT patent applications, submitting 69,610 applications in 2023, albeit with a minor decrease of 0.6% compared to the previous year. The United States followed in second place with 55,678 applications, experiencing a more significant decline of 5.3%. Japan, South Korea, and Germany completed the top five, each with varying changes in their application volumes.
 

 Image 1 of 2 (Image credit: WIPO) (Image credit: WIPO)
 

 India stood out as a significant contributor to the growth in patent filings, with a 44.6% increase in PCT applications compared to the previous year. According to WIPO, this follows a 25.9% growth in the prior year, indicating a strengthening and expanding innovation ecosystem in India. Similarly, Türkiye experienced an 8.5% growth in PCT filings in 2023. Other countries that experienced growth in patent filings were the Netherlands (+5.8%), France (+2%), and the Republic of Korea (+1.2%).
 

 Stay on the Cutting Edge Join the experts who read Tom's Hardware for the inside track on enthusiast PC tech news — and have for over 25 years. We'll send breaking news and in-depth reviews of CPUs, GPUs, AI, maker hardware and more straight to your inbox. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors
 

 ""Countries in Asia now represent 55.7% of international patent applications via WIPO – up from 40.5% just one decade ago,"" said Tang.
 

 Industries
 

 The most noticeable technology fields for PCT patent applications were computer technology, telecommunications, electrical machinery, medical technology, and pharmaceuticals. These fields accounted for approximately two-fifths of all published PCT applications in 2023. Notably, electrical machinery and transport experienced the fastest growth rates among the top technology fields.
 

 Image 1 of 2 (Image credit: WIPO) (Image credit: WIPO)
 

 Indeed, industry giants like Huawei, Qualcomm, Samsung, Ericsson, and Nokia filed for numerous telco-related PCT patent applications covering 5G and Wi-Fi technologies last year.
 

 ""Higher interest rates and economic uncertainties cast a shadow on innovation activity in 2023,"" said Daren Tang, WIPO director general. ""But declining inflation rates forecast for 2024 and hotspots like India, Southeast Asia, and beyond may provide more business confidence and innovation investments, setting the stage for a recovery in international IP fillings later this year. Despite these shorter-term dips, longer-term trends show IP use rising steadily in an increasingly global, digitalized economy and spreading worldwide as economies develop.""",Communications Technologies,Relevant,Relevant,
"Revolutionizing social media content creation with generative AI: strategies, insights, and future prospects",https://www.clickz.com/revolutionizing-social-media-content-creation-with-generative-ai-strategies-insights-and-future-prospects/269373/,"The social media landscape is a constant churn, demanding fresh and engaging content. As brands battle to capture audience attention, Generative Pre-trained Transformers (GPTs) have arrived as game-changers. These AI marvels, capable of whipping up text based on prompts, are revolutionizing how we create social media content.
 

 Prompting GPTs: mastering the art
 

 When it comes to using GPTs for social media content, crafting effective prompts is the key to generating content that resonates. A well-honed prompt significantly elevates the quality and relevance of the output. Here are some golden rules to remember when prompting GPTs for your social media needs:
 

 Specificity is king: Be crystal clear in your prompts to ensure the GPT understands exactly what kind of content you’re looking for. Vagueness leads to irrelevant or off-target responses. Keyword magic: Sprinkle your prompts with relevant keywords related to your topic or brand. This steers the GPT towards content that aligns with your marketing goals. The power of example: Show, don’t tell. Provide the GPT with examples within your prompt to illustrate the desired style, tone, and format. This helps it generate outputs that better match your vision. Refine and repeat: Don’t be afraid to tweak your prompts based on the results you receive. Iterative prompting helps you discover the optimal way to communicate your needs to the GPT. Stay in the know: The world of GPTs is constantly evolving. Keeping yourself updated on the latest features and developments is crucial. New versions might offer improved capabilities or require different prompting strategies for peak performance.
 

 By following these best practices, marketers can effectively tap into the power of GPTs to create captivating social media content that ignites audience engagement.
 

 Case study: Girl Power Marketing’s triumphant shift
 

 Girl Power Marketing (GPM) serves as a compelling case study in adapting to the digital age. Facing stagnant social media growth and engagement in early 2023, GPM founder Hodge identified the missing piece: a human touch.
 

 A strategic shift towards showcasing more of Hodge’s personality and GPM’s mission led to a remarkable transformation. This pivot to personalized content yielded impressive results, building a community of over 180,000 in just one year. Hodge’s experience underscores the importance of tailoring content to seasonal trends and holidays, ensuring brand messaging is timely and relatable. This case study exemplifies the power of adapting to a changing social media landscape and the effectiveness of injecting a personal touch into content creation.
 

 The future of social media marketing with generative AI
 

 The integration of generative AI into social media marketing marks a transformative era. As AI technologies like GPTs become more sophisticated, they offer unprecedented opportunities to create highly personalized and engaging content at scale.
 

 The future envisions AI not just as a content creation tool, but as a strategic partner in crafting campaigns that deeply resonate with audiences. Additionally, AI’s ability to analyze trends and predict consumer behavior will empower marketers to stay ahead of the curve, propelling social media marketing towards a more dynamic, responsive, and effective future. The journey with generative AI is just beginning, brimming with limitless potential for social media marketing.",AI,Relevant,Relevant,
Rivian Is Turning into the Subaru of EVs,https://heatmap.news/electric-vehicles/subaru-rivian-r3-suv,"Anchorage, Alaska’s mayoral race
 

 Who’s running: There are 10 candidates in Anchorage’s nonpartisan mayoral election, but the ones you need to know are Republican incumbent Mayor David Bronson; Democratic Party-endorsed Suzanne LaFrance, who helped pass the city’s Climate Action Plan while in the State Assembly; former state legislator and Democratic Party-endorsed Chris Tuck; and the Republican Party-endorsed former president and CEO of the Anchorage Economic Development Corporation Bill Popp.
 

 State of the race: Bronson led with 35% of the vote in polls a month out from election day on April 2, but that wouldn’t put him over the 45% hump he needs to win without a runoff. LaFrance holds around 25% of the potential vote, and experts say she’d likely beat Bronson if it goes to a runoff.
 

 Why it matters: Southcentral Alaska, home to half the state’s population, gets most of its energy from wells owned by Hilcorp in Cook Inlet. Hilcorp, however, has warned that it won’t commit to signing new contracts, which begin to expire next year, due to natural gas shortages. Mayors in the region, including Anchorage’s Bronson, recently formed a coalition to address the looming energy crisis, with solutions ranging from importing liquified natural gas from out of state, abroad, or Alaska’s North Slope 800 miles away; to new drilling (Bronson’s proposal); to finding an “alternative” source of energy (LaFrance’s stance). Whatever way you cut it, though, the next mayor of Anchorage is likely to have an outsized role in determining the state’s energy future, with organizations like The Alaska Center, which advocates for renewable energy, and Lead Locally, which champions climate leaders, rallying behind LaFrance.
 

 Arizona’s Senate seat
 

 Who’s running: Democratic Representative Ruben Gallego and “MAGA darling” Kari Lake are fighting for outgoing Independent Senator Kyrsten Sinema’s seat.
 

 State of the race: It’s a true toss-up, although early polls show Gallego with the edge.
 

 Why it matters: Sinema’s replacement could determine which party controls the Senate once the dust settles on November 5. In one corner is Lake, who has blamed heat-related deaths in the state on meth and, while “not opposed to some of the green energy,” has said she’d block renewable mandates. Gallego, by contrast, is endorsed by the League of Conservation Voters Action Fund in part for having paid special attention to public lands and waters and clean energy jobs while in Congress. He also co-sponsored the CHIPS and Science Act.
 

 Arizona’s Salt River Project Board of Directors
 

 What it is: The Salt River Project is the biggest public power company in the country by generation, serving the Phoenix metropolitan area. Its board and council are chosen through a confusing and dubiously democratic “acreage-based voting system” on the first Tuesday in April in even-numbered years.
 

 State of the race: A coalition of 14 clean energy candidates is attempting to flip the SRP board and council to make it more solar-friendly. However, only half of SRP’s customers are eligible to cast a vote — renters, for example, are not allowed — and less than 1% of those who are eligible actually do.
 

 Why it matters: Currently, less than 4% of SRP’s energy comes from solar, compared to almost 10% for other local utilities. Incumbents on the council and board — some of whom have had SRP seats in their families for more than a century — have voted to keep using coal and penalized rooftop solar, with six-time elected official Stephen Williams telling the local NBC affiliate that the “sun doesn’t shine at night” — which, while true, does not typically prohibit solar energy from being generated during the daytime. In addition to pushing for more solar, the Clean Energy candidates also want to protect the local watershed, an issue likely to become increasingly critical in the heat-baked state.
 

 The California Oil and Gas Well Regulations Referendum
 

 What it is: A vote on whether or not to overturn Senate Bill 1137, which prohibits new oil and gas wells from being built within a half-mile of homes, schools, nursing homes, jails, and hospitals, and requires additional safety measures like leak detection.
 

 State of the race: Big-money campaigns have killed progressive bills in California before, and the oil industry is poised to dump a lot more money into defeating the regulations. The campaign to overturn Senate Bill 1137 has already spent $20 million, while California’s Democratic Governor Gavin Newsom and Jane Fonda have rallied to support the bill.
 

 Why it matters: The California referendum is set to be one of a handful of cases of voters deciding directly on legislation related to oil, gas, and emissions this November. Oil interests are already tailoring their arguments to sway California’s liberal constituency, arguing that the law’s limits are arbitrary and that it will be worse for the environment in the long run by forcing the state to import oil from places with less stringent regulations. Proponents of the bill, however, say it is a cut-and-dry case of environmental justice, given that many of the more than 2 million Californians who live within a mile of an oil or gas well in the state are people of color. That hasn’t stopped oil interests from undertaking some confusing shenanigans, even as some experts say gas interests just want the referendum to cause a delay “until they figure out what they’re going to do next.”
 

 Michigan’s 7th Congressional District
 

 Who’s running: Former Democratic State Senator Curtis Hertel Jr., who is endorsed by the LCV, is running against former Republican State Senator Tom Barrett.
 

 State of the race: The Cook Political Reporthas called Michigan’s 7th district, representing Lansing and the surrounding area, “the most competitive open seat in the country.”
 

 Why it matters: “Climate won the Michigan midterms,” the Sierra Club wrote in 2022 after voters elected a “pro-environment majority” to the state legislature. Having control of both chambers allowed Democratic Governor Gretchen Whitmer to make speedy and impressive progress on the energy transition locally, while at the national level, Democrats took seven of the state’s 13 House seats. The advantages are slim, though, and going into November, Congressional Democrats face threats in MI-03, MI-08, and most notably, MI-07, which Democratic Congresswoman Elissa Slotkin has vacated to run for Senate. Notably, Democrats need to win five more House districts nationally to regain control of the chamber, which means every close district race is essential. It’s important locally, too; the race for Slotkin’s open seat is among the most competitive in the country, and green groups have hit Barrett for his poor environmental voting record and opposition to clean energy jobs.
 

 Montana’s Senate seat
 

 Who’s running: Incumbent Democrat Jon Tester will face the winner of the Republican primary — likely former Montana Secretary of State and Public Service Commission Chair Brad Johnson, a Libertarian, or ex-Navy SEAL and entrepreneur Tim Sheehy, who was endorsed by Trump as an “American hero.”
 

 State of the race:It’ll be a nail-biter. Tester “will likely have to convince one out of every six Trump voters to cross over for him” on a split ballot in November, RealClearPoliticsnotes. Still, polls show the Democrat with an early edge in potential Republican match-ups.
 

 Why it matters: Unlike Arizona, which has turned purple in the last two elections, Montana is still a solidly conservative state, which Trump won by more than 16 points in 2020. At the same time, Montana is becoming a “must-watch climate battleground,” balanced between its cheap and ample supply of coal and its deep-rooted pride in its natural landscape. But while Tester’s environmental record isn’t perfect, the opposition looks much worse: Johnson has scaremongered about the reliability of renewable energy and EVs stressing the grid, while Sheehy quietly deleted references to sustainability and climate change from the website for his aerial firefighting company, seemingly to boost his credibility with MAGA voters.
 

 North Carolina’s gubernatorial race
 

 Who’s running: North Carolina’s Democratic Attorney General Josh Stein will face the state’s Republican Lieutenant Governor, Mark K. Robinson.
 

 State of the race: Either a toss-up or a slight lean Democratic, depending on who you ask. Early polls show Stein and Robinson neck and neck.
 

 Why it matters: When I spoke to LCV’s senior vice president of campaigns, Pete Maysmith, he cited the North Carolina race as one of the advocacy group’s top 2024 priorities. Term-limited outgoing Democratic Governor Roy Cooper had long been an ally of green policymakers, setting strong EV goals for the state and making a (thwarted) push for offshore wind. Stein has vowed to keep up his predecessor’s work. Robinson, on the other hand, is one of the most flagrant deniers of climate change on any 2024 ballot: He’s called climate research “junk science” and misleadingly alleged there are “more polar bears on Earth now than ever.” Electing Stein wouldn’t just keep a climate denier out of office; with Cooper’s seat, Republicans could seize a trifecta in the state if, as expected, they keep control of the House and Senate. With no remaining opposition, they could start rolling back more of Cooper’s work.
 

 Washington State’s gubernatorial race
 

 Who’s running: There are currently 13 candidates in the nonpartisan primary for outgoing Governor Jay Inslee’s seat, but leading the polls are Attorney General Bob Ferguson, a Democrat endorsed by Inslee; moderate Democratic State Senator Mark Mullet; former moderate Republican Representative Dave Reichert; and former Richland school board member Semi Bird, the first Black Republican to run for governor in the state.
 

 State of the race: Likely Democrat; the state last elected a Republican governor in 1985. Still, a November poll that pitted Ferguson against Reichert showed the Republican with a 2-point lead over his opponent.
 

 Why it matters: Inslee’s apparent departure from politics will leave a gaping hole not just in the state’s climate leadership but also in the nation’s — as governor, Inslee made Washington an example for other states with its aggressive clean energy goals, phase-out of new gas-powered cars and trucks, heat pump requirement for new buildings, and local Climate Corps. That progressive trajectory is under threat from Republicans, who’ve successfully gathered signatures for potential initiatives that would chip away at “radical” policies like the state’s cap-and-invest program — a repeal of which both Reichert and Bird support. But Washington’s governor race could be consequential even if a Democrat wins. While Ferguson has called “climate change” a top priority and under Inslee opposed building a methane gas pipeline through the state, Mullet has taken a somewhat more moderate stance, expressing concerns about gas “affordability” for families.",General,Relevant,Irrelevant,
Deloitte unveils CyberSphere platform for simplified cyber program management,https://www.helpnetsecurity.com/2024/03/18/deloitte-cybersphere-platform/,"Deloitte has launched CyberSphere, a vendor-neutral services and solutions platform to help clients simplify their organizations’ cyber program data, workflows, reporting and third-party technologies for improved cyber operational efficiency and effectiveness.
 

 CyberSphere is built by Deloitte to help organizations quickly manage risks with the use of automation, artificial intelligence (AI) and machine learning (ML), while also reducing cyber program costs, duplicative efforts and threat alert fatigue. The streamlined and integrated platform is designed with multiple capabilities and broad functionality to offer clients new ways to visualize cyber risk metrics and workflows to inform ongoing environment tailoring, stakeholder reporting and cyber risk quantification.
 

 “Our C-suite and board-level clients have told us that as their organizations’ cyber programs grow, they need help reducing complexity and increasing the ease with which they can leverage advanced tech, hone programmatic strengths, shore-up weaknesses and report to key stakeholders,” said Emily Mossburg, Deloitte Global Cyber leader and a Deloitte Risk & Financial Advisory principal, Deloitte & Touche LLP. “This platform provides clients a set of services and solutions to help alleviate those pain points while providing access to data not possible with single solutions.”
 

 CyberSphere will offer clients the ability to leverage a curated set of modular capabilities supported by an ecosystem of third-party technology providers augmented by Deloitte services. Modules initially powered by CyberSphere will include digital identity management, managed extended detection and response (MXDR), attack surface management (ASM), managed secure access services edge (MSASE) and incident response. Future iterations of CyberSphere will include additional modules.
 

 “As the security threat landscape evolves, so does the need for cyber to enable business strategy. Operating in a coordinated manner across security programs is key to this,” said Adnan Amjad, U.S. Cyber leader and a Deloitte Risk & Financial Advisory partner, Deloitte & Touche LLP.
 

 “CyberSphere provides our clients with a simplified experience across various services, solutions and inputs, utilizing a tailored approach for ease of initial deployment and long-term operations. Enabled by both people and technology, CyberSphere can help organizations remain agile and drive better cybersecurity outcomes,” Amjad concluded.",General,Relevant,Relevant,
Qualcomm adds on device AI to more phones with Snapdragon 8s Gen 3,https://www.geeky-gadgets.com/on-device-ai/,"Qualcomm Technologies, has announced the launch of its latest premium-tier mobile platform, the Snapdragon 8s Gen 3. This new addition to the Snapdragon 8-series aims to deliver the most sought-after capabilities to a broader range of Android flagship smartphones, enabling extraordinary and premium user experiences.
 

 Key Features of Snapdragon 8s Gen 3
 

 The Snapdragon 8s Gen 3 Mobile Platform boasts an impressive array of features that set it apart from its predecessors:
 

 Support for powerful on-device generative AI features
 

 Always-sensing ISP for enhanced camera capabilities
 

 Hyper-realistic mobile gaming experience
 

 Breakthrough connectivity options
 

 Lossless high-definition sound quality
 

 One of the most notable aspects of the Snapdragon 8s Gen 3 is its support for a wide range of AI models, including popular large language models (LLM) such as Baichuan-7B, Llama 2, Gemini Nano, and Zhipu ChatGLM. This feature enables users to harness the power of generative AI directly on their smartphones, opening up a world of possibilities for creative and productive applications.
 

 On Device Generative AI and Advanced Photography
 

 Chris Patrick, senior vice president and general manager of mobile handsets at Qualcomm Technologies, Inc., emphasized the platform’s potential to enhance user experiences, stating, “With capabilities including on-device generative AI and advanced photography features, Snapdragon 8s Gen 3 is designed to enhance user experiences, fostering creativity and productivity in their daily lives.”
 

 The integration of generative AI capabilities within the Snapdragon 8s Gen 3 allows users to leverage the power of AI-driven tools directly on their smartphones. This means that tasks such as image and video editing, content creation, and even app development can be performed more efficiently and with greater ease, empowering users to unleash their creativity and boost their productivity.
 

 Collaboration with Leading Smartphone Manufacturers
 

 Qualcomm Technologies has partnered with several key OEMs, including Honor, iQOO, realme, Redmi, and Xiaomi, to bring the Snapdragon 8s Gen 3 to market. These manufacturers are expected to launch devices powered by the new mobile platform in the near future, with the first device anticipated to be announced as early as March.
 

 William Lu, Partner and President of Xiaomi Corporation, President of the International Business Department, and GM of Xiaomi Brand, expressed enthusiasm for the collaboration, stating, “We’re thrilled to collaborate with Qualcomm Technologies to introduce the first device powered by Snapdragon 8s Gen 3 – coming soon. This new mobile platform will allow us to provide our customers with a personalized premium experience, all thanks to generative AI.”
 

 With the introduction of the Snapdragon 8s Gen 3 Mobile Platform, Qualcomm Technologies is setting a new standard for premium smartphones. By bringing powerful on-device AI capabilities, advanced photography features, and cutting-edge connectivity options to a wider range of flagship devices, the company is empowering users to experience the best that mobile technology has to offer.
 

 As more smartphone manufacturers adopt the Snapdragon 8s Gen 3, consumers can expect to see a new generation of devices that deliver unparalleled performance, creativity, and productivity. The integration of generative AI and other advanced features will undoubtedly reshape the way users interact with their smartphones, making them an even more essential tool in their daily lives. Here are some other articles you may find of interest on the subject of Snapdragon 8 :
 

 

 

 Latest Geeky Gadgets Deals
 

 Some of our articles include affiliate links. If you buy something through one of these links, Geeky Gadgets may earn an affiliate commission. Learn about our Disclosure Policy",Communications Technologies,Relevant,Relevant,
Elon Says FSD V12.4 Is Way Better than Very Good FSD V12.3,https://www.nextbigfuture.com/2024/03/elon-says-fsd-v12-4-is-way-better-than-very-good-fsd-v12-3.html,"Elon Musk says Tesla FSD V12.4 is another big jump in capabilities and the training compute limitations are almost gone.
 

 AI expert James Douma had said that with additional training and data, he expected FSD V12.X to reach 0.1-1% of the interventions for Tesla FSD v11.X.
 

 If the level of improvement expected by James Douma were achieved then 1% intervention levels would be reached with three steps of 20% less each time.
 

 100 interventions, 20 interventions, 4 interventions, 0.8 interventions.
 

 If the rate of FSD training enabled 1 full release or improvement of an existing release every month, then 100X better than FSD v11.X would happen in May-June 2024.
 

 IF the Nvidia H100 chip sales for 2023 is correct, then Tesla had 15,000 Nvidia H100s in 2023. These should be installed and operating by now. This means that Tesla has at least 65 Exaflops of compute for training.
 

 

 

 Tesla had targeted 100 exaflops of training compute by October, 2024. If Tesla bought 10,000 Nvidia H100s in 2024 then Tesla will have over 100 Exaflops of training compute installed by May 2024.",AI,Relevant,Relevant,
"Army Raises Elite Unit To Work On 6G, AI, Critical Tech For Military Use",https://www.ndtv.com/india-news/army-raises-elite-unit-to-work-on-6g-ai-critical-tech-for-military-use-5261714,"The hi-tech unit will carry out technical scouting, evaluation, development.
 

 The Indian Army has raised an elite unit that will undertake research and evaluation of futuristic communication technologies like 6G, artificial intelligence, machine learning and quantum computing for military use given the changing nature of the field.
 

 The Signals Technology Evaluation and Adaptation Group or STEAG is mandated to nurture technologies spanning the complete spectrum of wired and wireless systems, officials said.
 

 The setting up of STEAG is part of the Army's efforts to develop technologies considering the future battlefield, they said.
 

 ""It will be a premier organisation, the first of its kind equipped with the capability to harness niche technology, leverage cutting-edge solutions and identify suitable cases for defence applications by fostering collaboration with academia and industry,"" one of the officials said.
 

 The elite unit will focus on all upcoming critical technology domains including electronic exchanges, mobile communications, software-defined radios, electronic warfare systems, 5G and 6G networks, quantum technologies, AI, machine learning, etc., he said.
 

 The hi-tech unit will carry out technical scouting, evaluation, development, and management of core ICT solutions, and provide user interface support by maintenance and upgradation of contemporary technologies available in the environment, the official added.
 

 Army Chief Gen Manoj Pande has been highlighting the need for acquiring new technologies by the force in view of the changing nature of warfare.
 

 ""Aligning itself with the tenets of Atmanirbhar Bharat and Start-Up India, STEAG will help bridge the divide between the armed forces on the one hand and industry and academia on the other,"" the official said on condition of anonymity.
 

 The new Centre of Excellence is expected to be a game changer in fostering self-reliance in high-end communication technologies, which have thus far been a monopoly of select countries with advanced economies and research ecosystems, he said.
 

 The Army believes communications are going to be an important component of military operations.
 

 ""In the fast-evolving technologies for the battlefield, the side with better communication technologies and the ability to connect the various constituents for information sharing will have an edge over its adversary,"" another official said.
 

 He said modern warfare necessitates the induction of new equipment to provide seamless communication support to units and formations during operations.
 

 ""To imbibe such advancements in technology, the Indian Army has raised this groundbreaking technology-oriented unit STEAG which will bolster its capabilities in the digital domain,"" he added.
 

 (Except for the headline, this story has not been edited by NDTV staff and is published from a syndicated feed.)",Communications Technologies,Relevant,Relevant,
Chuck Cook Says Tesla FSD V12.3 Is a Gamechanging Build,https://www.nextbigfuture.com/2024/03/chuck-cook-says-tesla-fsd-v12-3-is-a-gamechanging-build.html,"Chuck Cook is a supertester of Tesla FSD software. He has declared Tesla FSD V12.3 a gamechanging build.
 

 Chuck Cook on a 40 minute drive had no problems with areas that have always caused issues for other versions. It handled double lights, his unprotected left turns etc…
 

 It handled the unprotected left turn but there was a pause on partially committing turn.
 

 Dave Lee rated it a 9.5. He was super impressed with it. It was a lot better v11. He was not expected it to be a lot better than v11 this early.
 

 It is not robotaxi ready. He needs to do more drives. Dave is very excited with it getting more data and training to improve a lot this year.
 

 He is optimistic. Dave summarized:
 

 1.⁠ ⁠Wow! Overall, I’m super impressed. Ride quality is much more human-like than v11 with acceleration, braking and turning all much improved.
 

 2.⁠ ⁠Smart decisions – overall, v12.3 made better and smarter decisions in challenging situations than v11. Several places where I know v11 would have difficulty, v12.3 handled with ease.
 

 3.⁠ ⁠v12.3 handled speed bumps perfectly.
 

 4.⁠ ⁠Lots of the quirks and hesitations of v11 are gone in v12.3.
 

 5.⁠ ⁠Many of my rides today were flawless and exactly how a human would drive. v11 has a rigidity that is gone with v12.3.
 

 Overall, I’m quite blown away by v12.3. I was expecting a version that was comparable to v11 – better in some ways and worse in other ways. But what I’ve experienced (so far) is a system that feels much more confident and capable than v11. v12.3 is far from perfect and there’s still a lot of work ahead for Tesla’s FSD team but the end-to-end neural net app.",Robotics,Relevant,Relevant,
Samsung has been world’s biggest soundbar brand for 10 years in a row,https://www.sammobile.com/news/samsung-world-biggest-soundbar-brand-10-years-row/,"Samsung has announced that it was the world's biggest soundbar brand in 2023. With another year as the top-ranked soundbar brand globally, the South Korean firm has become the world's biggest soundbar brand for ten years.
 

 Samsung has been the world's biggest soundbar brand globally since 2013
 

 According to a report from FutureSource Consulting, Samsung was the world's biggest soundbar in 2023, and the company has achieved this feat consecutively for the past ten years. The latest market research analysis reveals that Samsung had an 18.8% market share and a 20.3% revenue share globally in 2023.
 

 Year after year, Samsung has continuously pushed the boundaries of soundbars, releasing several top-ranking soundbars and impressive new technologies. Some of the company's impressive audio technologies include Q-Symphony, which uses the speakers of the soundbar and the paired TV simultaneously for an immersive audio experience.
 

 The South Korean firm also introduced a feature called SpaceFit Sound, which calibrates the soundbar automatically according to the room it is placed in. A couple of years ago, Samsung also introduced Wireless Dolby Atmos, removing the restriction of using wires between the TV and the soundbar to be able to use Dolby Atmos.
 

 Last year, the HW-Q990C was adjudged the world's best soundbar of 2023, thanks to its impressive 11.1.4-channel audio and 656W of audio output. It also features AirPlay 2, 4K HDR10+ passthrough, built-in Alexa, SpaceFit Sound Pro, Active Voice Amplifier, and Game Mode Pro. It also has Spotify Connect, Tidal Connect, and SmartThings.
 

 Earlier this year, the company unveiled a follow-up flagship soundbar model, the HW-Q990D, which will be launched soon.
 

 Cheolgi Kim, EVP of Visual Display Business at Samsung Electronics, said, “We are thrilled to be once again acknowledged as the market leader in soundbars, a milestone that reflects the positive feedback from our customers over the years. Building on this success, we will continue to push the boundaries of home entertainment with superior sound quality and advanced connectivity features, leveraging AI-based sound technology to strengthen the consumer experience and Samsung’s position in the global market.”",Communications Technologies,Relevant,Irrelevant,
NVIDIA GTC 2024 – Jensen Huang discusses the future of AI,https://www.geeky-gadgets.com/?p=422433,"The world of artificial intelligence is rapidly evolving, and NVIDIA’s GTC 2024 conference is set to be a pivotal event in shaping its future. As AI continues to transform industries and revolutionize the way we live and work, it is crucial to stay informed about the latest advancements and trends in this field. GTC 2024 offers a unique opportunity to hear from visionary leaders, engage with experts, and explore the cutting-edge technologies that will drive the next wave of AI innovation.
 

 At the heart of this highly anticipated event is the opening keynote by Jensen Huang, NVIDIA’s founder and CEO. Known for his insightful and thought-provoking presentations, Huang will take the stage on Monday, March 18, at the SAP Center in San Jose, California, to discuss the future of AI and its potential to transform our world. His keynote will set the tone for the rest of the conference, which promises to be a gateway to the next wave of AI innovations.
 

 Shaping the Future of AI
 

 Here are some other articles you may find of interest on the subject of NVIDIA :
 

 Whether you are an AI enthusiast, a researcher, or a business leader looking to harness the power of artificial intelligence, GTC 2024 is an event you won’t want to miss. In this article, we will explore the key highlights of the conference, the visionary speakers you can expect to hear from, and how you can make the most of your GTC experience, whether attending in person or virtually.
 

 Attending GTC 2024
 

 To secure your spot for an immersive experience at the SAP Center, register to attend GTC in person. The center is conveniently located a short walk from the San Jose Convention Center, where the rest of the conference takes place. Attendees can pick up their badges starting at 10:30 a.m., with doors opening at 11 a.m. For those unable to attend in person, the keynote will also be livestreamed.
 

 Whether attending in person or virtually, dedicating yourself to the entire week of GTC is highly recommended. GTC is not just a conference; it is a gateway to the next wave of AI innovations that will shape our future.
 

 Transforming AI with Industry Pioneers
 

 Dive deeper into the origins and impact of transformer neural network architecture with Jensen Huang and the creators of this groundbreaking technology. Huang will host a panel featuring all eight authors of the legendary 2017 paper that introduced the concept of transformers:
 

 Ashish Vaswani
 

 Noam Shazeer
 

 Niki Parmar
 

 Jakob Uszkoreit
 

 Llion Jones
 

 Aidan N. Gomez
 

 Lukasz Kaiser
 

 Illia Polosukhin
 

 This panel will take place on Wednesday, March 20, from 11-11:50 a.m. Pacific.
 

 Visionaries Transforming Our World
 

 GTC 2024 brings together leaders from various industries who are at the forefront of AI innovation. Attendees will have the opportunity to hear from visionaries such as:
 

 Igor Babuschkin, xAI cofounder
 

 Sebastian Bubeck, Microsoft Vice President of GenAI
 

 Fei-Fei Li, Stanford University
 

 Joelle Pineau, Meta Vice President of AI Research
 

 Brad LightCap, OpenAI Chief Operating Officer
 

 David Luan, Adept AI founder and CEO
 

 Raquel Urtasun, Waabi founder and CEO
 

 Arthur Mensch, Mistral CEO
 

 These are just a few of the many experts who will share their insights and experiences at GTC 2024. From March 17-21, engage in workshops, peer networking, and connect with experts in the field. This year’s session catalog covers a wide range of topics, from robotics to generative AI, showcasing real-world applications and the latest in AI innovation.
 

 Stay connected with the event and fellow attendees by using the hashtag GTC24 on social media. This will allow you to engage with others, share your experiences, and stay up-to-date with the latest developments from the conference.
 

 GTC 2024 promises to be an enlightening experience for all, with visionary speakers and a comprehensive program covering the essentials of AI and computing. Don’t miss this opportunity to be part of the future of artificial intelligence and witness firsthand the advancements that will shape our world in the years to come. Jump over to the official NVIDIA GTC website to register and attend.“Come experience Jensen Huang’s GTC keynote live on-stage at the SAP Center in San Jose, CA to explore the AI advances that are shaping our future.”
 

 

 

 Latest Geeky Gadgets Deals
 

 Some of our articles include affiliate links. If you buy something through one of these links, Geeky Gadgets may earn an affiliate commission. Learn about our Disclosure Policy",General,Relevant,Relevant,
(PR) Qualcomm Brings the Best of On-Device AI to More Smartphones with Snapdragon 8s Gen 3,https://www.techpowerup.com/320481/qualcomm-brings-the-best-of-on-device-ai-to-more-smartphones-with-snapdragon-8s-gen-3,"Qualcomm Technologies, Inc. today announced the Snapdragon 8s Gen 3 Mobile Platform, delivering the most sought-after 8 series capabilities to more Android flagship smartphones, for extraordinary, premium experiences. Marquee features of the latest premium-tier platforms include support for powerful on-device generative AI features, an always-sensing ISP, hyper-realistic mobile gaming, breakthrough connectivity and lossless high-definition sound. The platform supports a broad array of AI models including popular large language models (LLM) such as Baichuan-7B, Llama 2, Gemini Nano and Zhipu ChatGLM.""With capabilities including on-device generative AI and advanced photography features, Snapdragon 8s Gen 3 is designed to enhance user experiences, fostering creativity and productivity in their daily lives."" said Chris Patrick, senior vice president and general manager of mobile handsets, Qualcomm Technologies, Inc. ""We're elated to introduce the latest addition to our premium Snapdragon 8-series, our most premium mobile offering, bringing a host of exceptional specially selected capabilities to more consumers.""""We're thrilled to collaborate with Qualcomm Technologies to introduce the first device powered by Snapdragon 8s Gen 3 - coming soon,"" said William Lu, Partner and President of Xiaomi Corporation, President of the International Business Department, GM of Xiaomi Brand. ""This new mobile platform will allow us to provide our customers with a personalized premium experience, all thanks to generative AI.""Snapdragon 8s Gen 3 will be adopted by key OEMS including Honor, iQOO, realme, Redmi and Xiaomi with the first device expected to be announced in March.",AI,Relevant,Relevant,
AI and Indigenous Languages.,https://languagehat.com/ai-and-indigenous-languages/,"Jesse Will writes about a promising use for what I suppose we must call AI, annoying as that name is:
 

 Running Wolf is one of a small but growing number of researchers who believe AI has the potential to safeguard endangered languages by simplifying the learning and practice process for speakers. As a co-founder of the First Languages AI Reality (FLAIR) Initiative at Mila Artificial Intelligence Institute, he is at the forefront of efforts to update the way indigenous languages are taught and preserved. “The ideal outcome is that we reverse this pendulum of language loss,” says Running Wolf. We discussed his Cheyenne roots and how his work experience as an engineer in AI speech recognition blossomed into a bigger calling. […]
 

 Indigenous languages are facing a steep decline: 90% are at risk of not being passed on to younger generations, while 70% are spoken by only a handful of individuals, predominantly elders. “Essentially, we’re racing against time. Within five to 10 years, we risk losing a significant part of the cultural and linguistic heritage in the United States,” explains Michael Running Wolf, a software engineer with roots in the Cheyenne community.
 

 Did you actively speak the Cheyenne language?
 

 I understood most of it. But it wasn’t something that was taught intentionally. It was a sore spot—for a long time Cheyenne was restricted institutionally. My mother managed to avoid the school system because her grandparents would hide them in the hills to avoid the government taking the children and putting them in boarding school. So you can see how speaking openly in Cheyenne could become a liability. But I grew up listening to it.
 

 […]
 

 How did you get interested in linguistics and technology?
 

 My grandfather spoke several languages: Cheyenne, Arapaho, Crow, and Lakota. I was always very proud of that. That used to be the norm for the Cheyenne—how we survived was being able to negotiate. So when I went to college I started thinking about language a lot, and how we might use modern technology to secure our future and culture. I think it’s critical that these technologies are compatible with indigenous languages, not only from a technical perspective, but also our ways of knowing.
 

 […]
 

 What area is your research currently focused on?
 

 What we’re doing right now is research and methodology to create automatic speech recognition for very low-resource indigenous languages in North America. In that process, I’m working on solving a lack of data, and the lack of compatibility between current AI methodologies and the morphology [the ways that words are formed] of North American languages, and trying to do it in a way that is ethical, earns the trust of indigenous communities, and hopefully inspires others. I don’t want to be the figurehead of indigenous AI. I need peers. I want communities becoming exemplars of what should be happening.
 

 About those technical challenges—what makes many indigenous languages fundamentally different than English?
 

 English has a finite distinct dictionary. In polysynthetic languages [such as Cheyenne], we have an infinite amount of words, and each word can convey as much information as an English phrase. Let’s take the simple example of a red car. I wouldn’t simply say “the red car.” In one word with three morphemes, one per word, and depending on the language, I’d say, “It’s your car, you are an acquaintance, you’re really far from me, and maybe that you’re to the west of me.” You bend all of that highly contextual information into a word that means “red car.” The dynamism here is such that a word may never occur more than once in a lifetime.
 

 But how do you gather a data set of infinite words?
 

 These are human languages. So there’s a finite set of morphemes. It’s doable for AI to speak indigenous languages—it’s just never been done. […]
 

 What do you imagine building?
 

 The majority of many tribes do not speak the language. We need to create tools that help them spread the knowledge a little bit easier. A key focal point of our practical research is to create tools that holistically integrate with the curricula that the speakers are teaching so that they could go home and practice on their phone with AI, without the necessity of having a speaker with them. That’s a big benefit if you’re shy—which most people are.
 

 And what if you could talk to your smart lightbulbs and say, in Lakota or Cheyenne, “Turn on the house lights”? It would make that indigenous language part of your life, rather than the language of ceremony. That’s what some of these languages have been relegated to—they’re no longer a day-to-day language except for a small pool of speakers. But if you’re a language learner, one of the best things to do is be immersed in it using all the technology that surrounds you.
 

 I mean, obviously, not everyone is going to do it. I don’t anticipate that every indigenous person is going to be wanting to learn their language, because that’s a personal choice. But making it easy and accessible—I think it’s a big first step.",AI,Relevant,Relevant,
"New Ecommerce Tools: March 18, 2024",https://www.practicalecommerce.com/new-ecommerce-tools-march-18-2024,"Every week we publish a rundown of new products from companies offering services to ecommerce and omnichannel merchants. This installment includes updates on payment platforms, smart search, B2B commerce, resale programs, gated-offer tools, logistics, customer experience platforms, and generative AI tools.
 

 Got an ecommerce product release? Email releases@practicalecommerce.com.
 

 New Tools for Merchants: March 18
 

 Amazon launches new generative AI-powered listing tool. In addition to using text or an image to generate product listings, sellers can now leverage existing listings by providing Amazon with a URL, which is automatically parsed by generative AI. This new capability is rolling out and will be available to U.S. sellers in the coming weeks.
 

 eBay launches Preloved Partner program. eBay is launching a new pilot program late this month to highlight pre-owned fashion, which sellers can join by invitation only. eBay will display a “Preloved Partner” program badge next to qualified items. Eligible sellers must maintain certain performance metrics, including Top Rated Seller status, a minimum of 95% positive feedback, 30-day returns, and fewer than 1% “Not Received” items.
 

 SAP announces composable payment solution. SAP’s new composable payment solution for retailers, Commerce Cloud, integrates with numerous third-party payment service providers, including Stripe, Adyen, Worldpay, and Airwallex. Commerce Cloud’s composable architecture allows retailers to pick payment partners tailored to their unique needs and markets. The new framework is extensible and headless, helping ensure the front- and back-ends are decoupled and operate independently.
 

 Walmart Commerce Technologies releases AI-powered logistics platform. Walmart is making its AI-powered logistics platform — Route Optimization — available to businesses as a SaaS solution through Walmart Commerce Technologies. Route Optimization provides businesses of all sizes the use of AI-driven software to optimize driving routes, pack trailers efficiently, and minimize miles traveled. Walmart says companies using this technology avoided 94 million pounds of carbon dioxide by eliminating 30 million unnecessary miles and optimized routes to bypass 110,000 inefficient paths.
 

 SheerID and Payment Plugins partner on gated offer platform for WooCommerce merchants. SheerID, a provider of identity verification for commerce, has partnered with Payment Plugins, a developer for WooCommerce, to launch SheerID for WooCommerce. The new platform allows merchants to verify consumer eligibility for gated offers and discounts instantly. SheerID states the platform is a no-code, turnkey solution.
 

 Rebuy introduces Smart Search for ecommerce. Rebuy, an ecommerce personalization platform for Shopify brands, has released Smart Search with the goal of increasing conversion rates and lowering cart abandonment rates through personalized experiences. Rebuy states that Smart Search can be set up and implemented in minutes. Additional enhancements will be released throughout the year, including collections merchandising and semantic search.
 

 Fortis and WooCommerce partner on B2B payment integration. Fortis, a payment and commerce technology service provider, has partnered with WooCommerce. This collaboration aims to provide B2B payment functionality to the WooCommerce platform and Fortis’s expanding back-office ecosystem. Fortis will debut as a verified payments app in the WooCommerce Marketplace and the WordPress Plugins Marketplace.
 

 Verndale announces strategic partnership with BigCommerce. Verndale, an ecommerce agency, has partnered with BigCommerce to provide design, development, and optimization services to merchant sites. Verndale’s commerce practice serves mid-market and enterprise clients and works with content management systems, enterprise resource planning platforms, customer relationship management platforms, and product information management databases.
 

 Brevo launches Commerce Suite for customer-data analysis. Brevo, a provider of customer-management applications, has launched Commerce Suite to provide merchants with a 360-degree view of customer data. Brevo says Commerce Suite enables merchants to analyze the full spectrum of their customers’ purchasing habits across all channels, allowing them to send more personalized recommendations. Per Brevo, merchants using Commerce Suite can improve the customer experience through multichannel communication adapted to each customer by email, SMS, chat, and social media — per Brevo.
 

 ShopMy secures $18.5 million to help influencers earn more from promoting products. ShopMy, a marketing platform for content creators, has raised $18.5 million in a round led by Inspired Capital. ShopMy’s platform equips creators with the tools to earn from their product recommendations, such as building digital storefronts, accessing a catalog of millions of products, making commissionable links, and chatting directly with companies. ShopMy will use the money to scale its network of 40,000 creators.​
 

 Zendesk to acquire Ultimate for AI-powered CX automation. Zendesk, a customer service platform, has announced it will acquire Ultimate, a provider of help-desk automation, to deliver a customer-service AI offering. With the addition of Ultimate, Zendesk says it will offer AI agents enhanced intelligence for proactive problem-solving, complementing human expertise. Terms of the deal were not disclosed.",General,Relevant,Irrelevant,
Announcing Search Index Management in MongoDB Compass,https://mongodb.com/blog/post/announcing-search-index-management-in-mongodb-compass,"Using Generative AI and MongoDB to Tackle Cybersecurity’s Biggest Challenges
 

 In the ever-evolving landscape of cybersecurity, organizations face a multitude of challenges that demand innovative solutions harnessing cutting-edge technologies. One of the most pressing issues is the increasing sophistication of cyber threats, including malware, ransomware, and phishing attacks, which are becoming more difficult to detect and mitigate. Additionally, the rapid expansion of digital infrastructures has widened the attack surface, making it harder for security teams to monitor and protect every entry and egress point. Another significant challenge is the shortage of skilled cybersecurity professionals — estimated by independent surveys to number around 4 million staff worldwide 1 — which leaves many organizations vulnerable to attack. These challenges underscore the need for advanced technologies that can augment human efforts to secure digital assets and data. How can generative AI help? Generative AI (gen AI) has emerged as a powerful tool in addressing these cybersecurity challenges. By leveraging large language models (LLMs) to generate new data or patterns based on existing datasets, generative AI can provide innovative solutions in several key areas: Enhanced threat detection and response Generative AI can be used to create simulations of cyber threats, including sophisticated malware and phishing attacks. These simulations can help in training machine learning models to detect new and evolving threats more accurately. Furthermore, gen AI can aid in the development of automated response systems that react to threats in real time. While this will never eliminate the need for human oversight, it will reduce the need for manual intervention and toil, allowing for quicker mitigation of attacks. For example, with the appropriate oversight it can automatically apply patches to vulnerable systems or adjust firewall rules to block attack vectors. This automated rapid response capability is particularly valuable in mitigating zero-day vulnerabilities, where the window between the discovery of a vulnerability and its exploitation by attackers can be very short. Actionable learnings from security event postmortems In the aftermath of a cybersecurity incident, conducting a thorough postmortem analysis is crucial for understanding what happened, why it happened, and how similar events can be prevented in the future. Generative AI can play a pivotal role in this process by synthesizing and summarizing complex data from a multitude of sources, including logs, network traffic, and security alerts. By analyzing this data, gen AI can identify patterns and anomalies that may have contributed to the security breach, offering insights that might be overlooked by human analysts due to the sheer volume and complexity of the information. Furthermore, it can generate comprehensive reports that highlight key findings, causative factors, and potential vulnerabilities, streamlining the postmortem process. This capability not only accelerates the recovery and learning process but also enables organizations to implement more effective remediation strategies, ultimately strengthening their cybersecurity posture. Generating synthetic data for deep model training The shortage of real-world data for training cybersecurity systems is a significant hurdle. Gen AI can create realistic, synthetic data sets that mirror genuine network traffic and user behavior without exposing sensitive information. This synthetic data can be used to train detection systems, improving their accuracy and effectiveness without compromising privacy or security. Automating phishing detection Phishing remains one of the most common attack vectors. Gen AI can analyze patterns in phishing emails and websites, generating models that predict and detect phishing attempts with high accuracy. By integrating these models into email systems and web browsers, organizations can automatically filter out phishing content, protecting users from potential threats. Putting it all together: The opportunities and the risks Generative AI holds the promise of transforming cybersecurity practices by automating complex processes, enhancing threat detection and response, and providing a deeper understanding of cyber threats. As the industry continues to integrate gen AI into cybersecurity strategies, it's crucial to remain vigilant about the ethical use of this technology and the potential for misuse. Nevertheless, the benefits it offers in strengthening digital defenses are undeniable, making it an invaluable asset in the ongoing battle against cyber threats. How does MongoDB help? With MongoDB, your development teams can build and deploy robust, correct, and differentiated real-time cyber defenses faster, and at any scale. To understand how MongoDB does this, consider that the the AI technology stack comprises three layers: The underlying compute (GPUs) and LLMs The tooling to fine-tune models along with the tooling for in-context learning and inference against the trained models The AI applications and related end-user experiences MongoDB operates at the second layer of the stack. It enables customers to bring their own proprietary data to any LLM running on any computing infrastructure to build gen AI-powered cybersecurity applications. MongoDB does this by addressing the hardest problems when adopting gen AI for cybersecurity. MongoDB Atlas securely unifies operational data, unstructured data, and vector data in a single, fully managed multi-cloud platform, avoiding the need to copy and sync data between different systems. MongoDB’s document-based architecture also allows development teams to easily model relationships between your application data and vector embeddings. This allows deeper and faster analytics and insights against security-related data. Figure 1: MongoDB Atlas brings together all of the data services needed to build modern cyber security applications in a unified API and developer data platform. MongoDB’s open architecture is integrated with a rich ecosystem of AI developer frameworks, LLMs, and embedding providers. This, combined with our industry-leading multi-cloud capabilities, allows your development teams the flexibility to move quickly and avoid lock-in to any particular cloud provider or AI technology in this rapidly evolving space. Check out our AI resource page to learn more about building AI-powered apps with MongoDB. Applying gen AI and MongoDB to real world cybersecurity applications Threat intelligence ExTrac utilizes AI-powered analytics and MongoDB Atlas to predict public safety risks by analyzing data from thousands of sources. The platform initially helped Western governments foresee conflicts but is expanding to enterprises for reputational management and more. MongoDB's document data model allows ExTrac to manage complex data efficiently, enhancing real-time threat identification. Atlas Vector Search aids in augmenting language models and managing vector embeddings for texts, images, and videos, speeding up feature development. This approach enables ExTrac to efficiently model trends, track evolving narratives, and predict risk for its customers, leveraging the flexibility and power of MongoDB to handle data of any shape and structure. Learn more in our ExTrac case study . Cybersec assessments VISO TRUST leverages AI to streamline the assessment of third-party cyber risks, making complex vendor security information quickly accessible for informed decision-making. Utilizing Amazon Bedrock and MongoDB Atlas, VISO TRUST's platform automates the due diligence of vendor security, significantly reducing the workload for security teams. Its AI-powered approach involves artifact intelligence that classifies security documents, detects organizations, and predicts security control locations within artifacts. MongoDB Atlas hosts text embeddings for a dense retrieval system that enhances the accuracy of LLMs through retrieval-augmented generation (RAG), providing instant, actionable security insights. This innovative use of technology enables VISO TRUST to offer rapid, scalable cyber risk assessments, boasting significant reductions in work and time for enterprises like InstaCart and Upwork. MongoDB's flexible document database and Atlas Vector Search play critical roles in managing and querying the vast amounts of data, supporting VISO TRUST's mission to deliver comprehensive cyber risk intelligence. Learn more in our Viso Trust case study . Steps to get started Generative AI powered by LLMs augmented with your own operational data encoded as vector embeddings is opening up many new possibilities in cyber security. If you want to learn more about the technology and its possibilities, take a look at our Atlas Vector Search learning byte . In just 10 minutes you’ll get an overview of different use cases and how to get started. 1 Hill, M. (2023, April 10). Cybersecurity workforce shortage reaches 4 million despite significant recruitment drive . CSO.",AI,Relevant,Relevant,
"Inside generative AI music startup Suno, whose model can compose songs, including human vocals, using a text prompt, as Suno aims to democratize music making (Brian Hiatt/Rolling Stone)",https://mediagazer.com/240318/p4,"About Mediagazer:
 

 Mediagazer presents the day's must-read media news on a single page.
 

 The media business is in tumult: from the production side to the distribution side, new technologies are upending the industry. Keeping up with these changes is time-consuming, as essential media coverage is scattered across numerous web sites at any given moment.
 

 Mediagazer simplifies this task by organizing the key coverage in one place. We've combined sophisticated automated aggregation technologies with direct editorial input from knowledgeable human editors to present the one indispensable narrative of an industry in transition.",General,Relevant,Irrelevant,
"Sources: Encyclopaedia Britannica, which publishes books like the Merriam-Webster dictionary, is seeking a $1B valuation in an IPO that could launch in June (Amy Or/Bloomberg)",https://mediagazer.com/240318/p8,"About Mediagazer:
 

 Mediagazer presents the day's must-read media news on a single page.
 

 The media business is in tumult: from the production side to the distribution side, new technologies are upending the industry. Keeping up with these changes is time-consuming, as essential media coverage is scattered across numerous web sites at any given moment.
 

 Mediagazer simplifies this task by organizing the key coverage in one place. We've combined sophisticated automated aggregation technologies with direct editorial input from knowledgeable human editors to present the one indispensable narrative of an industry in transition.",General,Relevant,Irrelevant,
"Q&A: Why Vrbo’s New Brand Campaign Is Spotlighting Trust, Transparency, and Consistency",http://skift.com/2024/03/18/qa-why-vrbos-new-brand-campaign-is-spotlighting-trust-transparency-and-consistency/,"Do vacation rental travelers prefer consistent experiences over quirky stays? Vrbo is betting they do, with a new brand campaign that aims to outshine the competition by highlighting traditional properties, price transparency, and loyalty rewards.
 

 This sponsored content was created in collaboration with a Skift partner.
 

 According to Skift Research, the short-term rental market is expected to normalize in 2024, following a year when U.S. demand declined due to economic uncertainty and Americans opted for overseas trips and cruises. AirDNA’s 2024 outlook predicts a rebound in demand, thanks to expected lower inflation rates and a pickup in domestic travel.
 

 Vrbo, part of Expedia Group, aims to capitalize on this increased demand with a new brand campaign highlighting the benefits of staying in a Vrbo and what sets it apart. For one thing, Vrbo primarily focuses on private vacation rentals, making it a preferred choice for families or groups seeking more space for togetherness. The campaign played up this focus on the traditional vacation rental market in two commercial spots that ran during the NFL divisional championship games.
 

 As the campaign unfolds, additional messaging emphasizes price transparency, consistent experiences, and the One Key travel rewards program, Expedia Group’s unique program that allows travelers to earn and burn rewards across Expedia, Hotels.com, and eligible Vrbo properties.
 

 SkiftX spoke with Tim Rosolio, vice president of vacation rental partner success at Expedia Group, about the latest vacation rental consumer trends and insights, the key elements of the Vrbo brand campaign, and the unique value proposition of One Key.
 

 SkiftX: What trends do you see shaping the short-term rental industry?
 

 Tim Rosolio, VP, Vacation Rental Partner
 

 Success at Expedia Group
 

 Tim Rosolio: During the pandemic, there was a surge in demand for vacation rentals as people sought safe and private accommodations. There was also an increase in supply as more people purchased second homes. While the initial wave of demand may have slowed, the industry remains healthy, as many travelers who tried vacation rentals during the pandemic have enjoyed the experience and are returning.
 

 With the influx of supply and normalized demand, property owners must now innovate and adapt to attract bookings, especially those not directly by prime locations like beaches and ski resorts — this could involve more flexible cancellation policies, adjusting minimum stay requirements, offering unique amenities, and reevaluating fees to make their offerings more attractive in a crowded marketplace.
 

 SkiftX: What prompted the creation of this campaign?
 

 Rosolio: Our campaign highlights how our brand stands out from competitors by focusing on the traditional vacation rental market. Unlike the evolving short-term rental space, which now includes shared spaces and unique accommodations — think homes shaped like spaceships — our approach emphasizes the classic experience of renting beach houses, ski lodges, or urban dwellings for a private getaway. While competitors may seek to redefine the category, we’re committed to the original concept of vacation rentals where guests enjoy privacy without an onsite host yet have support available.
 

 We aim to make the entire process seamless and transparent, from browsing to staying. This means clear pricing, detailed descriptions of what guests can expect from their rental, and a goal of consistency. We believe in the uniqueness of each property and provide a reliable experience where bookings are secure and the reality matches expectations, which reassures guests they can enjoy their vacation without surprises or disruptions.
 

 SkiftX: Can you walk us through the campaign’s key objectives, target audience, and multichannel strategy?
 

 Rosolio: Our primary audience is families and groups vacationing together who prefer traditional vacation rentals on beaches, near ski mountains, or at the lake. Our marketing campaign significantly leverages TV, featuring advertisements during major events such as NFL games and the Grammys.
 

 We’ve adopted an assertive approach in TV advertising and plan to expand our efforts through out-of-home advertising to highlight our unique offerings. This multi-faceted strategy also encompasses social media, public relations, and digital assets, aiming to engage our target audience comprehensively.
 

 Most of our promotional efforts are concentrated for spring, aligning with the peak booking period for summer stays. We’re still discussing our strategy for the fall, but in past years, we’ve often tied our marketing initiatives to college football campaigns.
 

 SkiftX: How does this campaign differentiate Vrbo and reset traveler expectations for the vacation rental industry?
 

 Rosolio: A vital differentiator we’re touting in the campaign is our One Key travel rewards program, the most comprehensive rewards program we’ve ever created. Historically, Hotels.com and Expedia had distinct rewards programs — however, Vrbo did not. Over the past few years, we’ve focused on integrating the back-end technologies across these core brands so we could create a unified travel rewards program. One Key members earn 2 percent in our OneKeyCash rewards currency on most vacation rentals. Since launching in July 2023, One Key now has over 100 million members1.
 

 What are the strategies you’re implementing to reduce host cancellations on guests? Specifically, are you taking measures to remove or penalize hosts with low acceptance and honor rates?
 

 Rosolio: Vacation rental travelers, like hotel guests, expect their selected booking to be quickly accepted and not canceled. To ensure this reliability, we’ve adopted a three-pronged strategy. First, we offer a Premier Host badge to partners who consistently meet our marketplace standards. Second, we’ve introduced a cancellation fee for hosts, which varies by the specifics of the booking and its proximity to the stay date, to deter cancellations. Finally, the most stringent measure is removing hosts from the platform if they frequently decline or cancel bookings. This approach prioritizes quality over quantity in our listings, focusing on properties committed to providing an exceptional experience, and reflects our commitment to maintaining a high standard of service and reliability for our travelers.
 

 SkiftX: The campaign is global, launching in the U.S., Canada, UK, France, Germany, Australia, and New Zealand. Why were these markets chosen?
 

 Rosolio: We are implementing our campaign in regions where our heritage brands are well-established, as Vrbo has grown by acquiring strong brands that share its core values. We have Abritel in France, FeWo-direkt in Germany, Bookabach in New Zealand, and Stayz in Australia, each serving as the go-to family and group travel platform. This common foundation allows us to apply similar creative strategies and assets across these markets. While maintaining a consistent global message, we also make thoughtful local adjustments. For instance, in the UK and Australia, we adapt our terminology to “holiday home” instead of “vacation rental” to better resonate with local audiences. These nuances in localization, however, align with the universal spirit of our marketing efforts.
 

 SkiftX: Vrbo’s new commercial spots clearly take aim at the quality of properties one might get with Airbnb. Are you trying to narrow the gap and compete head-on with Airbnb?
 

 Rosolio: While we never explicitly name competitors in our advertisements, it’s fairly obvious to discern who we might be referencing. We aim to excel in our niche: facilitating family and group travel through ideal vacation rentals, especially in traditional settings like ski and beach locations. We also see the potential for expansion into urban vacation rentals with a similarly high bar of quality. Our objective is to outperform other online travel agencies (OTAs) in these areas — and we’re confident we possess the necessary resources to achieve this goal and increase our market share.
 

 For more information about Expedia Group’s One Key rewards program, click here.
 

 This content was created collaboratively by Expedia Group and Skift’s branded content studio, SkiftX.",General,Relevant,Irrelevant,
Antony Blinken warns of false info âfloodâ as elections loom worldwide,https://www.moneycontrol.com/news/world/antony-blinken-warns-of-false-info-flood-as-elections-loom-worldwide-12479941.html,"Antony Blinken warns of false info ‘flood’ as elections loom worldwide
 

 Secretary of State Antony Blinken warned that authoritarian governments were going to meddle in a flurry of elections and the US would keep pressing to disrupt misinformation efforts from China and Russia.
 

 “Nearly half the people of the world are going to be going to the polls this year – this is an extraordinary election year in country after country,” Blinken told a session at the Summit for Democracy conference in Seoul on Monday. “But citizens and candidates will face a flood of falsehoods that suffocate serious civic debate.”
 

 Story continues below Advertisement Remove Ad
 

 The top US diplomat’s comments come during a year in which large democracies around the world — from India and Indonesia to the US and UK — are set to hold key elections, and at a time when huge advances in generative artificial intelligence are fueling increased worries about fake content influencing voters.
 

 “Our competitors, our adversaries are using disinformation to exploit fissures within our democracies by further sowing suspicion, cynicism and instability. Pitting one group against another. Discrediting our institutions,” he said.
 

 Since US tech companies and specialized American-made microchips are at the forefront of AI innovation, US leaders wield particular sway over how the field is overseen.
 

 The top US envoy also said during his visit to the South Korean capital that governments are using artificial intelligence to spy on their citizens and harass journalists.
 

 He cited US efforts to unveil Chinese propaganda campaigns in Africa and Southeast Asia and Russian attempts to sow its own narrative about the war in Ukraine in Latin America.
 

 Blinken said democracies needed to do more to disrupt misinformation, including encouraging powerful social media companies to properly label misleading or false content generated by new artificial intelligence technologies.
 

 Story continues below Advertisement Remove Ad
 

 “Digital technologies, social media and now artificial intelligence, they’re dramatically accelerating what has already been an incredibly fast pace of change, but that accelerant has also created” waves of disinformation, fueling polarization and confusion, he said.",Anti-disinformation technologies,Relevant,Relevant,
This $800 laptop punches way above its weight,https://www.digitaltrends.com/computing/asus-zenbook-14-q425-review/,"Asus Zenbook 14 Q425 MSRP $1,050.00 Score Details DT Recommended Product “The Asus Zenbook 14 Q425 is the first Meteor Lake laptop that's both fast and efficient.” Pros Excellent build quality
 

 Strong productivity performance
 

 Robust battery life
 

 Good keyboard and touchpad
 

 OLED's usual colors and contrast Cons Display is only FHD+
 

 Keyboard switches could be tighter
 

 Asus makes the best laptops under $1,000. Rather than compromise in key areas like design, performance, and build quality, Asus’ Zenbooks tend to balance these attributes remarkably well.
 

 The new Zenbook 14 Q425 is a great example of such a laptop. It checks all the boxes, offering Intel Meteor Lake chipsets and a great OLED display at a reasonable $800 starting price. At the same time, it’s a step down from the closely aligned Zenbook 14 OLED (UX3405) I reviewed earlier this year, which has a higher-resolution panel. Even so, the Zenbook 14 Q425, with its excellent battery life, remains an easy laptop to recommend at its lower price.
 

 Specs and configurations
 

 Asus Zenbook 14 Q425 Dimensions 12.30 inches x 8.67 inches x 0.59 inches Weight 2.82 pounds Processor Intel Core Ultra 5 125H
 

 Intel Core Ultra 7 155H Graphics Intel Arc graphics RAM 8GB
 

 16GB Display 14.0-inch 16:10 FHD+ (1920 x 1200) OLED touch, 60Hz Storage 512GB SSD
 

 1TB SSD Touch Yes Ports 2 x USB-C with Thunderbolt 4
 

 1 x USB-A 3.2 Gen 1
 

 1 x HDMI 2.1
 

 1 x 3.5mm audio jack Wireless Wi-Fi 6E and Bluetooth 5.3 Webcam 1080p with infrared camera for Windows 11 Hello Operating system Windows 11 Battery 75 watt-hours Price
 

 $800+
 

 Asus offers two configurations of the Zenbook 14 Q. The Q415 model costs $800 with an Intel Core Ultra 5 125H chipset, 8GB of RAM, a 512GB SSD, and a 14-inch FHD+ OLED display. I reviewed the Q425 model, which costs $1,050 for a Core Ultra 7 155H, 16GB of RAM, and a 1TB SSD. The base model is $100 more than the 2023 Zenbook 14 OLED, which started at $700 with an AMD processor, but less than the $1,300 2024 Zenbook 14 OLED.
 

 The entry-level model is a significant value for a fast 14-inch laptop with an OLED display. Only the 8GB of RAM gives me pause, although that’s enough for basic productivity tasks. The high-end model is an attractive option for anyone who needs more RAM and storage for their workflow.
 

 You’ll spend $1,o99 for a base MacBook Air M3 that matches the Zenbook’s base configuration and $1,699 on a comparable MacBook Air at the Zenbook’s high end. The Dell XPS 14 is $1,799 for the same chipset, RAM, and storage, but with an IPS display. Upgrade to the higher-resolution OLED option, and you’ll spend an additional $300.
 

 Design
 

 Everything else aside, I’ve always been impressed with Asus’ build quality. Like most Asus laptops I’ve reviewed, the Zenbook 14 Q425’s aluminum chassis and lid resist all bending, flexing, or twisting. I have no idea how Asus manages to make a lid that’s as thin as the MacBook Air’s but doesn’t exhibit that laptop’s slight bendiness. The rest of the Zenbook feels just as solid. Even the hinge is equally well done, allowing the lid to be opened smoothly with one hand and keeping it in place.
 

 The Zenbook 14 Q425 is also thin and light at 0.59 inches and 2.82 pounds. The MacBook Air is one of the thinnest laptops at just 0.44 inches, but it feels denser than the Zenbook at 2.7 pounds. Asus included reasonably thin display bezels, particularly along the sides, so the Zenbook 14 Q425 is also a small laptop, even with its 14-inch display. The MacBook Air is slightly less wide and deep, but it has a smaller 13.6-inch display. The Dell XPS 14 has the smallest display bezels around, and it’s still slightly thicker at 0.71 inches and heavier at 2.7 pounds.
 

 Aesthetically, the Zenbook 14 Q425 offers a simpler design than some other recent options. The Asus geometric pattern on the lid is absent here, with a simple dark gray color scheme and a subdued Asus logo. The rest of the laptop shares the same color, with an attractive minimalist design that doesn’t stand out. The MacBook Air and XPS 14 are arguably more attractive laptops, with the Dell boasting a particularly ultramodern design when the lid is open. However, you won’t spend more on those laptops based on their aesthetics alone.
 

 The Zenbook 14 Q425’s keyboard has large, comfortable keycaps, lots of key spacing, and light and snappy switches. I liked it quite a bit, although it falls behind the shallower Apple Magic Keyboard on the MacBook Air due mainly to the Zenbook’s switches seeming looser than I like. That’s a quibble, though. Typing this review on the Zenbook was quick and not the least bit fatiguing.
 

 The mechanical touchpad is nicely sized and has button clicks that I found just the slightest bit noisy when pressed. I can’t wait until haptic touchpads make their way down to midrange laptops like the Zenbook 14 Q425. That’s one thing that more expensive options like the MacBook Air and XPS 14 offer.
 

 Ports
 

 Not every 14-inch laptop has great connectivity. The Dell XPS 14 is one example, offering only USB-C with Thunderbolt port and requiring dongles for legacy devices. The Zenbook 14 Q425 is different, with a mix of Thunderbolt 4 and legacy connections. It lacks an SD card reader, which is an unfortunate omission, but I’ve seen a few recent laptops that do the same.
 

 Wireless connectivity isn’t the latest Wi-Fi 7, but Wi-Fi 6E, and Bluetooth 5.3 will meet mainstream needs for a few more years.
 

 The Zenbook 14 Q425 has a 1080p webcam with an infrared camera for Windows 11 Hello facial recognition and a physical privacy shutter. Asus builds in a few technologies to enhance videoconferencing quality, such as its AiSense ambient light sensor and 3D noise reduction.
 

 As with all laptops using the Meteor Lake chipset with its Neural Processing Unit (NPU), the Zenbook can speed up various tasks using Microsoft Studio Effects, such as background blue, eye contact, and automatic framing. Theoretically, the NPU performs these tasks more efficiently.
 

 Performance and battery life
 

 The Zenbook 14 Q series can be purchased with either an Intel Core Ultra 5 125H or Core Ultra 7 155H chipset. Both are members of the 14th-gen Meteor Lake series, and they offer the aforementioned NPUs for on-device AI to go with new Low Power Efficient cores that promise better efficiency. Both are 28-watt chipsets, with the Core Ultra 5 125H offering 14 cores (four Performance, eight Efficient, and two Low Power Efficient) and 18 threads running at up to 4.5GHz and the Core Ultra 7 155H with 16 cores (six Performance, eight Efficient, and two Low Power Efficient) and 22 threads running at up to 4.8GHz.
 

 I reviewed the latter, and it provided the same fast CPU performance as every other laptop sporting the same chipset. It’s as fast as the previous generation of 45-watt chips and can meet the most demanding productivity needs. While the fans spun up in performance mode, they were never too loud and the chassis and keyboard deck never got more than warm. We haven’t tested a Core Ultra 5 125H, but it should provide plenty of performance for productivity users.
 

 The integrated Intel Arc graphics are about twice as fast as the earlier Intel Iris Xe, but that’s still about half as fast as entry-level discrete GPUs. So, the Zenbook 14 Q425 isn’t as impressive as a gaming laptop or creator’s workstation.
 

 Geekbench 5
 

 (single/multi) Handbrake
 

 (seconds) Cinebench R23
 

 (single/multi) PCMark 10 Complete Asus Zenbook 14 Q425
 

 (Core Ultra 7 155H) Bal: 1,693 / 10,983
 

 Perf: 1,728 / 11,473 Bal: 97
 

 Perf: 85 Bal: 1,706 / 8,684
 

 Perf: 1,758 / 10,899 6,086 Lenovo ThinkPad X1 Carbon Gen 12
 

 (Core Ultra 7 155H) Bal: 1,658 / 8,569
 

 Perf: 1,698 / 9,726 Bal: 159
 

 Perf: 108 Bal: 1,570 / 6,867
 

 Perf: 1,625 / 10,365 6,082 Asus Zenbook 14 OLED 2024
 

 (Core Ultra 7 155H) Bal: 1,696 / 9,502
 

 Perf: 1,703 / 12,246 Bal: 145
 

 Perf: 88 Bal: 1,653 / 9,156
 

 Perf: 1,635 / 12,130 6,316 HP Spectre x360 14
 

 (Core Ultra 7 155H) Bal: 1,696 / 9,502
 

 Perf: 1,703 / 12,256 Bal: 111
 

 Perf: N/A Bal: 1,750 / 9,832
 

 Perf: N/A 6,316 Lenovo Yoga 9i Gen 8 (Core i7-1360P) Bal: 1,843 / 8,814
 

 Perf: 1,835 / 10,008 Bal: 122
 

 Perf: 101 Bal: 1,846 / 8,779 Perf: 1,906 / 9,849 6,102 Asus Zenbook 14X OLED (Core i7-13700H) Bal: 1,848 / 11,157
 

 Perf: 1,852 / 11,160 Bal: 84
 

 Perf: 82 Bal: 1,819 / 11,066 Perf: 1,826 / 12,795 6,020 HP Pavilion Plus 14 2023
 

 (Ryzen 7 7840U) Bal: 1,819 / 9,655
 

 Perf: N/A Bal: 84
 

 Perf: N/A Bal: 1,721 / 12,234
 

 Perf: N/A 6,804 Apple MacBook Air
 

 (M2) Bal: 1,925 / 8,973
 

 Perf: N/A Bal: 151
 

 Perf: N/A Bal: 1,600 / 7,938
 

 Perf: N/A N/A
 

 One thing I hoped to see from Meteor Lake was improved efficiency. So far, that hasn’t been the case with many laptops I’ve reviewed — but the Zenbook 14 Q425 is a step in the right direction.
 

 The Zenbook benefits from a very large 75-watt-hour battery, which is a healthy capacity for a 14-inch laptop. While it has an OLED display, it’s also “just” FHD+ resolution, whereas some of its other midrange laptops have higher-res 2.8K panels. In our web-browsing test, which plays through a list of complex websites, it performed very well at roughly 12.5 hours. That’s well above the class average and competes strongly against AMD’s more efficient chips. And when looping our test video, the Zenbook 14 Q425 lasted for an impressive 18 hours.
 

 That’s much better than the other Meteor Lake machines in the comparison group, including other Zenbooks, and it’s only significantly behind the industry-leading MacBook Air. You’ll get a full day’s work in productivity workflows and the usual web browsing, media consumption, and email tasks. That’s more like it.
 

 Web browsing Video Asus Zenbook 14 Q425
 

 (Core Ultra 7 155H) 12 hours, 25 minutes 18 hours, 1 minute Lenovo ThinkPad X1 Carbon Gen 12
 

 (Core Ultra 7 155H) 7 hours, 4 minutes 10 hours 30 minutes Asus Zenbook 14 OLED 2024
 

 (Core Ultra 7 155H) 7 hours, 9 minutes 14 hours, 22 minutes Asus Zenbook 14X OLED
 

 (Core i7-13700H) 8 hours, 2 minutes 10 hours, 49 minutes HP Spectre x360 14
 

 (Core Ultra 7 155H) 8 hours, 6 minutes 13 hours, 3 minutes Asus Zenbook 14 OLED 2023
 

 (Ryzen 5 7530U) 12 hours, 13 minutes 17 hours, 19 minutes Lenovo Yoga 9i Gen 8
 

 (Core i7-1360P) 7 hours, 41 minutes 13 hours, 25 minutes Apple MacBook Air
 

 (Apple M2) 17 hours, 59 minutes 21 hours, 9 minutes
 

 Display
 

 Asus has been a leader in pushing OLED displays to lower-priced laptops, and that’s what we see here. However, some other 14-inch Zenbooks have had 2.8K (2880 x 1800) displays that are sharper than the Zenbook 14 Q425’s FHD+ (1920 x 1200) panel. And this one is limited to 60Hz, when the industry is shifting to 120Hz and faster.
 

 However, I found the Zenbook 14 Q425 to sport a very nice display. I noticed some pixels while staring at text, but most people wouldn’t. According to my colorimeter, its colors were excellent at 100% of sRGB, 97% of AdobeRGB, and 100% of DCI-P3, with accuracy at a Delta-E of 0.90 (less than 1.0 is excellent). The contrast was also excellent, as usual, with inky blacks, and there’s enough brightness at 361 nits for anything but the best high dynamic range (HDR) performance.
 

 I would have preferred a 120Hz refresh rate, but otherwise, this is an excellent display that will please productivity users and creators. The lower resolution and slower refresh rate likely contribute to the Zenbook 14 Q425’s great battery life, making them net benefits for most people.
 

 The audio is provided by a pair of downward-firing “Super-linear” speakers that Asus says increase the diaphragm’s amplitude by 50% and volume by 2.25 times. They definitely get loud, but at full volume, there was considerable distortion and highs were way too bright. It sounded a lot better at around 50% volume, where distortion disappeared, while still being loud enough. The bass was even able to make an appearance, and dialogue sounded snappy. Now, the audio didn’t match the excellent system in the MacBook Pro, but it was certainly enjoyable for streaming YouTube and Netflix, which surprised me.
 

 Not the best Asus option, but still very good
 

 The Zenbook 14 Q425 is similar to some other Asus 14-inch laptops, but it’s not identical. It’s less expensive than the company’s other recent models and cuts a corner in display resolution.
 

 But it shares the typical Asus build quality, has a very good keyboard and touchpad, and its battery life matches its excellent performance. If you’re looking for a 14-inch laptop that won’t break the bank, the Zenbook 14 Q425 comes recommended.
 

 Editors' Recommendations",General,Relevant,Irrelevant,
Citizen Celebrates 100 Years Of Watchmaking With A Limited-Edition Pocket Watch,https://www.ablogtowatch.com/citizen-celebrates-100-years-of-watchmaking-with-a-limited-edition-pocket-watch/,"Sponsored post presented on aBlogtoWatch for advertiser
 

 The Citizen of today may be best known for its pioneering use of technologies such as Eco-Drive, Super Titanium, and Atomic Timekeeping, but back in 1924, when the first Citizen watch was produced, the brand began with a modest hand-winding pocket watch meant to be cherished and enjoyed by all. To celebrate a century of watchmaking, Citizen just proudly announced a modern recreation of its first watch in the form of the 100th Anniversary of the First Citizen Watch Special Limited-Edition Pocket Watch.
 

 Advertising Message
 

 In 1868, the Edo period ended, along with the era of the samurai, and Japan became a constitutional monarchy, ushering in the Meiji era (1868-1912) and with it, an age of industrialization and technological advancement. By the 1920s, various industries, including the electric power industry, were flourishing. Pocket watches imported from overseas were widespread, as global trade soared and citizens embraced new fashions and technology from around the world. Against this backdrop, Kamekichi Yamazaki, who ran a precious metals store in Ginza, became aware of the mass production of American pocket watches during an overseas inspection. He decided to create domestic watches in Japan and train Japanese watchmakers by establishing the Shokosha Watch Research Institute in 1918. The goal was to create Japanese watches that would rival and surpass the imports.
 

 The watch that resulted was a white-dialed, hand-wound caliber 16 pocket watch. Clean, simple, and elegant, it was designed to be worn and loved by everyone. Yet, this was a watch without a name. The Shokosha Watch Research Institute reached out to Tokyo Mayor Count Shinpei Goto and asked him to suggest a name for the watch. He put forth the name “Citizen” with the idea that citizens from Japan and around the world would use and cherish the watches they produced. A few short years later, in 1930, Citizen Watch Company would adopt that name and spirit for the brand itself.
 

 In celebrating 100 years since the launch of that original timepiece, Citizen is creating a limited run of just 100 pocket watches to usher in the next century of the brand. The anniversary pocket watch pays its respects to the forebear while showcasing advancements made over the past century, bridging the past and present, and ushering in the future.
 

 Advertising Message
 

 Citizen is renowned for its use of titanium in horology. Titanium is an ideal material for watchmaking, being lightweight, corrosion-resistant, and hypoallergenic. Though certainly not the only brand to embrace titanium, few, if any, brands have innovated on the material to the same extent. It’s fitting, then, that this limited-edition pocket watch features a titanium case, fitted front and back with anti-reflective-coated sapphire glass.
 

 The case measures in at 43.5mm in diameter and just 13.4mm in thickness — a perfect size for slipping into your pocket and holding in your hand. There’s a tactile pleasure in interacting with a pocket watch that can’t be replicated with a wristwatch, part of what made pocket watches so treasured at the height of their popularity. The dial on the anniversary pocket watch stays faithful to the original with elegant numerals, a broad and legible sub-seconds register at 6 o’clock, and blued hands. Even the Citizen text at 12 o’clock stays true to the original. Where the new pocket watch deviates, however, is on the white of the dial. Here, Citizen created an electroformed dial finished with clear coating and polishing to produce a dynamic and three-dimensional texture.
 

 The dial on the pocket watch is certainly gorgeous, and the movement powering the piece is equally stunning. Using a free-sprung balance wheel that brings this pocket watch into the modern era, the hand-wound movement provides an accuracy of -3/+5 seconds/day and a power reserve of approximately 55 hours. The movement is finished with gentle curves and features Côtes de Genève and diamond-cut edges. The difficult decision will be choosing which side to admire first. Before the watch is delivered, each goes through 17 days of in-house testing and inspection, including regulation in six positions and three temperatures. Each watch is then provided with an inspection certificate.
 

 The Citizen Watch Special Limited-Edition Pocket Watch is limited to only 100 pieces and priced at $9,000 USD; each comes with a limited-edition number engraved on the case. Each watch also includes a pure Jaapanese silk braided cord that’s dyed an indigo charcoal color created especially for this watch. To learn more about Citizen and its anniversary pocket watch, please visit the brand’s website.
 

 Sponsored Posts are a form of advertising that allows sponsors to share useful news, messages, and offers to aBlogtoWatch readers in a way traditional display advertising is often not best suited to. All Sponsored Posts are subject to editorial guidelines with the intent that they offer readers useful news, promotions, or stories. The viewpoints and opinions expressed in Sponsored Posts are those of the advertiser and not necessarily those of aBlogtoWatch or its writers.",General,Relevant,Irrelevant,
NTSB investigates fatal crash possibly involving partially automated driving system—and this time Tesla Autopilot isn't involved,https://fortune.com/2024/03/17/ntsb-fatal-crash-automated-driving-system-ford-electric-vehicle-not-tesla/,"The National Transportation Safety Board is investigating a fatal crash in San Antonio, Texas, involving a Ford electric vehicle that may have been using a partially automated driving system.
 

 The agency said in a statement Friday that a team of investigators from its Office of Highway Safety will travel to Texas and work with police on the Feb. 24 crash on Interstate 10.
 

 The NTSB said that preliminary information shows a Ford Mustang Mach-E SUV equipped with the company’s partially automated driving system collided with the rear of a Honda CR-V that was stopped in one of the highway lanes.
 

 Television station KSAT reported that the Mach-E driver told police the Honda was stopped in the middle lane with no lights on before the crash around 9:50 p.m. The 56-year-old driver of the CR-V was killed.
 

 “NTSB is investigating this fatal crash due to its continued interest in advanced driver assistance systems and how vehicle operators interact with these technologies,” the agency statement said.
 

 Ford’s Blue Cruise system allows drivers to take their hands off the steering wheel while it handles steering, braking and acceleration on highways. The company says the system isn’t fully autonomous and it monitors drivers to make sure they pay attention to the road. It operates on 97% of controlled access highways in the U.S. and Canada, Ford says.
 

 There are no fully autonomous vehicles for sale to the public in the U.S.
 

 The NTSB said investigators will travel to San Antonio to examine wreckage, collect information about the crash scene and look into the events leading up to the collision. A preliminary report is expected within 30 days.
 

 In a statement, Ford said it is researching the crash and the facts are not yet clear. The company expressed sympathy to those involved and said it reported the crash to the National Highway Traffic Safety Administration.
 

 Both NHTSA and the NTSB have investigated multiple previous crashes involving partially automated driving systems, most involving Tesla’s Autopilot. In past investigations, the NTSB has examined how the partially automated system functioned.",General,Relevant,Irrelevant,
A closer look at Rabbit R1 and Humane Ai Pin wearables,https://www.geeky-gadgets.com/ai-wearables/,"In the rapidly evolving world of AI, two new devices have been generating buzz: the Rabbit R1 and the Humane AI Pin. These AI assistant devices are set to ship soon, and their creators have made some impressive claims about their capabilities. However, upon closer inspection, there are reasons to be skeptical about whether these devices will live up to the hype. In the video below Dave2D takes a closer look at the to companies and the new AI wearable devices.
 

 What Do These Devices Claim to Do?
 

 According to their marketing, the Rabbit R1 and Humane AI Pin aim to simplify various tasks through voice commands and AI assistance. Some examples include:
 

 Booking an entire family trip to Europe with just two or three voice commands
 

 Calculating the calories or protein content in a handful of almonds by simply showing the device the food
 

 Replacing your smartphone for many tasks, without the need to launch apps
 

 Assisting with repairs, live translations, and more
 

 Here are some other articles you may find of interest on the subject of Rabbit R1 AI wearable :
 

 AI Wearables
 

 As technology continues to advance, AI wearables are poised to revolutionize the way we interact with our surroundings and manage our daily lives. These devices, equipped with artificial intelligence and machine learning capabilities, have the potential to seamlessly integrate into our routines and provide us with personalized assistance, insights, and support.
 

 In the future, AI wearables could help us in numerous ways:
 

 Health and Wellness: AI wearables may continuously monitor our vital signs, activity levels, and sleep patterns, providing real-time feedback and recommendations to improve our overall well-being. They could alert us to potential health issues and even communicate with healthcare providers when necessary.
 

 Productivity and Time Management: With the ability to learn our habits and preferences, AI wearables could optimize our schedules, remind us of important tasks, and help us prioritize our responsibilities. They may even automate certain tasks, freeing up more time for us to focus on what matters most.
 

 Communication and Translation: AI wearables could break down language barriers by offering real-time translations during conversations or while traveling abroad. They may also enhance our communication skills by providing feedback on our tone, body language, and social cues.
 

 Navigation and Safety: By leveraging GPS and other location-based technologies, AI wearables could provide us with turn-by-turn navigation, helping us find our way in unfamiliar places. They may also alert us to potential safety hazards or emergency situations, such as accidents or natural disasters.
 

 Personalized Learning and Skill Development: AI wearables could adapt to our individual learning styles and provide tailored educational content, making it easier for us to acquire new knowledge and skills. They may even coach us through complex tasks or guide us in developing new habits.
 

 As AI wearables become more sophisticated and integrated into our lives, they have the potential to transform the way we learn, work, and interact with the world around us. However, it’s crucial to address concerns related to privacy, security, and ethical use of these devices as they become more prevalent.
 

 Responsible Development
 

 While the future of AI wearables is promising, it’s essential for manufacturers, developers, and users alike to prioritize responsible development and adoption of these technologies. This includes:
 

 Ensuring the privacy and security of user data
 

 Developing robust ethical frameworks to guide the creation and use of AI wearables
 

 Promoting transparency and user control over how these devices collect and utilize personal information
 

 Collaborating with experts from various fields, including healthcare, education, and social sciences, to ensure that AI wearables are designed to benefit individuals and society as a whole
 

 As we look towards a future increasingly shaped by AI wearables, it’s crucial to approach these technologies with a balance of excitement and caution. By prioritizing responsible development and adoption, we can harness the power of AI wearables to enhance our lives while mitigating potential risks and challenges.
 

 Hardware and Pricing
 

 The Rabbit R1, priced at $200, boasts a sleek design inspired by Teenage Engineering. It features a small screen, camera, analog scroll wheel, speaker, and button. Despite not yet being available for hands-on testing, the R1 has reportedly sold over 100,000 units on pre-order.
 

 In contrast, the Humane AI Pin comes with a heftier price tag of $700, plus a $25 monthly subscription. Instead of a screen, it uses a projector to display the UI onto the user’s hand. The AI Pin is designed to attach to clothing rather than be handheld.
 

 Concerns and Limitations
 

 While the promise of these AI assistant devices is enticing, there are several concerns and limitations to consider:
 

 Voice commands may not be suitable for complex tasks that require fine-tuning and real-time adjustments based on visual cues and options.
 

 Demonstrating the devices’ capabilities through edited videos that hide response times and latency raises questions about their actual performance.
 

 The Humane AI Pin’s laser projection feature may be more of a gimmick than a practical solution, as evidenced by the lack of similar standalone products in the market.
 

 The Rabbit R1’s large action model (LAM) feature, which learns from user interactions to perform actions, may not be fully functional at launch due to insufficient training data from the initial user base.
 

 AI hallucinations and errors could lead to more severe consequences when dealing with action models that can make purchases or bookings, compared to simple image generation mistakes.
 

 The Need for Realistic Expectations
 

 While it’s essential to recognize the potential of these AI assistant devices, it’s equally important to maintain realistic expectations. The marketing claims made by the companies behind the Rabbit R1 and Humane AI Pin may be overly optimistic, and consumers should be aware of the current limitations of AI technology.
 

 As with any new technology, it’s crucial for companies to be transparent about the capabilities and limitations of their products. Overpromising and under-delivering can lead to disappointment and mistrust among consumers.
 

 The Future of AI Assistants
 

 Despite the concerns surrounding the Rabbit R1 and Humane AI Pin, it’s important to acknowledge that the development of AI assistants is still in its early stages. As technology advances and more companies experiment with new ideas, we can expect to see more refined and capable AI assistant devices in the future.
 

 The journey towards truly intelligent and reliable AI assistants will likely involve many failures and iterations. However, the lessons learned from these experiences will ultimately contribute to the creation of better products that genuinely enhance our daily lives.
 

 

 

 Latest Geeky Gadgets Deals
 

 Some of our articles include affiliate links. If you buy something through one of these links, Geeky Gadgets may earn an affiliate commission. Learn about our Disclosure Policy",AI,Relevant,Relevant,
Navigating The Ethical Terrain: The Role Of AI In Social Care,https://www.ponoko.com/blog/ponoko/navigating-the-ethical-terrain-the-role-of-ai-in-social-care/,"In the realm of social care, where the demand for assistance outweighs the available workforce, technology has emerged as a potential solution. However, recent findings from a pilot study conducted by researchers at the University of Oxford raise concerns about the ethical implications of incorporating unregulated AI bots into care practices. What are the potential risks associated with unregulated AI bots into social care practices, how do emerging technologies like facial recognition and infrared cameras contribute to the landscape of social care, and as efforts to establish guidelines for responsible AI use in social care intensify, what roles should regulatory bodies like the Care Quality Commission and the Department for Health and Social Care play in ensuring ethical standards are upheld?
 

 Read the full article here
 

 Top Stories This Week
 

 Hardware Business News
 

 China Moves To Pump $27bn Into Semiconductor Industry To Counter The US
 

 Image Source – Flickr
 

 In the intricate geopolitical landscape of the 21st century, the global tech scene has become a battleground where nations vie for dominance and supremacy. Against this backdrop of geopolitical friction and economic competition, China has recently made a bold move to bolster its semiconductor sector with the announcement of a $27 billion chip fund. How does China’s massive investment in its semiconductor industry through the “Big Fund” reflect its determination to achieve technological independence amidst escalating tensions with the US, what are the key challenges China faces in its quest for self-sufficiency in semiconductor manufacturing, and how might the establishment of the “Big Fund” reshape the landscape of the global semiconductor market and impact the ongoing tech war between the US and China?
 

 Read the full article here
 

 Google Restricts Gemini AI Chatbot Election Answers
 

 Image Source – Pixabay
 

 In the ever-evolving landscape of online information, the influence of technology giants on shaping public discourse and safeguarding against misinformation has become increasingly paramount. Alphabet’s Google, a search engine titan, has taken proactive measures to mitigate the spread of election-related misinformation by announcing restrictions on queries that users can pose to its Gemini AI chatbot. How do Google’s restrictions on election-related queries for its Gemini chatbot reflect the company’s commitment to combating misinformation, in what ways have advancements in generative AI technology heightened concerns over the spread of misinformation, and how are other major technology companies responding to the challenges posed by election-related misinformation?
 

 Read the full article here
 

 Combatting Counterfeit Electronic Components: Challenges And Solutions
 

 Image Source – Pixabay
 

 The risk of procuring counterfeit electronic components surged during the Covid-19 pandemic peak as shortages of essential components, particularly integrated circuits, prompted OEMs to turn to non-authorized resellers. This crisis exacerbated concerns within the industry, with a recent survey revealing that 87 percent of experts considered counterfeit components a significant issue. As the industry braces for future challenges, start-ups are leveraging optical technology and AI to combat counterfeiting risks. How did the Covid-19 pandemic exacerbate the risk of counterfeit electronic components, in what ways are start-ups utilizing optical technology and AI to address the proliferation of counterfeit electronic components, and what impact are these solutions expected to have on the industry?
 

 Read the full article here
 

 Hardware Engineering News
 

 Hand Hygiene Innovation: Fighting Germs in Fast-Food Chains
 

 Image Source – PathSpot
 

 In the relentless battle against germs and foodborne illnesses, fast-food chains are turning to innovative solutions to ensure hygiene standards are met. Enter the Handscanner, a product developed by PathSpot, a tech start-up based in New York. This device, akin to a lie detector at the sink, is revolutionizing hand hygiene practices in food service establishments. How does the Handscanner by PathSpot address the issue of inadequate hand hygiene among food service workers, what are the potential health consequences of inadequate hand hygiene in food service establishments, and how does the implementation of the Handscanner contribute to mitigating these risks?
 

 Read the full article here
 

 Unveiling the Future Of Transistors: Innovations And Revolutions In Semiconductor Manufacturing
 

 Image Source – Pixabay
 

 As we stand on the brink of a paradigm shift unseen in the market for decades, the brightest minds worldwide dedicate themselves to unravelling the mysteries of crafting transistors at the atomic level, seemingly defying the laws of physics. In this article, embark on a journey into the realm of semiconductor technology, and delve into the fascinating world of future transistors where breakthroughs promise unprecedented changes in chip structure and production methods. How do GAAFET transistors represent a significant departure from previous transistor geometries, what challenges do semiconductor manufacturers face in implementing this technology, and what advantages does the Back Side Power Delivery Network (BSPDN) offer in terms of transistor placement and power distribution?
 

 Read the full article here
 

 Dell Tackles E-Waste With Giant QR Code Installation At SXSW
 

 Image Source – Dell Technologies
 

 In an era marked by the relentless expansion of electronic consumption, a parallel surge in electronic waste poses a critical environmental challenge, with staggering implications for sustainability. Amidst this backdrop, Dell, a titan in consumer electronics, has embarked on a initiative aimed at raising awareness about the e-waste crisis and promoting responsible recycling practices. This innovative outdoor campaign debuts at the prestigious 28th annual SXSW, a convergence of technology and music in Austin, Texas, this month, signalling a pivotal moment in the fight against e-waste. How does Dell’s outdoor campaign at SXSW leverage innovative tactics to draw attention to the e-waste crisis and promote responsible recycling, what role does the use of a giant QR code play in facilitating the recycling process for SXSW attendees, and in what ways can other industry leaders and stakeholders learn from Dell’s approach to tackling the e-waste challenge?
 

 Read the full article here
 

 Hardware R&D News
 

 A New Sensor Detects Harmful “Forever Chemicals” In Drinking Water
 

 Image Source – Pixabay
 

 In a new development, MIT chemists have engineered a cutting-edge sensor capable of detecting minuscule quantities of perfluoroalkyl and polyfluoroalkyl substances (PFAS), ubiquitous chemicals found in everyday consumer products such as food packaging and non-stick cookware. These compounds, often referred to as “forever chemicals,” pose significant health risks due to their persistence in the environment and have been linked to various adverse health effects, including cancer and reproductive issues. How does MIT’s sensor technology address the pressing need for more accessible and efficient methods of detecting PFAS chemicals in drinking water and industrial settings, what implications does this breakthrough hold for public health and environmental conservation efforts, and what are the next steps in MIT’s research agenda to further enhance the sensor’s sensitivity and applicability?
 

 Read the full article here
 

 Revolutionizing Electronics: The Rise Of Biodegradable Papertronics
 

 Image Source – Binghamton University
 

 In an era marked by the pervasive integration of smart technologies, the demand for sustainable electronics has become paramount. As the Internet of Things continues to expand its reach, encompassing diverse applications ranging from food packaging to agriculture and healthcare, the urgency to develop biodegradable electronics has intensified. How do Professor Choi’s integrated papertronics address the critical challenges posed by traditional electronics manufacturing methods, what key technological innovations distinguish Choi’s papertronics from previous iterations of biodegradable electronics, and how do these advancements enhance the functionality and applicability of paper-based circuits?
 

 Read the full article here
 

 Open-Source Hardware News
 

 Leaked Docs Hint Google May Use SiFive RISC-V Cores In Next-Gen TPUs
 

 Image Source – Pixabay
 

 Following a challenging year in 2023, SiFive, a leading designer of RISC-V chips, anticipates a positive turnaround driven by the burgeoning demand for artificial intelligence technologies in 2024, along with the introduction of new AI chips. While specific details regarding the chip family remain undisclosed, indications suggest a potential expansion of SiFive’s partnership with Google, possibly involving the provision of processor cores for the search giant’s tensor processing units. How significant is the role of AI in driving SiFive’s projected revenue growth for 2024, what factors contribute to the company’s strategic focus on developing processors tailored specifically for AI workloads, and what implications does SiFive’s collaboration with Google hold for the broader landscape of AI infrastructure and cloud computing?
 

 Read the full article here",AI,Relevant,Irrelevant,
Army raises elite unit to work on critical technologies having military applications,https://economictimes.indiatimes.com/news/defence/army-raises-elite-unit-to-work-on-critical-technologies-having-military-applications/articleshow/108588068.cms,"(You can now subscribe to our
 

 (You can now subscribe to our Economic Times WhatsApp channel
 

 The Indian Army has initiated a significant development in its technological capabilities by establishing the Signals Technology Evaluation and Adaptation Group ( STEAG ). This elite unit is dedicated to researching and evaluating futuristic communication technologies like 6G , artificial intelligence ( AI ), machine learning, and quantum computing for military applications.""It will be a premier organisation, the first of its kind equipped with the capability to harness niche technology, leverage cutting-edge solutions and identify suitable cases for defence applications by fostering collaboration with academia and industry,"" one of the officials said.STEAG's primary objective is to nurture technologies across wired and wireless systems, covering a wide spectrum of domains including electronic exchanges, mobile communications, software-defined radios, electronic warfare systems, and more. Officials within the Army highlight the importance of STEAG in developing cutting-edge solutions and fostering collaboration with academia and industry to identify suitable defense applications.The elite unit will focus on all upcoming critical technology domains including electronic exchanges, mobile communications, software defined radios, electronic warfare systems, 5G and 6G networks, quantum technologies, AI, machine learning, etc., the official said.The hi-tech unit will carry out technical scouting, evaluation, development, management of core ICT solutions, and provide user interface support by maintenance and upgradation of contemporary technologies available in the environment, the official added.According to Army officials, STEAG will focus on critical technology domains such as 5G and 6G networks, quantum technologies, AI, and machine learning. The unit will conduct technical scouting, evaluation, development, and management of core ICT solutions while providing user interface support through the maintenance and upgrade of contemporary technologies.""Aligning itself with the tenets of Atmanirbhar Bharat and Start-Up India, STEAG will help bridge the divide between the armed forces on the one hand and industry and academia on the other,"" the official said on condition of anonymity.The new Centre of Excellence is expected to be a game changer in fostering self-reliance in high-end communication technologies, which have thus far been a monopoly of select countries with advanced economies and research ecosystems, he said.The establishment of STEAG underscores the Army's commitment to acquiring new technologies in response to the evolving nature of warfare. Army Chief Gen Manoj Pande has emphasized the importance of staying ahead in technology to maintain a competitive edge on the battlefield. By aligning with the principles of Atmanirbhar Bharat (Self-Reliant India) and Start-Up India, STEAG aims to bridge the gap between the armed forces, industry, and academia.Officials believe that STEAG will play a crucial role in fostering self-reliance in high-end communication technologies, which have traditionally been dominated by countries with advanced economies and research ecosystems. The establishment of this Center of Excellence is expected to be a game-changer in India's quest for technological self-sufficiency.In the context of modern warfare, effective communication is paramount for operational success. Army officials emphasize that the side with superior communication technologies and the ability to connect various constituents for information sharing will have a strategic advantage. STEAG's establishment reflects the Army's commitment to imbibe advancements in technology to enhance its capabilities in the digital domain and ensure seamless communication support during operations.""In the fast-evolving technologies for the battlefield, the side with better communication technologies and the ability to connect the various constituents for information sharing will have an edge over its adversary,"" another official said.He said modern warfare necessitates the induction of new equipment to provide seamless communication support to units and formations during operations.""To imbibe such advancements in technology, the Indian Army has raised this groundbreaking technology-oriented unit STEAG which will bolster its capabilities in the digital domain,"" he added.(With inputs from PTI)",Communications Technologies,Relevant,Relevant,
New features of AutoGen AI multi-agent framework,https://www.geeky-gadgets.com/autogen-features/,"AutoGen, a groundbreaking multi-agent framework developed by Microsoft Research AI Frontiers, has been making significant strides in the AI community since its release in October 2022. Driven by the vision of empowering developers to create cutting-edge AI applications, AutoGen has quickly gained recognition for its flexibility, modularity, and simplicity. Despite its relatively short existence, the framework has already garnered widespread adoption from companies, organizations, and universities worldwide, showcasing its immense potential in shaping the future of AI development.
 

 AutoGen AI
 

 One of the most compelling aspects of AutoGen is its ability to transform various industries by enabling the development of powerful AI solutions. In the pharmaceutical sector, for example, AutoGen is helping to break down barriers to clinical data analytics, allowing a wider community of researchers and practitioners to derive meaningful insights while maintaining strict data security standards. This is particularly crucial when dealing with sensitive information, such as personally identifiable information (PII), which cannot be shared with external services like ChatGPT.
 

 The versatility of AutoGen has caught the attention of numerous industry verticals, with hundreds of example applications showcasing its diverse use cases. Some organizations have even adopted AutoGen as the backbone for their own agent platforms, while others leverage it for research, investment, and innovative applications involving multiple agents. The framework’s adaptability and robustness have made it an invaluable tool for businesses and institutions seeking to harness the power of AI.
 

 Here are some other articles you may find of interest on the subject of AutoGen AI Multi-Agent Framework :
 

 AutoGen’s Performance on the GAIA Benchmark
 

 AutoGen’s capabilities were recently put to the test on the challenging GAIA Benchmark, which evaluates a model’s ability to answer simple questions by retrieving information from sources like Wikipedia. Remarkably, AutoGen achieved the highest accuracy across all three difficulty levels on the leaderboard, surpassing several other well-known models. This outstanding performance demonstrates AutoGen’s proficiency in solving context-based tasks and highlights its potential for further growth and development.
 

 The success on the GAIA Benchmark is just one example of AutoGen’s ongoing efforts to tackle open, hard questions in AI development. The team behind AutoGen is dedicated to designing optimal multi-agent workflows, enabling scalability, ensuring safety, and enhancing human agency in AI systems. By continuously pushing the boundaries of what is possible, AutoGen is setting the stage for a new era of AI innovation.
 

 New AutoGen Features and Ongoing Research
 

 As AutoGen continues to evolve, the development team is working tirelessly to introduce new features and improvements at a rapid pace. Some of the exciting developments in the pipeline include:
 

 Evaluation tools: AutoGen is developing sophisticated agent-based evaluation and benchmarking tools to help users assess the performance of their multi-agent workflows.
 

 Improved interface: The team is focusing on further simplifying the interface, making it even more intuitive and user-friendly for developers to build agent applications.
 

 AutoGen Studio: This low-code or no-code solution will enable users to create agents, design workflows, and perform tasks without requiring extensive coding knowledge.
 

 Finite State Machine (FSM) support: Users will be able to create teams of agents and direct responses between them, facilitating the development of more complex and dynamic workflows.
 

 Learning capability: Agents will have the ability to remember teachings from users or other agents long-term, promoting continuous improvement and adaptation over time.
 

 Integration with new technologies: AutoGen is being integrated with cutting-edge technologies like OpenAI’s assistant and multimodality, expanding its capabilities and use cases.
 

 Custom model support: The framework aims to simplify the process of connecting to local, open-source language models, reducing reliance on external services and ensuring data privacy.
 

 The Future of AutoGen AI
 

 AutoGen’s success can be attributed to its passionate and active community of developers, researchers, and AI practitioners. The community’s enthusiasm and support have been instrumental in AutoGen’s rapid growth and evolution. The framework has received numerous awards and recognition, including being selected by “The Sequence” as one of the top favorite AI papers in 2023.
 

 As AutoGen continues to empower the AI community, it is poised to play a significant role in shaping the future of AI development. By lowering the barriers to entry and providing powerful tools for building agent applications, AutoGen is democratizing AI and enabling developers from diverse backgrounds to create innovative solutions. The framework’s commitment to scalability, safety, and human agency in AI systems ensures that its impact will be felt across various industries and domains.
 

 With its rapid development, growing community support, and dedication to pushing the boundaries of AI, AutoGen is set to revolutionize the way we approach AI development. As more developers, researchers, and organizations embrace the power of AutoGen, we can expect to see a surge in groundbreaking AI applications that transform industries, solve complex problems, and drive innovation forward. The future of AI is bright, and AutoGen is leading the charge.
 

 

 

 Latest Geeky Gadgets Deals
 

 Some of our articles include affiliate links. If you buy something through one of these links, Geeky Gadgets may earn an affiliate commission. Learn about our Disclosure Policy",AI,Relevant,Relevant,
4 ways AI is contributing to bias in the workplace,https://www.zdnet.com/article/4-ways-ai-is-contributing-to-bias-in-the-workplace/,"ZDNET Recommends': What exactly does it mean?
 

 ZDNET's recommendations are based on many hours of testing, research, and comparison shopping. We gather data from the best available sources, including vendor and retailer listings as well as other relevant and independent reviews sites. And we pore over customer reviews to find out what matters to real people who already own and use the products and services we’re assessing.
 

 When you click through from our site to a retailer and buy a product or service, we may earn affiliate commissions. This helps support our work, but does not affect what we cover or how, and it does not affect the price you pay. Neither ZDNET nor the author are compensated for these independent reviews. Indeed, we follow strict guidelines that ensure our editorial content is never influenced by advertisers.
 

 ZDNET's editorial team writes on behalf of you, our reader. Our goal is to deliver the most accurate information and the most knowledgeable advice possible in order to help you make smarter buying decisions on tech gear and a wide array of products and services. Our editors thoroughly review and fact-check every article to ensure that our content meets the highest standards. If we have made an error or published misleading information, we will correct or clarify the article. If you see inaccuracies in our content, please report the mistake via this form.",General,Relevant,Irrelevant,
Is synthetic data the solution to data privacy challenges?,https://betanews.com/2024/03/17/is-synthetic-data-the-solution-to-data-privacy-challenges/,"Synthetic data is artificial material that was not generated by natural life events. As such, it can be created by computer programs and AI tools that use different techniques, with generative adversarial networks and diffusion models being among the most popular and effective today. Synthetic data may come in many forms, but images and textual information are currently the most feasible options.
 

 If you are interested in AI and ML developments, you have probably heard the term already -- “sanitized” synthetic data is a recent hype in the AI training field that, it is believed, might solve pressing data privacy and ownership challenges posed by real data. However, it all sounds like sunshine and rainbows only until you stop and consider the fact that AI algorithms used to generate synthetic data still need to be trained on real data -- the very obstacle they offer to remove.
 

 So, is synthetic data an answer to recent AI sector challenges or just a temporary hype that will allow some tech startups to earn a billion or two and then dwindle? As often, the answer lies somewhere in the middle.
 

 The synthetic data market on the rise
 

 Training the algorithms behind self-driving cars (autonomous vehicles, AV) was the first area that started to rely heavily on artificially generated data. AV developers encounter many hypothetical situations that the algorithm has to learn and consider -- combinations of weather and traffic patterns, vehicle speed, etc. Real data simply does not exist in such abundance and would take hundreds of years of traffic history to collect. As such, synthetic data allows researchers to go beyond the real world’s constraints and simulate events regardless of their real-life representation.
 

 In the last few years, however, the market demand has grown exponentially. Recent studies show that 60 percent of all data used for AI will be synthetic rather than real by 2024. The synthetic data market is projected to reach USD 3,400 million by 2031, and the main driver behind this growth is simple business calculations.
 

 Today, AI companies spend millions of dollars annually just to get their data labeled. Data labeling isn’t only expensive -- it is time-consuming and prone to human errors and biases. Contrary to real data, where every data point (say, a picture) has to be painstakingly explained to train ML models, synthetic data comes already labeled, solving probably the biggest bottleneck in the current AI/ML market.
 

 Moreover, synthetic data is usually generated faster than real data is collected and offers new opportunities in complex fields where real data is scarce or nonexistent, such as climate future forecasting. Finally, synthetic data promises to solve yet another painful constraint for data gatherers -- privacy-imposed limitations.
 

 Privacy vs. innovation
 

 Last year, major AI firms, such as Google, Microsoft, and OpenAI, encountered a good deal of legal issues due to civil lawsuits claiming user data had been exploited without consent for training generative AI algorithms behind Midjourney, Bard, ChatGPT, and other major commercial releases.
 

 It is unlikely that AI firms have been maliciously trespassing on people’s fundamental right to privacy, especially keeping in mind that data used for AI/ML training is usually aggregated. However, data collection at scale is itself a novel phenomenon and, unfortunately, still loosely regulated. This creates a lot of challenges for businesses and innovative technologies.
 

 The real data challenge
 

 In some cases, when collected at an enormous scale, real data might accidentally include personal information, creating legal consequences for those who collected it, even if they didn’t have an intention of doing it. It is more important, though, that sometimes, personal data might be vital for training AI systems, for example, in health diagnostics. Financial services also use customer data for software testing, AI-driven AML and fraud detection, and predicting market trends.
 

 In both health and financial domains, personal data is highly sensitive. Moreover, common data anonymization techniques might not be as effective if numerous data points were gathered for the same person. Anonymization can also introduce inaccuracies and errors.
 

 But here comes synthetic data -- pre-labeled and “sanitized,” meaning it doesn’t entail personal information. It mimics real data but does not clone it, using a base dataset and then building an artificial representation upon this real data. As such, synthetic data offers AI developers a clear way out of the “wild wild West” situation in which they have found themselves due to concerns over data privacy. However, that way out is not without its own roadblocks.
 

 Privacy vs. accuracy
 

 To understand the roadblocks, one needs to consider the main synthetic data creation techniques. Different ones exist, but AI-driven models are the most effective. For quality synthetic data generation at scale, developers usually use neural networks. Today’s key technology is generative adversarial networks, or GANs. It has a pretty simple underlying principle.
 

 There are two neural networks -- the generator and the discriminator. The first one gets a set of real data (images are the most common example of this) and begins to generate similar artificial representations. The second one is fed with a varied dataset containing both real and generated images and has to identify the fake ones. Both models work in an endless cycle, with one trying to deceive the other and the latter trying to “sort” things out, which results in increasing quality, diversity, and hyper-realism of the artificial data.
 

 Another popular technique -- diffusion models -- is based on denoising corrupted real data. The model first distorts the image and then tries to reverse the process. Once trained, these models can produce good-quality audio and visual synthetic data. It is important to note that the rapid advancement of large language models (LLMs) today presents a novel opportunity to produce synthetic data at an even larger scale and with greater originality.
 

 The vicious circle
 

 However, as one might already suspect, all these AI-based techniques have the same shortcoming -- they need to be trained on real data and constantly synced with it, requiring developers to gather large amounts of diverse, multifaceted training data. Otherwise, neural networks start degrading, which results in errors, hallucinations, and a general lack of accuracy.
 

 Moreover, synthetic data might exacerbate the challenges associated with data fairness, quality, and accuracy. Rather than offering an accurate reflection of reality, synthetic datasets might accentuate specific patterns and biases inherent in the underlying datasets, potentially exacerbating existing disparities.
 

 Unlike real data, which undergoes constant evolution, synthetic datasets remain static representations akin to frozen snapshots. AI systems that are based on synthetic datasets might have a tendency to move towards closed epistemic systems where the abundance of ideas, theories, and other representations of the real world will slowly vanish.
 

 Re-imagining what’s real
 

 This gloomy dystopian scenario doesn’t mean that synthetic data can’t have a positive impact. MIT research demonstrates that, in some cases, AI algorithms trained on synthetic data might perform even better than those trained on the real stuff. Most probably, this result has been achieved because synthetic data presents less noise or “scene-object bias,” as the researchers call it.
 

 However, the world isn’t sleek; it is noisy, and to ensure the best representation and accuracy, most AI developers will still have to work with real and artificial data simultaneously. It is the combination of both that will probably bring in the biggest breakthroughs -- synthetic data can positively enrich the overall size of the AI training material, help developers move beyond real-world representations, and imagine possible outliers and scenarios that might await us in the future.
 

 As for privacy, synthetic data might solve the issue up to a point -- for example, it can replace specific data values that bear a high risk if disclosed. This offers an easier way through in such areas as healthcare and genomic research. Even so, to avoid critical inaccuracies, synthetic data will still have to be periodically synced with updated real-world data. An important issue that is often overlooked is that AI systems trained on synthetic data might suffer from lower consumer trust, especially in sensitive areas like healthcare.
 

 Final thoughts: overcoming data accessibility challenges
 

 One of the biggest positive effects of synthetic data on AI research and development might not be the one related to data privacy challenges but that of data democratization. Data collection at scale is a costly endeavor, further complicated by big tech companies acting as “gatekeepers” and trying to shut down open access to public data.
 

 This painful legal and political issue has been recently highlighted by social media giants lashing out with lawsuits at companies, researchers, and NGOs that gather public web intelligence. Under such circumstances, synthetic data might help level the playing field for smaller companies or startups trying to step into the AI and big data game and circumvent the artificial roadblocks promoted by those aiming to own the internet.
 

 Image Credit: Wayne Williams
 

 Juras Jursenas is Chief Operating Officer at Oxylabs.",AI,Relevant,Relevant,
US SEC fines two investment advisers over AI claims,https://www.channelnewsasia.com/business/us-sec-fines-two-investment-advisers-over-ai-claims-4203246,"WASHINGTON :Two investment advisers have agreed to pay penalties to settle U.S. Securities and Exchange Commission charges that they made false and misleading statements about their use of artificial intelligence (AI), the regulator said on Monday.
 

 Toronto-based Delphia Inc and San Francisco-based Global Predictions Inc, which did not admit or deny the SEC's charges, agreed to pay a combined $400,000 in fines to settle the civil charges related to ""AI washing,"" the SEC said in a statement.
 

 Regulators have been ratcheting up scrutiny on AI. The SEC has repeatedly warned companies about making false statements regarding AI technology. Chair Gary Gensler has reminded companies that they need to ensure that they are disclosing accurate information, especially if they are using artificial intelligence.
 

 Global Predictions in a statement said it had cooperated with the inquiry.
 

 ""Additionally, we have clarified across our marketing how exactly we use AI,"" the statement said.
 

 Delphia did not respond immediately to requests for comment.
 

 The SEC found that from 2019 to 2023 Delphia made false and misleading statements in SEC filings, a press release and on its website over its purported use of AI and machine learning.
 

 Global Predictions made false and misleading claims about AI in 2023 on its website and social media, the SEC said.
 

 ""We’ve seen time and again that when new technologies come along, they can create buzz from investors as well as false claims by those purporting to use those new technologies,"" SEC Division of Enforcement Director Gurbir Grewal said in a statement.
 

 Delphia will pay a $225,000 penalty while Global Predictions will pay $175,000, the SEC said.",AI,Relevant,Relevant,
Blinken tells democracy summit that technology must sustain democratic values,https://www.startribune.com/blinken-tells-democracy-summit-that-technology-must-sustain-democratic-values/600351989/,"SEOUL, South Korea — U.S. Secretary of State Antony Blinken underscored the need to make sure that technologies sustain democratic values, telling a democracy summit on Monday that authoritarian regimes deploy them to undermine democracy and human rights.
 

 Blinken spoke at the ministerial conference of the third Summit for Democracy, a U.S.-led initiative held in Seoul, South Korea, this year.
 

 ''Revitalizing democracy will also require us to shape the technological future, that's inclusive, that's rights respecting, directed at driving progress in people's lives,'' Blinken said.
 

 ''As authoritarian and repressive regimes deploy technologies to undermine democracy and human rights, we need to ensure that technology sustains and supports democratic values and norms,'' he said.
 

 U.S. President Joe Biden first proposed the idea of a democracy summit during his 2020 campaign and has called for the U.S. and like-minded allies to show the world that democracies serve societies better than autocracies.
 

 The Biden administration announced as the summit kicked off that six additional countries were joining an American-led consortium focused on countering the misuse of commercial spyware. Blinken announced that Finland, Germany, Ireland, Japan, Poland and South Korea were joining the group that already included Australia, Canada, Costa Rica, Denmark, France, New Zealand, Norway, Sweden, Switzerland, the United Kingdom, and the U.S.
 

 Concerns about countries using spyware to target activists, diplomats and journalists is a growing worry for the White House. Earlier this month, the U.S. Treasury Department announced that it had sanctioned two people and a Greece-based commercial spyware company headed by a former Israeli military officer that developed, operated and distributed technology used to target U.S. government officials, journalists and policy experts.
 

 Biden administration officials said it marked the first time that the Treasury Department has sanctioned people or entities for the misuse of spyware.
 

 Also Monday, Blinken met South Korean Foreign Minister Cho Tae-yul and President Yoon Suk Yeol for talks on North Korea and the U.S.-South Korea alliance, according to the South Korean government.",General,Relevant,Irrelevant,
A Consultant’s Perspective on Potential EU AI Regulations and Their Impact on the Hospitality Industry,https://www.hospitalitynet.org/opinion/4120939.html,"Executive Summary
 

 The impending EU AI regulations present a dynamic landscape for the hospitality industry. This paper explores the potential impact on compliance, operations, guest experience, and innovation. We aim to equip stakeholders with a forward-looking analysis to navigate this evolving environment. We'll delve into crucial considerations like integrating AI within the regulatory framework, maintaining a competitive edge, and upholding ethical standards.
 

 Introduction
 

 The EU's commitment to responsible AI use, emphasizing safety, transparency, and respect for individual rights, significantly influences the hospitality sector. This industry, a leader in AI adoption for personalization, efficiency, and guest satisfaction, now faces the challenge of aligning its AI strategies with these regulations. Potential impact areas include data protection, operational efficiency, customer interaction, compliance costs, safety protocols, and international collaboration.
 

 The Balancing Act: Personalization and Data Protection
 

 The EU's focus on data privacy mandates the development of AI solutions that personalize the guest experience while adhering to the highest standards of data security and ethical use. Hospitality entities must invest in sophisticated AI solutions that deliver bespoke services while rigorously safeguarding personal information. This approach will foster trust and loyalty among guests.
 

 Optimizing Operations While Minding the Workforce
 

 AI-driven tools offer unparalleled efficiency gains in inventory management, reservation systems, and overall workflows. However, the EU's regulations might introduce limitations to protect workers' rights. It will be crucial to balance automation's benefits and its potential socio-economic impact on the workforce.
 

 Building Trust with Transparent Customer Service AI
 

 The integration of AI in customer service through chatbots and virtual assistants will need to evolve to meet EU standards for transparency and accountability. These tools should inform users of their interactions with AI and offer clear options for human intervention. This fosters trust and enhances guest satisfaction.
 

 Managing Costs and Fostering Innovation
 

 Compliance with new regulations might present financial and operational burdens, particularly for small and medium-sized enterprises (SMEs). While this could impact innovation and raise costs, it also creates opportunities to develop cutting-edge, compliant AI technologies that redefine the industry's competitive landscape.
 

 Prioritizing Safety and Security with Ethical AI
 

 AI applications in safety and security, such as facial recognition and surveillance, will face stringent EU regulations focusing on user consent, data privacy, and ethical data handling. This necessitates investment in technologies that enhance guest and staff safety while aligning with confidentiality and ethical standards.
 

 Ensuring Seamless Data Flow: International Cooperation
 

 The hospitality industry's global nature necessitates considering the EU's AI regulations on international data transfer and cooperation. This is critical for global hotel chains operating across different jurisdictions. Harmonized practices that comply with EU standards while facilitating international operations will be essential.
 

 Recommendations: Charting a Course in the New Landscape
 

 The potential EU AI regulations present a pivotal moment for the hospitality industry, urging a strategic reevaluation of AI deployment. To navigate this landscape effectively, hospitality businesses should:
 

 Invest in Data-Centric AI Solutions: Prioritize AI technologies championing data protection and ethical use.
 

 Prioritize AI technologies championing data protection and ethical use. Balance Efficiency with Workforce Considerations: Optimize operations while ensuring the socio-economic well-being of employees.
 

 Optimize operations while ensuring the socio-economic well-being of employees. Embrace Transparency in AI-powered Customer Service: Ensure customers are aware of AI interactions and have clear options for human intervention.
 

 Ensure customers are aware of AI interactions and have clear options for human intervention. Allocate Resources for Compliance and Innovation: Dedicate resources to ensure compliance and foster the development of innovative, compliant AI applications.
 

 Dedicate resources to ensure compliance and foster the development of innovative, compliant AI applications. Prioritize Ethical Security Measures: Invest in solutions that enhance safety and security while respecting privacy and ethical standards.
 

 Invest in solutions that enhance safety and security while respecting privacy and ethical standards. Advocate for International Cooperation: Collaborate with industry peers to establish frameworks for seamless cross-border data flows and AI deployment.
 

 By proactively addressing these areas, the hospitality industry can leverage AI for innovation, build trust with guests, and ensure a positive, ethical guest experience in this evolving regulatory landscape.
 

 ©[email protected] augmented with the aid of various AI platforms.
 

 Terence Ronson
 

 Managing Director
 

 Pertlink Limited",AI,Relevant,Relevant,
Microsoft: 87% of UK Organizations Vulnerable to Costly Cyber-Attacks,https://www.infosecurity-magazine.com/news/microsoft-uk-orgs-vulnerable-cyber/,"Organizations considered ‘High Risk’ are those that have limited focus on cybersecurity, and mostly fail to use AI in their business at all.
 

 Of the 48% of organizations categorized as ‘Vulnerable,’ the researchers said that while defensive systems and processes are in place, additional investment and support is required to build resilience. Only a few are using AI as a security tool.
 

 The report defined resilient organizations as those that have implemented security-by-design across their networks. Additionally, they must be adopting AI security tools to enable them to detect and respond faster to threats.
 

 Microsfot urged increased investment in AI technologies and solutions to tackle the growing weaponization of AI by cyber-threat actors.
 

 The tech giant said the lack of secure foundations harms the UK’s ambition of becoming an ‘AI superpower’.
 

 Just 13% of UK organizations are resilient to cyber-attacks, with the remainder either vulnerable (48%) or at high risk (39%) of damaging cyber-incidents, according to a new report by Microsoft in collaboration with the University of London.
 

 The research also found that cyber-attacks could be costing UK organizations £87bn ($111bn) every year, and estimated that stronger cybersecurity could save the UK economy £52bn ($66bn) annually.
 

 The majority of decision-makers (52%) and senior security professionals (60%) surveyed expressed concern that current geopolitical tensions will increase cyber risks to their organization.
 

 Additionally, nearly three-quarters (70%) of senior security professionals said they feared the risks posed by AI to their organization, with this sentiment expressed by 49% of decision-makers.
 

 Despite this concern, only 55% of organizations are prepared for cyber threats and just 43% have designated resources for cybersecurity-related events.
 

 Less than half (49%) of these leaders claimed to understand the cybersecurity skills their workforce requires, and only 56% have offered cyber-awareness training to staff.
 

 Almost a third (27%) of UK decision-makers admitted they do not know what cost a successful cyber-attack would have to their organization, while 53% do not know how long it takes to recover from one.
 

 The Urgent Need to Leverage AI in Cybersecurity
 

 The report estimated that businesses that incorporate AI into their security strategy might lower financial losses after a successful attack by 20%.
 

 The average cost of incidents for organizations using AI in security was £16,600 ($21,156) which compares to £20,700 ($26,380) for those not using these tools.
 

 The researchers calculated that organizations using AI in cyber defense could withstand an average of 254 successful attacks before the equivalent of their annual revenue is wiped out. This falls to just 106 attacks for organizations not deploying AI in this manner.
 

 However, just 21% of organizations currently deploy AI in the detection of cyber vulnerabilities, and only 27% are using it specifically to strengthen their cyber defenses.
 

 The report emphasized that AI offers UK organization an opportunity to tip the scales in their favor against cybercriminals.
 

 Dr Chris Brauer, Director of Innovation at Goldsmiths, University of London, commented: “The UK has phenomenal potential to lead the world in the use of AI – an unprecedented opportunity to supercharge our economy and transform our public services. But that future must be built on secure foundations.
 

 “To become an AI superpower, the UK must maintain its position as a cybersecurity superpower. With so many organisations shown to be vulnerable to cybercrime, our research surfaces both the urgency of the issue, and useful actions that leaders can take to boost the country’s cyber resilience.”
 

 Microsoft Announces General Availability of Copilot for Security
 

 On March 13, 2024, Microsoft announced that its Copilot for Security product will be generally available worldwide from April 1 following a the conclusion of its early access program for select customers.
 

 The large language model (LLM) is designed to assist security teams in a variety of functions, including classifying and responding to incidents, report writing for investigations, and analyzing the organization’s internal and external attack surface.
 

 Speaking on a Microsoft security briefing call on March 12, Andrew Conway, Vice President Security Marketing at Microsoft, said Conway revealed that the tech giant is currently in the process of embedding Copilot for security across the entire Microsoft security portfolio.
 

 He observed that cybersecurity has emerged as the most serious use case for AI.
 

 “We see our customers have traditionally faced a disadvantage versus threat actors, and this is a moment where we’re actually seeing organizations use generative AI to gain an advantage,” explained Conway.",AI,Relevant,Relevant,
How Investors Can Shape AI for the Benefit of Workers (Blog),https://ssir.org/articles/entry/ai-investors-care-workers,"(Illustration by Hugo Herrera)
 

 The world of work is changing. AI’s impact on work and workers is an inescapable conversation right now everywhere from the World Economic Forum and the White House, to American union halls, Fortune 100 board rooms, and VC cocktail parties. AI is poised to alter everything from how customer service questions get answered to diagnosing cancer. Here we will skip the false precision of predicting exactly how many jobs will be dislocated and instead focus on how we can envision and incentivize the beneficial impacts of AI for both workers and society.
 

 As venture investors, we are constantly hunting for big, audacious ideas that can produce outsized returns for our investors. But we also didn’t get into this industry without the fundamental belief that the future can be made better than the present. That’s not techno-utopianism but rather a recognition that there are numerous levers within capital that can shape the future we want to live in. If we choose to use them. And as the world of work is reshaped by AI, we believe there are opportunities within our critical, fast-growing care economy sector to enable and support a workforce with the biggest shortages in the United States.
 

 Making Tech Work for Workers This in-depth article series, sponsored by the Ford Foundation, explores the harms of the digital economy and asks workers, organizers, technologists, economists, and funders: How can we collectively build a future of work that is just, equitable, and sustainable for all? FOLLOW THIS SERIES SIGN UP You'll get email alerts when there is new content in this series.
 

 AI and the Future of Work: What Stays and What Goes?
 

 AI’s fundamental skill is pattern recognition at a staggering scale. This means that many administrative and analytical tasks like note-taking, scheduling, data reconciliation, and summarization will be reduced dramatically. It is true that jobs will be lost in these areas. But the ones that remain may become higher quality and higher paying. For example, think of a nurse manager or a teacher who no longer needs to devote 40% of their time to jockeying a schedule or designing slides and worksheets. Instead, they can lean into the uniquely human elements of their job in ways that require emotional and contextual assessment and insight that technology cannot replicate. AI will isolate and highlight these soft skills in ways that will make them more valuable and potentially higher compensated.
 

 AI also has the potential to lower the barriers to entry to many jobs, including technical ones. We’ve seen this same scenario play out with other technological leaps forward, time and time again. Think of the way online maps and navigation made becoming a London black cab driver more accessible, no longer requiring decades to earn “The Knowledge” of every side street. Now that AI can synthesize huge volumes of information and deliver it at the moment of need—to a technician repairing a downed telephone pole, to a nurse wondering which needle gauge to use, to a young engineer who can automate her code production—the workforce will actually become more fungible.
 

 While this sounds like bad news for workers, cheapening tenure and reducing the costs of turnover, workers are more than their technical knowledge. Soft skills, relationship building, and culture will all still matter across industries and job types. Right now we have plenty of highly qualified workers whose days are stuck doing a lot of workflows that are essential to their jobs but aren’t the best use of their training. By having AI automate some of the more time consuming and routine tasks, more experienced, long-tenured workers may benefit as they are able to “practice at the top of their license.”Moreover, a more fungible workforce can accrue significant benefits for workers too. Just-in-time training and a wealth of accrued knowledge at your fingertips no matter how long you’ve been in the job will open up the ability to change jobs, move geographically, upskill, and cross-train.
 

 The Role of New Technology and Caregiving
 

 While much of the alarm around AI and automation concerns the threat that these technologies will be used to replace workers—a real risk in some sectors—we are, in fact, facing acute labor shortages in some industries that have been here for years and show no sign of going away. And while we’ve seen abundant investment in tools designed to assist software developers and free up time for them to focus on the more challenging parts of their jobs, there has been far less investment in technology that could assist construction workers, the service sector, teachers, nurses, or other care workers. Many of these jobs are ripe for innovation, and responsible AI technology could bring more good than harm in assisting parts of our workforce that are stretched to the breaking point.
 

 According to BCG, the United States will lose $290B per year by 2030 if we don’t address two critical care-economy dynamics: the extreme worker shortage in care jobs and the departure of family caregiver employees from other industries when they have to fill the care gaps created.
 

 Some of the most interesting examples of how AI might benefit both workers and those who they serve may therefore occur in the care economy. The care economy employs 17 percent of the US workforce, an area currently experiencing one of the greatest employment shortages, including home health-care aides and nurses. At the same time, these jobs have incredibly high rates of burnout, are physically taxing, mentally exhausting, and often poorly paid. Nearly one in five home health-care aides lives in poverty.
 

 AI and other enabling technologies can make care jobs better and more attractive as a way to increase supply—by automating tasks as opposed to the job wholesale. Take health-care worker burnout for example Things like AI-supported charting, documentation and staffing companies like Abridge, Guardoc, and In-House Health, can potentially cut that work by two-thirds. Tech can also build software for small businesses in areas like childcare, hospice care, and skilled nursing facilities to make scheduling, enrollment, and business management more efficient, potentially opening up savings for higher pay. Similar applications can reduce the time nurses spend on administrative duties, helping to relieve a critical nurse shortage.
 

 Teachers in the United States report the highest levels of burnout of any profession in the country. Currently, about half of teachers’ time is spent not with students but on grading, lesson planning, and curriculum development, as well as other administrative tasks. Some of these tasks could be areas where generative AI technology like Brisk Teaching could serve as a useful copilot for overburdened employees.
 

 At the same time, AI and other technologies can reduce the burden of caregiving on the 40 million Americans who are unpaid family caregivers for their loved ones. Companies like Wellthy use AI to offer customized care coordination tools and support, and companies like Carefull use advanced AI and machine learning techniques to detect fraud and enable adult children to manage the daily finances of their aging loved ones. Caregiving is equal parts work and love—and technology can help reduce the administrative work burden for families and allow more time for connection.
 

 Looking Forward
 

 AI and technological innovation alone will not solve the labor crisis in the care economy. A multi-sector response is required to ensure higher standards and better pay for the caregiving workforce and increased financial support for American families to enable increased access to child care and elder care.
 

 In trying to ensure that the rapid growth of technology is something that will benefit workers and societies as much as entrepreneurs and executives, there’s a role for all of us: employers and workers, academics and governments, as well as investors committed to seeing the technology they fund be used to increase the common good.
 

 Civil society, governments around the world and industry leaders are beginning the difficult conversations to develop regulatory frameworks that can be harmonized globally—that acknowledge the enormous promise of AI as well as its not insignificant peril if not thoughtfully deployed. Venture investors are privileged to have a front seat to those building the future of AI. It is incumbent on us to nudge the economy towards something more sustainable and more humane. This is a space where a lot of people are currently debating the right approach. The White House recently released an AI Executive Order and last year the European Union introduced their first regulatory framework via the AI Act. In November, a group of venture capital investors, the Responsible Innovation Labs, released a set of guidelines on Responsible AI Commitments and Protocol for startups and funders to follow, prioritizing issues of safety, trust, and transparency. Already, the guidelines have drawn the support of dozens of venture investors, startups, and others.
 

 The impetus for responsible technology investment must also come from the asset owners themselves whose money is managed by the venture investors, such as major foundations, pension plans, and university endowments. Aligning investments with ethical missions is not just the right thing to do—it's good business.
 

 As we navigate this transformative era, being deliberate about pointing the innovation engine of our economy towards technology that benefits everyone will be essential.
 

 Support SSIR’s coverage of cross-sector solutions to global challenges.
 

 Help us further the reach of innovative ideas. Donate today.
 

 Read more stories by Elana Berkowitz & Courtney Leimkuhler.",AI,Relevant,Relevant,
World’s Top Solar Firm Longi Plans Thousands of Job Cuts on Glut,https://finance.yahoo.com/news/world-top-solar-firm-longi-082045813.html,"(Bloomberg) -- China’s Longi Green Energy Technology Co., the world’s largest solar manufacturer, is cutting almost one-third of its staff to slash costs in an industry struggling with overcapacity and fierce competition.
 

 Most Read from Bloomberg
 

 Longi plans to trim as much as 30% of its workforce, which last year totaled about 80,000 at its peak, according to several people familiar with the matter, including some briefed by senior management. The people asked not to be identified because the plans aren’t public.
 

 The move signals an acceleration of job cuts that Longi began in November, when it started laying off thousands of people who were mostly management trainees and factory hires — a reversal after years of breakneck expansion across the global solar industry. It isn’t clear how many employees had been dismissed before this latest decision.
 

 Longi rejected as false the suggestion that it would cut 30% of staff and said reductions would involve about 5% of total employees.
 

 The solar sector is facing an “increasingly competitive environment,” the company said in a statement. “In order to adapt to market changes and improve organizational efficiency, Longi is optimizing our workforce.”
 

 Xi’an-based Longi isn’t alone: China’s solar industry dominates global manufacturing but has suffered from layoffs and suspended investment plans in recent months. Manufacturers have been forced to sell at or below production costs after prices for solar panels fell to record lows last year. The result is that an industry seen as crucial to the global energy transition is struggling with excessive capacity, consolidation and the possibility of bankruptcies.
 

 Story continues
 

 Fierce competition has also forced many companies that make wafers — a solar panel precursor that is wired into cells and assembled into modules — to cut production. Longi, a leading wafer producer, had to significantly cut prices last year.
 

 Staff at Longi have seen previous efforts to cut costs fall short, including the cancelation of free afternoon tea, shrinking budgets for business trips and being told to only print in black-and-white unless approved to do otherwise by supervisors, the people said. Longi’s Shanghai office also stopped offering free coffee, two of the people said.
 

 Amid rising internal concerns about job losses by rank-and-file workers, the company late last year disabled an internal function where employees could see the total number of staff, some of the people said.
 

 Read More: Biden Solar Subsidies Seen as Insufficient Against China
 

 Beyond the overcapacity and competition issues, there have been other headaches for Longi and the industry: some Chinese manufacturers have had their exports to the US held up over alleged forced labor abuses in China’s Xinjiang region, accusations which Beijing has repeatedly denied. Longi saw its American joint venture in Ohio, which it built with a local partner, face pushback as political tensions between Beijing and Washington rose.
 

 For Longi, the financial pressures sent its net income plunging 44% to 2.52 billion yuan ($350 million) in the third quarter of 2023. Company President Li Zhenguo said in October that the firm “made a mistake” in not being aggressive enough in price competition with peers and was likely to miss its annual shipment target. The company’s shares have fallen about 70% from their peak in 2021.
 

 The solar industry has a history of boom and bust cycles, as its growth soared and stalled at the whim of government subsidies. Once-top manufacturers like Suntech Power Holdings and Yingli Green Energy Holding Co. later filed for bankruptcy or entered judicial restructuring. On the flip side, cheap solar panels are driving a surge in demand, with new installations soaring 72% to a new record last year, according to BloombergNEF.
 

 Riding a wave of investment and demand for solar power globally, employment at Longi had surged from the 4,068 people it had in 2012, when the manufacturer went public on the Shanghai Stock Exchange. The company reported 60,601 of employees at the end of 2022, and hiring continued well into 2023, according to the people.
 

 That’s all being reversed now.
 

 Employees who left Longi recently were often fired directly or quit after being transferred to different positions that they weren’t able to take, while factories using older technologies have seen more job cuts than other units, some of the people said.
 

 Despite the recent challenges, China’s solar industry could start to see a rebound by year-end, with margins rising in 2025 based on a “quickening pace of consolidation” and a better balance between supply and demand, according to an analysis by Bloomberg Intelligence.
 

 Longi should be in a good position to weather that turbulence: Beyond being a market leader, the company had about $7.4 billion in cash and equivalents at the end of 2022, far more than most of its competitors, according to company filings and a comparison with peers identified by Bloomberg Intelligence.
 

 --With assistance from Dan Murtaugh and Alfred Cang.
 

 (Updates to add company statement from fourth paragraph. A previous version of this story corrected the company name in first paragraph.)
 

 Most Read from Bloomberg Businessweek
 

 ©2024 Bloomberg L.P.",Green Computing,Relevant,Irrelevant,
An Expert on Trust Says We’re Thinking About It All Wrong,https://time.com/6957741/rachel-botsman-trust-interview/,"It’s always tempting for journalists to search for threads that connect disparate news stories, and easy to overstate their significance. But it’s remarkable how much one such thread—declining trust in the institutions that once dominated public life—ties together so many of today’s major headlines, from our deeply polarized politics to the proliferation of crazy conspiracy theories. This decline, sometimes called a “crisis of trust” or a “trust deficit,” has of course become an increasingly common topic in newsrooms and think tanks and global conferences that conjure a world without trust and search for solutions.
 

 But Rachel Botsman, an author, teacher and Substacker who is considered one of the leading experts on the topic, argues we’re thinking about trust wrong. I met Botsman earlier this year at the World Economic Forum at Davos (theme: “Rebuilding Trust”). Because we’re asking many of the wrong questions about trust at places like Davos and elsewhere, she says, we’re missing some of the solutions. Below, condensed and edited for clarity, is our conversation about why that is, and how to fix it.
 

 We hear a lot that trust is in decline. But that's not really your view, is it? It's more that it's in a state of redirection or fragmentation?
 

 Trust is like energy—it doesn't get destroyed; it changes form. It's not a question of whether you trust; it's where you place your trust. In society today, trust is shifting from institutional trust to “distributed trust.” Trust used to flow upwards to leaders and experts, to referees and regulators. Networks, platforms and marketplaces change that flow sideways to peers, strangers and crowds, creating a dispersion of authority and fracturing of trust.
 

 A lack of acceptance that the trust dynamics have changed, I think, is a systemic problem. We're trying to solve trust issues in the distributed world through an institutional mindset.
 

 And if I'm a leader of an institution or a company, then I can learn from that.
 

 Yes. It's like, ""Oh, my trust went over there. That's where it's gone."" That's how they're being influenced. “That's where I've got to be.”
 

 You've said that crucial context is missing from a lot of conversations about trust.
 

 Talking in general terms about trust is not helpful because trust is a belief, and like all beliefs, it is highly subjective and contextual. Whenever we ask the question, ""Do you trust fill in the blank?"" we should follow with ""to do what?""
 

 If you think about trust in AI in education versus trust in AI in healthcare, these are very different applications with different trust needs. Trusting these systems to do what? Talking about trust is problematic unless you get to the context.
 

 So how do you define trust?
 

 The way I define trust is ""a confident relationship with the unknown."" The greater the unknown, the more uncertainty, the more trust that you need.
 

 This perspective runs counter to many social scientists who claim trust is knowing another person will do what is expected or knowing how things will turn out. But this has always struck me as odd: If you know the outcome or how things will end, why do you need trust?
 

 If you take AI, think of all the complexities and unknowns; you need a lot of trust. When most leaders talk about trust in new technologies, they are often talking about mitigating risk. They are focused on governance and controls, and guardrails and mitigating the unknown. And then of course there is the belief that you can increase trust through transparency. This is a big misconception. You can reduce the need for trust through transparency and through these risk controls. Or you can increase people's confidence in the unknown.
 

 So if we want to increase trust in society, we have to do more than mitigate risks.
 

 Yes. I find it quite unsettling that when pressed for solutions, the default is often transparency. Let's make the media transparent. Let's make the algorithms more transparent. Let's make the inner workings of government more transparent. But if that's the way we head, we've kind of given up on trust. You're actually lowering the need for trust. You're saying, ""This is how this thing works. You can be certain about the processes. Therefore, you don't really need as much trust.""
 

 So what does your research say about the right way to build trust, in our institutions and in each other?
 

 Deep trust forms based on how people behave. Above all, I think, it comes from integrity. How do you realign the public's belief and confidence that whatever this institution is is serving their best interests?
 

 It's around changing our behavior rather than guardrails?
 

 You need both, don't get me wrong. But if we're talking about restoring trust, regulatory guardrails don't always restore people's confidence. People's confidence comes more from a belief that you know what you're doing–capability, and I know why you are doing it—–character. Put simply, it comes from not just doing things but doing the right things.
 

 So we need to have more discussion of solutions as a way of building confidence in the notion that we can get from here to there?
 

 There is a crisis of confidence in our society that the people in charge actually know how to get out of this mess and chaos. I often hear, ""Oh, we need to lower expectations of what we think we're going to get from political leaders."" I find it incredibly disconcerting that we've come to accept things unimaginable even five years ago regarding the erosion of trust. We've entered an age of information and content where it's no longer ""trust, but verify"" but ""verify, then trust.""
 

 You recently wrote that, ""Owning our uncertainty makes us kinder, more creative, and more alive."" It seems to me we are seeing some of this in a positive way around AI, at least as compared to social media, do you agree? An acknowledgement that there's plenty we don't know.
 

 What I'm struck by is what I would describe as a push-pull between fear of joining in and fear of missing out. Business leaders need to innovate with AI because they're scared of being left behind. At the same time, there is extreme caution not to move too fast because they understand the unintended consequences if they get it wrong.
 

 The fear, the hesitation, is good for trust. It creates a trust pause, where people slow down and think, ""How do I trust these systems?"" For example, I trust it for input and information, but I don't trust it yet to make decisions about my health or money.
 

 I was impressed, I have to say, by the humility of Sam Altman when he said, the sign above his desk says “no one knows what happens next."" The next generation of AI leaders may have the humility to admit they don't know. They may program that into the technology so that it says, ""I don't know the factual answer to that. Ask a human being or find another source.""
 

 Is there an example in your research or work of an institution or a field that has turned it around, that has rebuilt trust?
 

 It always comes down to an individual. It's often a very low-tech intervention. Take schools. Sometimes, kids have a very low propensity to trust others. They've never experienced being trusted, so they don't know or find it incredibly difficult to trust others. And then you have these remarkable teachers who slowly earn their trust over time.
 

 One of the things that always strikes me is that the teachers never go into these situations with the assumption that the children will give their trust back. They assume these kids will not trust them. Earning trust is through small gestures over time. It's how you treat people day in, day out. It's how you make them feel, especially on tough days. Can you scale that type of human trust through technology? Do we want to? We’ll see.
 

 Does that make you a pessimist?
 

 Or a realist. Or a humanist! I'm hopeful in many ways because AI will make us think more carefully about human connection and why humanness will become a differentiator.",Trust Technologies,Relevant,Relevant,
"Restraining the shuttle effect of polyiodide and modulating the deposition of zinc ions to enhance the cycle lifespan of aqueous Zn-I
  
  2
  
  battery",https://pubs.rsc.org/en/content/articlelanding/2024/sc/d4sc00792a,"Restraining the shuttle effect of polyiodide and modulating the deposition of zinc ions to enhance the cycle lifespan of aqueous Zn-I 2 battery
 

 Q. Yue, Y. Wan, X. Li, Q. Zhao, T. Gao, G. Deng, B. Li and D. Xiao, Chem. Sci., 2024, Accepted Manuscript , DOI: 10.1039/D4SC00792A
 

 This article is licensed under a Creative Commons Attribution-NonCommercial 3.0 Unported Licence. You can use material from this article in other publications, without requesting further permission from the RSC, provided that the correct acknowledgement is given and it is not used for commercial purposes.
 

 To request permission to reproduce material from this article in a commercial publication, please go to the Copyright Clearance Center request page.
 

 If you are an author contributing to an RSC publication, you do not need to request permission provided correct acknowledgement is given.
 

 If you are the author of this article, you do not need to request permission to reproduce figures and diagrams provided correct acknowledgement is given. If you want to reproduce the whole article in a third-party commercial publication (excluding your thesis/dissertation for which permission is not required) please go to the Copyright Clearance Center request page.
 

 Read more about how to correctly acknowledge RSC content.",General,Irrelevant,Irrelevant,
"How Elon Musk courted Don Lemon to show that X isn't a right-wing tool, as the breakup highlights Linda Yaccarino's thankless task of trying to assure brands (Tim Higgins/Wall Street Journal)",https://mediagazer.com/240317/p1,"About Mediagazer:
 

 Mediagazer presents the day's must-read media news on a single page.
 

 The media business is in tumult: from the production side to the distribution side, new technologies are upending the industry. Keeping up with these changes is time-consuming, as essential media coverage is scattered across numerous web sites at any given moment.
 

 Mediagazer simplifies this task by organizing the key coverage in one place. We've combined sophisticated automated aggregation technologies with direct editorial input from knowledgeable human editors to present the one indispensable narrative of an industry in transition.",General,Relevant,Irrelevant,
"DirecTV introduces a ""No Locals"" package, which allows customers to opt out of receiving their local TV stations and receive discounts of $12 per month (Jon Lafayette/Next TV)",https://mediagazer.com/240317/p3,"About Mediagazer:
 

 Mediagazer presents the day's must-read media news on a single page.
 

 The media business is in tumult: from the production side to the distribution side, new technologies are upending the industry. Keeping up with these changes is time-consuming, as essential media coverage is scattered across numerous web sites at any given moment.
 

 Mediagazer simplifies this task by organizing the key coverage in one place. We've combined sophisticated automated aggregation technologies with direct editorial input from knowledgeable human editors to present the one indispensable narrative of an industry in transition.",General,Relevant,Irrelevant,
"Ofcom rules that five GB News programmes presented by Conservative politicians have broken its due impartiality rules and puts the channel ""on notice"" (Charlotte Tobitt/Press Gazette)",https://mediagazer.com/240318/p5,"About Mediagazer:
 

 Mediagazer presents the day's must-read media news on a single page.
 

 The media business is in tumult: from the production side to the distribution side, new technologies are upending the industry. Keeping up with these changes is time-consuming, as essential media coverage is scattered across numerous web sites at any given moment.
 

 Mediagazer simplifies this task by organizing the key coverage in one place. We've combined sophisticated automated aggregation technologies with direct editorial input from knowledgeable human editors to present the one indispensable narrative of an industry in transition.",General,Relevant,Irrelevant,
"Authentic Brands licenses Sports Illustrated's publishing rights to The Players' Tribune owner Minute Media for 10 years, with plans to keep the print edition (Benjamin Mullin/New York Times)",https://mediagazer.com/240318/p7,"About Mediagazer:
 

 Mediagazer presents the day's must-read media news on a single page.
 

 The media business is in tumult: from the production side to the distribution side, new technologies are upending the industry. Keeping up with these changes is time-consuming, as essential media coverage is scattered across numerous web sites at any given moment.
 

 Mediagazer simplifies this task by organizing the key coverage in one place. We've combined sophisticated automated aggregation technologies with direct editorial input from knowledgeable human editors to present the one indispensable narrative of an industry in transition.",General,Relevant,Irrelevant,
The 5 best Wi-Fi adapters for PC in 2024,https://www.digitaltrends.com/computing/best-wifi-adapters/,"Whether youâ€™re designing it yourself or getting a pre-built PC, it can be easy to get a computer and realize that it doesnâ€™t have a native Wi-Fi adapter. Or, maybe it does, but youâ€™re internet speeds are getting faster, game downloads are getting bigger, youâ€™ve already upgraded your router and need an adapter to match your newfound power requirements. No matter the situation, an external Wi-Fi adapter that you can add to your PC setup or even laptop setup will be worth your time. Here, we investigate the best Wi-Fi adapters for PC use. Most are incredibly affordable and just snap into a free USB port and start working.
 
 The best Wi-Fi adapter for PC in 2024
 
 Buy the for the overall best Wi-Fi adapter for most people.
 
 for the overall best Wi-Fi adapter for most people. Buy the as a good runner-up.
 
 as a good runner-up. Buy the for a convenient USB stick adapter on the affordable side.
 
 for a convenient USB stick adapter on the affordable side. Buy the if youâ€™re having trouble with reception.
 
 if youâ€™re having trouble with reception. Buy the for a miniature USB Wi-Fi adapter plug on the cheap. (Great for laptops!)
 
 TP-Link AX1800 Wi-Fi 6 USB Adapter
 
 Best for most people
 
 Pros Cons Dual-band adaptation Pre-loaded drivers are outdated Dual usage modes Slightly expensive Extendable â€œantennaâ€
 
 For a USB Wi-Fi adapter that has it all, check out this TP-Link. The TP-Link AX1800 has a super fast data transfer rate, Wi-Fi 6 connectivity, an extendable â€œantennaâ€ flap, and can either be used as a direct plugin as a stick or put on a stand connected to a 1.2 meter cable for support from a somewhat removed location. While, as an individual, you may not find all of these features useful all of the time for your situation, they do bring everything that you might desire together in one package.
 
 The antenna flap, for example, is a great way to pull extra Wi-Fi â€œreceptionâ€ if youâ€™re far away from your router. If you place the AX1800 in its standup base, connect the 1.2 meter USB cable to it, extend the antenna, and place it on a table away from your PC tower, you may very well find that you get better internet. Just as you need to properly place your router, having the receiver in the right location can help, too. At the same time, this device is not magical. It wonâ€™t pickup Wi-Fi signal that isnâ€™t there. Youâ€™ll need to extend your Wi-Fi range in that case. Still, the flexibility given here can greatly help your home PC setup.
 
 Meanwhile, with the antenna flap closed and the stand put away, you have a super powerful Wi-Fi adapter with a compact form factor and one of the highest data transfer rates youâ€™ll see on such a device. This can be great for your minimalist home PC setup or great for your budget laptop that you want Wi-Fi 6 capabilities on. While that does not mean the fast speeds native devices can bring, it does mean youâ€™ll get the lower latency the new tech offers.
 
 Due to the wide range of applications and high speeds offered, TP-Links AX1800 is a sort of standard for Wi-Fi adapters. That doesnâ€™t mean that it comes without flaws, however. While it isnâ€™t the most expensive adapter on the list, it is over $50 unless on a deep cutting sale, and you by no means need to spend over $50 on a Wi-Fi adapter for functionality. Furthermore, youâ€™ll have to upgrade the drivers that come preloaded with the AX1800 to get the best usage out of it. Still, this Wi-Fi adapter is so fully featured, that it is an excellent place to start on your journey to finding what you want.
 
 Key Specifications Size 4.4 x 1.2 x 0.58 inches Data transfer rate 1800 Megabits per second
 
 Netgear Nighthawk A8000 Wi-Fi 6/6E Adapter
 
 Best alternative
 
 Pros Cons Wi-Fi 6 and Wi-Fi 6E versions available Expensive without sales and discounts Excellent form factor Compact body
 
 Netgearâ€™s Nighthawk A8000 admittedly came very close to being the best Wi-Fi adapter overall. It has a nicely compact body with a solid construction and the ability to be used as a simple USB stick or to sit in its cradle in a location away from the computer it is attached to. These are all features that are admirable for a Wi-Fi adapter to have and, once again, represent a kind of gold standard feature list for such products.
 
 The Nighthawk A8000 even has two possible versions you can obtain, one with Wi-Fi 6 and one with Wi-Fi 6E. So long as you have the appropriate Wi-Fi 6 router, these technologies represent big upgrades for your performance. Getting the Wi-Fi 6E version can possibly increase the reliability of your connection, alongside reducing interference and decreasing issues you might have with latency. Just to be clear, however, youâ€™ll still be limited to the 1201 megabits per second maximum of Wi-Fi adapter (or whatever other speed-limiting factor might exist in your system).
 
 So what shortcoming puts the Nighthawk A8000 into the runner-up category? Again, it is all a matter of price. The Nighthawk A8000 is on the more expensive end of the spectrum at MSRP. Try to find a good deal on it before making a purchase.
 
 Key Specifications Size 3.66 x 1.24 x 0.57 inches Data transfer rate 1201 Megabits per second
 
 Ugreen AC1300 Wi-Fi Adapter
 
 Most convenient dongle
 
 Pros Cons Convenient jump-drive style Not as fast as top models Protection cap for travel Great price
 
 If youâ€™re looking for that classic jump-drive USB look that you can plug into your PC and largely forget about, this is the one. The Ugreen offers a decent level of speed (though not as much as our top contenders) while keeping the form simple and reliable. You, more or less, just need to plug it in and get started as there is no need to mess about with its antennae or deal with a long cord. Another great convenience is the one-click WPS Wi-Fi connection button, making connection a new network a snap.
 
 Another nod to the jump-drive origins of the Ugreen AC1300â€™s form factor is the nice protection cap on the end. When you want to travel with your device, you can keep your Wi-Fi adapter protected easily. Thereâ€™s also the case for using the stick in your laptop if its internal Wi-Fi adapter is burnt out. However, in this case youâ€™ll need to be careful when you use the laptop in your lap while reclining in bed or on the couch, as a wrong movement can catch the end of the adapter. In other words, if you mostly use your laptop at a desk this is perfect for you, but if you move about a lot, a short mini dongle is the best Wi-Fi adapter for you.
 
 A final reasoning for picking the Ugreen AC1300 is its relatively fast speed for the form factor. You should know that it still isnâ€™t capable of the speeds of more premium models, but for the vast majority of people, this connection should be fast enough and serve you well.
 
 Key Specifications Size 3.35 x 0.98 x 0.31 inches Data transfer rate 867 Megabits per second
 
 TP-Link Archer T4U Plus
 
 Best for weak signals
 
 Pros Cons Highly affordable Not great for laptops Dual antenna design Good range
 
 The TP-Link Archer T4U Plus is a dual-band Wi-Fi adapter that can help you get the most out of a difficult situation when it comes to getting signal. The Wi-Fi adapter itself is a stand that connects to your PC via a USB 3.0 cord that fits into the back of its main â€œtowerâ€ chassis. While the body of this â€œtowerâ€ is quite short, two antennae with 180-degree adjustability come out of it. These antennae are high-gain, with some users reporting the ability to pick up signal as far as 200 feet away from their router. This being said, an antenna â€” no matter how good â€” cannot pick up signal that is not there.
 
 Another of the huge pros of this Wi-Fi adapter is its affordability. Just about anybody should be able to pop a Wi-Fi adapter of this tier and pricing into their cart without much worry. At the same time, this Wi-Fi adapter is not the best for laptops, due to the fact that it needs the cord and extension. Youâ€™ll want to place it somewhere permanently on your quality computer desk, not move it around consistently. But, if you give it a dedicated spot and spend some time adjusting it properly, you should be able to get a decent connection out of the Archer T4U Plus.
 
 Key Specifications Size 3.31 x 0.76 x 6.15 inches Data transfer rate 1267 Megabits per second
 
 TP-Link Archer T2U Nano
 
 Best budget
 
 Pros Cons Small size Slower data transfer rate Great durability Good pricing
 
 TP-Linkâ€™s Archer T2U Nano takes on the form factor of the mini dongle that has been popularized by some of the best wireless mice. The size of this Wi-Fi adapter cannot be understated, with many of them being able to fit in a single cubic inch. That makes the TP-Link Archer T2U the best Wi-Fi adapter for laptop users. Due to its small size, it can safely live in your laptopâ€™s USB port during transport, largely forgotten about.
 
 Thereâ€™s also a pretty good case for buying the TP-Link Archer T2U for any device. The price. This is one of the lowest cost Wi-Fi adapters that youâ€™ll be able to find. The speed that it will provide is considerably lower than others, however if that doesnâ€™t matter too much to you and the type of internet use youâ€™re typically doing, this is a â€˜buyâ€™.
 
 Key Specifications Size 0.73 x 0.59 x 0.28 inches Data transfer rate 433 Megabits per second
 
 How we chose these Wi-Fi adapters for PCs
 
 Picking Wi-Fi adapters isnâ€™t the most difficult thing in the world, but there are some things worth thinking about in the process. Here are a few points that stick out and are worth giving a moment of your attention.
 
 Data transfer rate and Wi-Fi protocol
 
 In the abstract, you can think of your Wi-Fi as being the final part of a long, single-file journey from the land of the internet to your home PC. The slowest part of the journey dictates the pace. As a result, if you get a Wi-Fi adapter with a slow data transfer rate, or at least slower than the next slowest piece in your connection, the Wi-Fi adapter will make slow your connection down. If a Wi-Fi adapter results in slower than expected internet, be sure to try other ways to boost your internet speed.
 
 Pay attention to the Wi-Fi protocol â€” youâ€™ll likely hear about Wi-Fi 6 and Wi-Fi 6E if the manufacturer supports it â€” as this will also affect your Wi-Fi adapterâ€™s connection. However, it wonâ€™t necessarily affect your connection in the way you might predict it to. Wi-Fi 6, despite and manufacturer verbiage to the contrary, wonâ€™t make your internet connection faster than the aforementioned slowest link in the race.
 
 In general, when choosing Wi-Fi adapters we have favored those with Wi-Fi 6 and Wi-Fi 6E because they are capable of providing better, more stable connections.
 
 The USB connection
 
 Wi-Fi adapters are stuck in a sort of technological limbo, being even slower than the latest iPhones to adapt to USB-C. While it does make sense, as USB-C devices tend to have fairly decent Wi-Fi internally, it is an odd peculiarity of the space. In case the intricacies of USB-A have been long forgotten for you, USB 3.0 is the best one and is the one that we have typically selected for.
 
 Size, length, wires, and leverage
 
 How do you use the device the Wi-Fi adapter is connected to? If you walk by it constantly or, as in the case of laptops, move the device it is connected to around quite a bit, you are inadvertently creating a powerful lever. Much like a see-saw, the far end of a USB stick has a lot of leverage and, should enough force be applied, can cause your Wi-Fi adapter to snap right at the USB plug if it is knocked into or pressed too hard into the bed.
 
 If you do happen to be one of these users that travels near the port of your PC (or is using a Wi-Fi adapter on your laptop) consider getting a mini or â€œnanoâ€ Wi-Fi adapter, which are typically slower but also much less likely to snap than the stick form factor. If you have a more solid, immobile PC setup, you can also get a Wi-Fi adapter with a stand or base that extends from the USB port on a cable. This will also give you the advantage of being able to position the Wi-Fi adapter in a more favorable location.
 
 Antennae
 
 A final word on the form factor of your Wi-Fi adapter â€” it may have an antenna, or even two. These can, indeed help you get some better signal for your Wi-Fi. Donâ€™t, however, think that a Wi-Fi adapter will make up for a true lack of signal or help you overcome some obstruction in your setup. We considered antennae a nice-to-have (especially if extending it was optional) that some of the best Wi-Fi adapters might have, but it is not necessarily a requirement. If your router is in the next room, you will likely not need an antenna on your Wi-Fi adapter.
 
 This article is managed and created separately from the Digital Trends Editorial team.
 
 Editors' Recommendations",General,Irrelevant,Irrelevant,